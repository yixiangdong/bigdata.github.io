{"meta":{"title":"大数据商务智能(BI)专栏","subtitle":"专注 系统 专业 ","description":"大数据商务智能(BI)方案设计","author":"易向东","url":"https://etop.work","root":"/"},"pages":[],"posts":[{"title":"实时用户画像系统(二十一)","slug":"ceshi25","date":"2020-03-30T12:46:15.000Z","updated":"2020-03-31T02:53:15.661Z","comments":true,"path":"2020/03/30/ceshi25/","link":"","permalink":"https://etop.work/2020/03/30/ceshi25/","excerpt":"","text":"加入后端接口让图表动态显示数据","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(二十)vue.js+highcharts构建图表","slug":"ceshi24","date":"2020-03-30T12:46:06.000Z","updated":"2020-03-31T02:48:46.738Z","comments":true,"path":"2020/03/30/ceshi24/","link":"","permalink":"https://etop.work/2020/03/30/ceshi24/","excerpt":"在项目中引入highcharts图表该文章适合有一定基础的vue语法基础的童鞋学习，语法在这里不再讲述。","text":"在项目中引入highcharts图表该文章适合有一定基础的vue语法基础的童鞋学习，语法在这里不再讲述。 项目components结构 各个部分的代码如下: charts.vue作用: charts页面调用HighCharts显示图像 123456789101112131415161718192021222324252627&lt;template&gt; &lt;div class=\"x-bar\"&gt; &lt;div :id=\"id\" :option=\"option\"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import HighCharts from 'highcharts' export default &#123; // 验证类型 props: &#123; id: &#123; type: String &#125;, option: &#123; type: Object &#125; &#125;, watch: &#123; option () &#123; HighCharts.chart(this.id,this.option); &#125; &#125;, mounted() &#123; HighCharts.chart(this.id,this.option) &#125; &#125;&lt;/script&gt; highcharts.vue作用: 定义图像各个维度（标题，副标题，列，x轴,y轴） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;template&gt;&lt;div&gt; &lt;x-chart id=\"high\" class=\"high\" :option=\"option1\"&gt;&lt;/x-chart&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; // 导入chart组件 var myvue = &#123;&#125;; import XChart from './charts' export default &#123; data() &#123; return &#123; option1:&#123; chart: &#123; type: 'column' &#125;, title: &#123; text: '月平均降雨量' &#125;, subtitle: &#123; text: '数据来源: WorldClimate.com' &#125;, xAxis: &#123; categories: [ '一月','二月','三月','四月','五月','六月','七月','八月','九月','十月','十一月','十二月' ], crosshair: true &#125;, yAxis: &#123; min: 0, title: &#123; text: '降雨量 (mm)' &#125; &#125;, tooltip: &#123; // head + 每个 point + footer 拼接成完整的 table headerFormat: '&lt;span style=\"font-size:10px\"&gt;&#123;point.key&#125;&lt;/span&gt;&lt;table&gt;', pointFormat: '&lt;tr&gt;&lt;td style=\"color:&#123;series.color&#125;;padding:0\"&gt;&#123;series.name&#125;: &lt;/td&gt;' + '&lt;td style=\"padding:0\"&gt;&lt;b&gt;&#123;point.y:.1f&#125; mm&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;', footerFormat: '&lt;/table&gt;', shared: true, useHTML: true &#125;, plotOptions: &#123; column: &#123; borderWidth: 0 &#125; &#125;, series: [&#123; name: '东京', data: [49.9, 71.5, 106.4, 129.2, 144.0, 176.0, 135.6, 148.5,500, 194.1, 95.6, 54.4] &#125;] &#125;, &#125; &#125;, beforeCreate:function()&#123; myvue = this; &#125;, mounted:function()&#123; myvue.other.title.text = '2010 ~ 2016 年太阳能行业就业人员发展情况'; myvue.other.subtitle.text = '数据来源：thesolarfoundation.com'; myvue.other.series = myvue.data;//数据 myvue.other.yAxis.title.text = '就业人数'; //数据 myvue.option = myvue.other; &#125;, components: &#123; XChart &#125; &#125;&lt;/script&gt; 路由router设置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import Vue from &#39;vue&#39;import VueRouter from &#39;vue-router&#39;import home from &#39;..&#x2F;components&#x2F;home.vue&#39;import index from &#39;..&#x2F;index.vue&#39;import store from &#39;..&#x2F;store&#x2F;index.js&#39;import VueResource from &#39;vue-resource&#39;import highcharts from &#39;..&#x2F;components&#x2F;highcharts.vue&#39;&#x2F;&#x2F;highcharts的引入Vue.use(VueResource)Vue.use(VueRouter)&#x2F;* eslint-disable no-new *&#x2F;&#x2F;&#x2F; new Vue(&#123;&#x2F;&#x2F; el: &#39;#app&#39;,&#x2F;&#x2F; render: h &#x3D;&gt; h(App)&#x2F;&#x2F; &#125;)&#x2F;&#x2F; 0. 如果使用模块化机制编程， 要调用 Vue.use(VueRouter)&#x2F;&#x2F; 1. 定义（路由）组件。&#x2F;&#x2F; 可以从其他文件 import 进来&#x2F;&#x2F; 2. 定义路由&#x2F;&#x2F; 每个路由应该映射一个组件。 其中&quot;component&quot; 可以是&#x2F;&#x2F; 通过 Vue.extend() 创建的组件构造器，&#x2F;&#x2F; 或者，只是一个组件配置对象。&#x2F;&#x2F; 我们晚点在讨论嵌套路由。const routes &#x3D; [ &#123; path: &#39;&#x2F;&#39;,name:&quot;home&quot;,component: home&#125;, &#123; path: &#39;&#x2F;highcharts&#39;,name:&quot;highcharts&quot;,component: highcharts&#125; ]&#x2F;&#x2F; 3. 创建 router 实例，然后传 &#96;routes&#96; 配置&#x2F;&#x2F; 你还可以传别的配置参数, 不过先这么简单着吧。const router &#x3D; new VueRouter(&#123; mode: &#39;history&#39;, routes &#x2F;&#x2F; （缩写）相当于 routes: routes&#125;)&#x2F;&#x2F; 4. 创建和挂载根实例。&#x2F;&#x2F; 记得要通过 router 配置参数注入路由，&#x2F;&#x2F; 从而让整个应用都有路由功能const app &#x3D; new Vue(&#123; store, router, render: h &#x3D;&gt; h(index)&#125;).$mount(&#39;#app&#39;)&#x2F;&#x2F; 现在，应用已经启动了！ 前端显示结果npm run dev http://localhost:8081/highcharts","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十九)vue.js+highcharts构建图表","slug":"ceshi23-1","date":"2020-03-30T12:45:56.000Z","updated":"2020-03-31T02:40:02.490Z","comments":true,"path":"2020/03/30/ceshi23-1/","link":"","permalink":"https://etop.work/2020/03/30/ceshi23-1/","excerpt":"安装highchartsnpm install highcharts –save","text":"安装highchartsnpm install highcharts –save 访问highcharts官网以及演示图表https://www.highcharts.com.cn/demo/highcharts 基础折线图使用方法: 图中红圈区域是重点需要了解的地方，只需要把js和html代码复制到项目里面去就可以了。 加入bootstrap css样式下载bootstrap 3.3.6 项目依赖package.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657\"dependencies\": &#123; \"highcharts\": \"^7.0.0\", \"vue\": \"^2.0.1\", \"vue-highcharts\": \"0.0.11\", \"vue-resource\": \"^1.5.1\"&#125;,\"devDependencies\": &#123; \"autoprefixer\": \"^6.4.0\", \"babel-core\": \"^6.0.0\", \"babel-loader\": \"^6.0.0\", \"babel-plugin-transform-runtime\": \"^6.0.0\", \"babel-preset-es2015\": \"^6.0.0\", \"babel-preset-stage-2\": \"^6.0.0\", \"babel-register\": \"^6.0.0\", \"chai\": \"^3.5.0\", \"connect-history-api-fallback\": \"^1.1.0\", \"css-loader\": \"^0.25.0\", \"eventsource-polyfill\": \"^0.9.6\", \"express\": \"^4.13.3\", \"extract-text-webpack-plugin\": \"^1.0.1\", \"file-loader\": \"^0.9.0\", \"function-bind\": \"^1.0.2\", \"html-webpack-plugin\": \"^2.8.1\", \"http-proxy-middleware\": \"^0.17.2\", \"inject-loader\": \"^2.0.1\", \"isparta-loader\": \"^2.0.0\", \"json-loader\": \"^0.5.4\", \"karma\": \"^1.3.0\", \"karma-coverage\": \"^1.1.1\", \"karma-mocha\": \"^1.2.0\", \"karma-phantomjs-launcher\": \"^1.0.0\", \"karma-sinon-chai\": \"^1.2.0\", \"karma-sourcemap-loader\": \"^0.3.7\", \"karma-spec-reporter\": \"0.0.26\", \"karma-webpack\": \"^1.7.0\", \"less-loader\": \"^2.2.3\", \"lolex\": \"^1.4.0\", \"mocha\": \"^3.1.0\", \"opn\": \"^4.0.2\", \"ora\": \"^0.3.0\", \"phantomjs-prebuilt\": \"^2.1.3\", \"shelljs\": \"^0.7.4\", \"sinon\": \"^1.17.3\", \"sinon-chai\": \"^2.8.0\", \"style-loader\": \"^0.13.1\", \"stylus\": \"^0.54.5\", \"stylus-loader\": \"^3.0.2\", \"url-loader\": \"^0.5.7\", \"vue-loader\": \"^9.4.0\", \"vue-router\": \"^2.0.1\", \"vue-style-loader\": \"^1.0.0\", \"vuex\": \"^2.0.0\", \"webpack\": \"^1.13.2\", \"webpack-dev-middleware\": \"^1.8.3\", \"webpack-hot-middleware\": \"^2.12.2\", \"webpack-merge\": \"^0.14.1\"&#125; 运行项目并访问 也可以npm install之后 运行命令npm run dev http://localhost:8080","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十八)vuejs+nodejs构建前端项目","slug":"ceshi23","date":"2020-03-30T11:10:19.000Z","updated":"2020-03-30T12:42:51.674Z","comments":true,"path":"2020/03/30/ceshi23/","link":"","permalink":"https://etop.work/2020/03/30/ceshi23/","excerpt":"Vue.jsVue.js 是一个JavaScriptMVVM库，是一套构建用户界面的渐进式框架Vue.js是当下很火的一个JavaScript MVVM库，它是以数据驱动和组件化的思想构建的。相比于Angular.js，Vue.js提供了更加简洁、更易于理解的API，使得我们能够快速地上手并使用Vue.js。 安装nodejs进入官网: http://nodejs.cn/","text":"Vue.jsVue.js 是一个JavaScriptMVVM库，是一套构建用户界面的渐进式框架Vue.js是当下很火的一个JavaScript MVVM库，它是以数据驱动和组件化的思想构建的。相比于Angular.js，Vue.js提供了更加简洁、更易于理解的API，使得我们能够快速地上手并使用Vue.js。 安装nodejs进入官网: http://nodejs.cn/ window上点击运行输入CMD,node -v 验证版本即可! install webpack –gnpm install –global vue-cli –registry=https://registry.npm.taobao.org 设置成国内taobao镜像增加下载速度 npm install –registry=https://registry.npm.taobao.org 搭建开发环境开发工具使用是ws(webstorm)","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十六)潮男族潮女族标签","slug":"ceshi21","date":"2020-03-29T15:37:20.000Z","updated":"2020-03-30T09:54:27.423Z","comments":true,"path":"2020/03/29/ceshi21/","link":"","permalink":"https://etop.work/2020/03/29/ceshi21/","excerpt":"添加实体类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.List;/** * Created by li on 2019/1/6. */public class ChaomanAndWomenInfo &#123; private String chaotype;//1,潮男 ；2，潮女 private String userid;//用户id private long count; private String groupbyfield; private List&lt;ChaomanAndWomenInfo&gt; list; public List&lt;ChaomanAndWomenInfo&gt; getList() &#123; return list; &#125; public void setList(List&lt;ChaomanAndWomenInfo&gt; list) &#123; this.list = list; &#125; public String getChaotype() &#123; return chaotype; &#125; public void setChaotype(String chaotype) &#123; this.chaotype = chaotype; &#125; public String getUserid() &#123; return userid; &#125; public void setUserid(String userid) &#123; this.userid = userid; &#125; public long getCount() &#123; return count; &#125; public void setCount(long count) &#123; this.count = count; &#125; public String getGroupbyfield() &#123; return groupbyfield; &#125; public void setGroupbyfield(String groupbyfield) &#123; this.groupbyfield = groupbyfield; &#125;&#125;","text":"添加实体类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.List;/** * Created by li on 2019/1/6. */public class ChaomanAndWomenInfo &#123; private String chaotype;//1,潮男 ；2，潮女 private String userid;//用户id private long count; private String groupbyfield; private List&lt;ChaomanAndWomenInfo&gt; list; public List&lt;ChaomanAndWomenInfo&gt; getList() &#123; return list; &#125; public void setList(List&lt;ChaomanAndWomenInfo&gt; list) &#123; this.list = list; &#125; public String getChaotype() &#123; return chaotype; &#125; public void setChaotype(String chaotype) &#123; this.chaotype = chaotype; &#125; public String getUserid() &#123; return userid; &#125; public void setUserid(String userid) &#123; this.userid = userid; &#125; public long getCount() &#123; return count; &#125; public void setCount(long count) &#123; this.count = count; &#125; public String getGroupbyfield() &#123; return groupbyfield; &#125; public void setGroupbyfield(String groupbyfield) &#123; this.groupbyfield = groupbyfield; &#125;&#125; 添加map数据处理类12345678910111213141516171819202122232425262728293031323334353637383940414243import com.alibaba.fastjson.JSONObject;import com.youfan.entity.ChaomanAndWomenInfo;import com.youfan.entity.UseTypeInfo;import com.youfan.kafka.KafkaEvent;import com.youfan.log.ScanProductLog;import com.youfan.util.HbaseUtil;import com.youfan.utils.MapUtils;import com.youfan.utils.ReadProperties;import org.apache.commons.lang.StringUtils;import org.apache.flink.api.common.functions.FlatMapFunction;import org.apache.flink.util.Collector;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * Created by li on 2019/1/6. */public class ChaomanAndwomenMap implements FlatMapFunction&lt;KafkaEvent,ChaomanAndWomenInfo&gt; &#123; @Override public void flatMap(KafkaEvent kafkaEvent, Collector&lt;ChaomanAndWomenInfo&gt; collector) throws Exception &#123; String data = kafkaEvent.getWord(); ScanProductLog scanProductLog = JSONObject.parseObject(data,ScanProductLog.class); int userid = scanProductLog.getUserid(); int productid = scanProductLog.getProductid(); ChaomanAndWomenInfo chaomanAndWomenInfo = new ChaomanAndWomenInfo(); chaomanAndWomenInfo.setUserid(userid+\"\"); String chaotype = ReadProperties.getKey(productid+\"\",\"productChaoLiudic.properties\"); if(StringUtils.isNotBlank(chaotype))&#123; chaomanAndWomenInfo.setChaotype(chaotype); chaomanAndWomenInfo.setCount(1l); chaomanAndWomenInfo.setGroupbyfield(\"chaomanAndWomen==\"+userid); List&lt;ChaomanAndWomenInfo&gt; list = new ArrayList&lt;ChaomanAndWomenInfo&gt;(); list.add(chaomanAndWomenInfo); collector.collect(chaomanAndWomenInfo); &#125; &#125;&#125; 添加Flatmap数据处理类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import com.alibaba.fastjson.JSONObject;import com.youfan.entity.ChaomanAndWomenInfo;import com.youfan.kafka.KafkaEvent;import com.youfan.log.ScanProductLog;import com.youfan.util.HbaseUtil;import com.youfan.utils.ReadProperties;import org.apache.commons.lang.StringUtils;import org.apache.flink.api.common.functions.FlatMapFunction;import org.apache.flink.util.Collector;import java.util.*;/** * Created by li on 2019/1/6. */public class ChaomanAndwomenbyreduceMap implements FlatMapFunction&lt;ChaomanAndWomenInfo,ChaomanAndWomenInfo&gt; &#123; @Override public void flatMap(ChaomanAndWomenInfo chaomanAndWomenInfo, Collector&lt;ChaomanAndWomenInfo&gt; collector) throws Exception &#123; Map&lt;String, Long&gt; resultMap = new HashMap&lt;String, Long&gt;(); String rowkey = \"-1\"; if (rowkey.equals(\"-1\")) &#123; rowkey = chaomanAndWomenInfo.getUserid() + \"\"; &#125; String chaotype = chaomanAndWomenInfo.getChaotype(); Long count = chaomanAndWomenInfo.getCount(); long pre = resultMap.get(chaotype) == null ? 0l : resultMap.get(chaotype); resultMap.put(chaotype, pre + count); String tablename = \"userflaginfo\"; String famliyname = \"userbehavior\"; String colum = \"chaomanandwomen\"; String data = HbaseUtil.getdata(tablename, rowkey, famliyname, colum); if (StringUtils.isNotBlank(data)) &#123; Map&lt;String, Long&gt; datamap = JSONObject.parseObject(data, Map.class); Set&lt;String&gt; keys = resultMap.keySet(); for (String key : keys) &#123; Long pre1 = datamap.get(key) == null ? 0l : datamap.get(key); resultMap.put(key, pre1 + resultMap.get(key)); &#125; &#125; if (!resultMap.isEmpty()) &#123; String chaomandanwomenmap = JSONObject.toJSONString(resultMap); HbaseUtil.putdata(tablename, rowkey, famliyname, colum, chaomandanwomenmap); long chaoman = resultMap.get(\"1\") == null ? 0l : resultMap.get(\"1\"); long chaowomen = resultMap.get(\"2\") == null ? 0l : resultMap.get(\"2\"); String flag = \"women\"; long finalcount = chaowomen; if (chaoman &gt; chaowomen) &#123; flag = \"man\"; finalcount = chaoman; &#125; if (finalcount &gt; 2000) &#123; colum = \"chaotype\"; ChaomanAndWomenInfo chaomanAndWomenInfotemp = new ChaomanAndWomenInfo(); chaomanAndWomenInfotemp.setChaotype(flag); chaomanAndWomenInfotemp.setCount(1l); chaomanAndWomenInfotemp.setGroupbyfield(flag + \"==chaomanAndWomenInforeduce\"); String type = HbaseUtil.getdata(tablename, rowkey, famliyname, colum); if (StringUtils.isNotBlank(type) &amp;&amp; !type.equals(flag)) &#123; ChaomanAndWomenInfo chaomanAndWomenInfopre = new ChaomanAndWomenInfo(); chaomanAndWomenInfopre.setChaotype(type); chaomanAndWomenInfopre.setCount(-1l); chaomanAndWomenInfopre.setGroupbyfield(type + \"==chaomanAndWomenInforeduce\"); collector.collect(chaomanAndWomenInfopre); &#125; HbaseUtil.putdata(tablename, rowkey, famliyname, colum, flag); collector.collect(chaomanAndWomenInfotemp); &#125; &#125; &#125;&#125; 添加reduce统计类1234567891011121314151617181920212223242526import com.youfan.entity.BrandLike;import com.youfan.entity.ChaomanAndWomenInfo;import org.apache.flink.api.common.functions.ReduceFunction;import java.util.List;/** * Created by li on 2019/1/6. */public class ChaomanandwomenReduce implements ReduceFunction&lt;ChaomanAndWomenInfo&gt; &#123; @Override public ChaomanAndWomenInfo reduce(ChaomanAndWomenInfo chaomanAndWomenInfo1, ChaomanAndWomenInfo chaomanAndWomenInfo2) throws Exception &#123; String userid = chaomanAndWomenInfo1.getUserid(); List&lt;ChaomanAndWomenInfo&gt; list1 = chaomanAndWomenInfo1.getList(); List&lt;ChaomanAndWomenInfo&gt; list2 = chaomanAndWomenInfo2.getList(); list1.addAll(list2); ChaomanAndWomenInfo chaomanAndWomenInfofinal = new ChaomanAndWomenInfo(); chaomanAndWomenInfofinal.setUserid(userid); chaomanAndWomenInfofinal.setList(list1); return chaomanAndWomenInfofinal; &#125;&#125; 1234567891011121314151617181920212223242526import com.youfan.entity.ChaomanAndWomenInfo;import com.youfan.entity.EmaiInfo;import org.apache.flink.api.common.functions.ReduceFunction;/** * Created by li on 2019/1/5. */public class ChaomanwomenfinalReduce implements ReduceFunction&lt;ChaomanAndWomenInfo&gt;&#123; @Override public ChaomanAndWomenInfo reduce(ChaomanAndWomenInfo chaomanAndWomenInfo1, ChaomanAndWomenInfo chaomanAndWomenInfo2) throws Exception &#123; String chaotype = chaomanAndWomenInfo1.getChaotype(); long count1 = chaomanAndWomenInfo1.getCount(); long count2 = chaomanAndWomenInfo2.getCount(); ChaomanAndWomenInfo finalchao = new ChaomanAndWomenInfo(); finalchao.setChaotype(chaotype); finalchao.setCount(count1+count2); return finalchao; &#125;&#125; 添加flink实时计算类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import com.youfan.entity.ChaomanAndWomenInfo;import com.youfan.kafka.KafkaEvent;import com.youfan.kafka.KafkaEventSchema;import com.youfan.map.*;import com.youfan.reduce.*;import org.apache.flink.api.common.restartstrategy.RestartStrategies;import org.apache.flink.api.java.utils.ParameterTool;import org.apache.flink.streaming.api.TimeCharacteristic;import org.apache.flink.streaming.api.datastream.DataStream;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;import org.apache.flink.streaming.api.functions.AssignerWithPeriodicWatermarks;import org.apache.flink.streaming.api.watermark.Watermark;import org.apache.flink.streaming.api.windowing.time.Time;import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer010;import javax.annotation.Nullable;/** * Created by li on 2019/1/6. */public class ChaomanandwomenTask &#123; public static void main(String[] args) &#123; // parse input arguments args = new String[]&#123;\"--input-topic\",\"scanProductLog\",\"--bootstrap.servers\",\"192.168.80.134:9092\",\"--zookeeper.connect\",\"192.168.80.134:2181\",\"--group.id\",\"youfan\"&#125;; final ParameterTool parameterTool = ParameterTool.fromArgs(args);// if (parameterTool.getNumberOfParameters() &lt; 5) &#123;// System.out.println(\"Missing parameters!\\n\" +// \"Usage: Kafka --input-topic &lt;topic&gt; --output-topic &lt;topic&gt; \" +// \"--bootstrap.servers &lt;kafka brokers&gt; \" +// \"--zookeeper.connect &lt;zk quorum&gt; --group.id &lt;some id&gt;\");// return;// &#125; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.getConfig().disableSysoutLogging(); env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(4, 10000)); env.enableCheckpointing(5000); // create a checkpoint every 5 seconds env.getConfig().setGlobalJobParameters(parameterTool); // make parameters available in the web interface env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime); DataStream&lt;KafkaEvent&gt; input = env .addSource( new FlinkKafkaConsumer010&lt;&gt;( parameterTool.getRequired(\"input-topic\"), new KafkaEventSchema(), parameterTool.getProperties()) .assignTimestampsAndWatermarks(new CustomWatermarkExtractor())); DataStream&lt;ChaomanAndWomenInfo&gt; chaomanAndWomenMap = input.flatMap(new ChaomanAndwomenMap()); DataStream&lt;ChaomanAndWomenInfo&gt; chaomanAndWomenReduce = chaomanAndWomenMap.keyBy(\"groupbyfield\").timeWindowAll(Time.seconds(2)).reduce(new ChaomanandwomenReduce()).flatMap(new ChaomanAndwomenbyreduceMap()); DataStream&lt;ChaomanAndWomenInfo&gt; chaomanAndWomenReducefinal = chaomanAndWomenReduce.keyBy(\"groupbyfield\").reduce(new ChaomanwomenfinalReduce()); chaomanAndWomenReducefinal.addSink(new ChaoManAndWomenSink()); try &#123; env.execute(\"ChaomanandwomenTask analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static class CustomWatermarkExtractor implements AssignerWithPeriodicWatermarks&lt;KafkaEvent&gt; &#123; private static final long serialVersionUID = -742759155861320823L; private long currentTimestamp = Long.MIN_VALUE; @Override public long extractTimestamp(KafkaEvent event, long previousElementTimestamp) &#123; // the inputs are assumed to be of format (message,timestamp) this.currentTimestamp = event.getTimestamp(); return event.getTimestamp(); &#125; @Nullable @Override public Watermark getCurrentWatermark() &#123; return new Watermark(currentTimestamp == Long.MIN_VALUE ? Long.MIN_VALUE : currentTimestamp - 1); &#125; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十五)flink分布式kmeans实现用户分群","slug":"ceshi20","date":"2020-03-29T14:49:56.000Z","updated":"2020-03-29T15:37:22.144Z","comments":true,"path":"2020/03/29/ceshi20/","link":"","permalink":"https://etop.work/2020/03/29/ceshi20/","excerpt":"添加实体类","text":"添加实体类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217import java.util.HashMap;import java.util.List;import java.util.Map;/** * Created by li on 2019/1/5. */public class UserGroupInfo &#123; private String userid; private String createtime; private String amount ; private String paytype ; private String paytime; private String paystatus;//0、未支付 1、已支付 2、已退款 private String couponamount; private String totalamount; private String refundamount; private Long count;//数量 private String producttypeid;//消费类目 private String groupfield;//分组 private List&lt;UserGroupInfo&gt; list;//一个用户所有的消费信息 private double avramout;//平均消费金额 private double maxamout;//消费最大金额 private int days;//消费频次 private Long buytype1;//消费类目1数量 private Long buytype2;//消费类目2数量 private Long buytype3;//消费类目3数量 private Long buytime1;//消费时间点1数量 private Long buytime2;//消费时间点2数量 private Long buytime3;//消费时间点3数量 private Long buytime4;//消费时间点4数量 public String getUserid() &#123; return userid; &#125; public void setUserid(String userid) &#123; this.userid = userid; &#125; public String getCreatetime() &#123; return createtime; &#125; public void setCreatetime(String createtime) &#123; this.createtime = createtime; &#125; public String getAmount() &#123; return amount; &#125; public void setAmount(String amount) &#123; this.amount = amount; &#125; public String getPaytype() &#123; return paytype; &#125; public void setPaytype(String paytype) &#123; this.paytype = paytype; &#125; public String getPaytime() &#123; return paytime; &#125; public void setPaytime(String paytime) &#123; this.paytime = paytime; &#125; public String getPaystatus() &#123; return paystatus; &#125; public void setPaystatus(String paystatus) &#123; this.paystatus = paystatus; &#125; public String getCouponamount() &#123; return couponamount; &#125; public void setCouponamount(String couponamount) &#123; this.couponamount = couponamount; &#125; public String getTotalamount() &#123; return totalamount; &#125; public void setTotalamount(String totalamount) &#123; this.totalamount = totalamount; &#125; public String getRefundamount() &#123; return refundamount; &#125; public void setRefundamount(String refundamount) &#123; this.refundamount = refundamount; &#125; public Long getCount() &#123; return count; &#125; public void setCount(Long count) &#123; this.count = count; &#125; public String getProducttypeid() &#123; return producttypeid; &#125; public void setProducttypeid(String producttypeid) &#123; this.producttypeid = producttypeid; &#125; public String getGroupfield() &#123; return groupfield; &#125; public void setGroupfield(String groupfield) &#123; this.groupfield = groupfield; &#125; public List&lt;UserGroupInfo&gt; getList() &#123; return list; &#125; public void setList(List&lt;UserGroupInfo&gt; list) &#123; this.list = list; &#125; public double getAvramout() &#123; return avramout; &#125; public void setAvramout(double avramout) &#123; this.avramout = avramout; &#125; public double getMaxamout() &#123; return maxamout; &#125; public void setMaxamout(double maxamout) &#123; this.maxamout = maxamout; &#125; public int getDays() &#123; return days; &#125; public void setDays(int days) &#123; this.days = days; &#125; public Long getBuytype1() &#123; return buytype1; &#125; public void setBuytype1(Long buytype1) &#123; this.buytype1 = buytype1; &#125; public Long getBuytype2() &#123; return buytype2; &#125; public void setBuytype2(Long buytype2) &#123; this.buytype2 = buytype2; &#125; public Long getBuytype3() &#123; return buytype3; &#125; public void setBuytype3(Long buytype3) &#123; this.buytype3 = buytype3; &#125; public Long getBuytime1() &#123; return buytime1; &#125; public void setBuytime1(Long buytime1) &#123; this.buytime1 = buytime1; &#125; public Long getBuytime2() &#123; return buytime2; &#125; public void setBuytime2(Long buytime2) &#123; this.buytime2 = buytime2; &#125; public Long getBuytime3() &#123; return buytime3; &#125; public void setBuytime3(Long buytime3) &#123; this.buytime3 = buytime3; &#125; public Long getBuytime4() &#123; return buytime4; &#125; public void setBuytime4(Long buytime4) &#123; this.buytime4 = buytime4; &#125;&#125; 添加map数据处理类1234567891011121314151617181920212223242526272829import com.youfan.logic.LogicInfo;import org.apache.commons.lang3.StringUtils;import org.apache.flink.api.common.functions.MapFunction;import java.util.Random;/** * Created by li on 2019/1/5. */public class KMeansMap implements MapFunction&lt;String, KMeans&gt;&#123; @Override public KMeans map(String s) throws Exception &#123; if(StringUtils.isBlank(s))&#123; return null; &#125; //2,3,4 Random random = new Random(); String [] temps = s.split(\",\"); String variable1 = temps[0]; String variable2 = temps[1]; String variable3 = temps[2]; KMeans kMeans = new KMeans(); kMeans.setVariable1(variable1); kMeans.setVariable2(variable2); kMeans.setVariable3(variable3); kMeans.setGroupbyfield(\"logic==\"+random.nextInt(10)); return kMeans; &#125;&#125; 添加reduce统计计算类123456789101112131415161718192021222324252627282930313233import com.youfan.logic.CreateDataSet;import com.youfan.logic.LogicInfo;import com.youfan.logic.Logistic;import org.apache.flink.api.common.functions.GroupReduceFunction;import org.apache.flink.util.Collector;import java.util.ArrayList;import java.util.Iterator;import java.util.Set;/** * Created by li on 2019/1/6. */public class KMeansReduce implements GroupReduceFunction&lt;KMeans,ArrayList&lt;Point&gt;&gt; &#123; @Override public void reduce(Iterable&lt;KMeans&gt; iterable, Collector&lt;ArrayList&lt;Point&gt;&gt; collector) throws Exception &#123; Iterator&lt;KMeans&gt; iterator = iterable.iterator(); ArrayList&lt;float[]&gt; dataSet = new ArrayList&lt;float[]&gt;(); while(iterator.hasNext())&#123; KMeans kMeans = iterator.next(); float[] f = new float[]&#123;Float.valueOf(kMeans.getVariable1()),Float.valueOf(kMeans.getVariable2()),Float.valueOf(kMeans.getVariable3())&#125;; dataSet.add(f); &#125; KMeansRun kRun =new KMeansRun(6, dataSet); Set&lt;Cluster&gt; clusterSet = kRun.run(); ArrayList&lt;Point&gt; arrayList = new ArrayList&lt;Point&gt;(); for(Cluster cluster:clusterSet)&#123; arrayList.add(cluster.getCenter()); &#125; collector.collect(arrayList); &#125;&#125; 添加Flink 计算类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import com.youfan.logic.LogicInfo;import com.youfan.logic.LogicMap;import com.youfan.logic.LogicReduce;import org.apache.flink.api.common.io.FileOutputFormat;import org.apache.flink.api.common.io.OutputFormat;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.utils.ParameterTool;import org.apache.flink.configuration.Configuration;import java.io.IOException;import java.util.*;/** * Created by li on 2019/1/6. */public class KMeansTask &#123; public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); // set up the execution environment final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataSet&lt;String&gt; text = env.readTextFile(params.get(\"input\")); DataSet&lt;KMeans&gt; mapresult = text.map(new KMeansMap()); DataSet&lt;ArrayList&lt;Point&gt;&gt; reduceresutl = mapresult.groupBy(\"groupbyfield\").reduceGroup(new KMeansReduce()); try &#123; List&lt;ArrayList&lt;Point&gt;&gt; reusltlist = reduceresutl.collect(); ArrayList&lt;float[]&gt; dataSet = new ArrayList&lt;float[]&gt;(); for(ArrayList&lt;Point&gt; array:reusltlist)&#123; for(Point point:array)&#123; dataSet.add(point.getlocalArray()); &#125; &#125; KMeansRun kRun =new KMeansRun(6, dataSet); Set&lt;Cluster&gt; clusterSet = kRun.run(); List&lt;Point&gt; finalClutercenter = new ArrayList&lt;Point&gt;(); int count= 100; for(Cluster cluster:clusterSet)&#123; Point point = cluster.getCenter(); point.setId(count++); finalClutercenter.add(point); &#125; DataSet&lt;Point&gt; flinalMap = text.map(new KMeansFinalMap(finalClutercenter)); flinalMap.writeAsText(params.get(\"out\")); env.execute(\"KmeansTask analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 添加最终map类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import com.youfan.logic.LogicInfo;import com.youfan.logic.LogicMap;import com.youfan.logic.LogicReduce;import org.apache.flink.api.common.io.FileOutputFormat;import org.apache.flink.api.common.io.OutputFormat;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.utils.ParameterTool;import org.apache.flink.configuration.Configuration;import java.io.IOException;import java.util.*;/** * Created by li on 2019/1/6. */public class KMeansTask &#123; public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); // set up the execution environment final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataSet&lt;String&gt; text = env.readTextFile(params.get(\"input\")); DataSet&lt;KMeans&gt; mapresult = text.map(new KMeansMap()); DataSet&lt;ArrayList&lt;Point&gt;&gt; reduceresutl = mapresult.groupBy(\"groupbyfield\").reduceGroup(new KMeansReduce()); try &#123; List&lt;ArrayList&lt;Point&gt;&gt; reusltlist = reduceresutl.collect(); ArrayList&lt;float[]&gt; dataSet = new ArrayList&lt;float[]&gt;(); for(ArrayList&lt;Point&gt; array:reusltlist)&#123; for(Point point:array)&#123; dataSet.add(point.getlocalArray()); &#125; &#125; KMeansRun kRun =new KMeansRun(6, dataSet); Set&lt;Cluster&gt; clusterSet = kRun.run(); List&lt;Point&gt; finalClutercenter = new ArrayList&lt;Point&gt;(); int count= 100; for(Cluster cluster:clusterSet)&#123; Point point = cluster.getCenter(); point.setId(count++); finalClutercenter.add(point); &#125; DataSet&lt;Point&gt; flinalMap = text.map(new KMeansFinalMap(finalClutercenter)); flinalMap.writeAsText(params.get(\"out\")); env.execute(\"KmeansTask analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十四)kmeans之原理和代码编写","slug":"ceshi19","date":"2020-03-29T13:58:00.000Z","updated":"2020-03-29T14:49:34.764Z","comments":true,"path":"2020/03/29/ceshi19/","link":"","permalink":"https://etop.work/2020/03/29/ceshi19/","excerpt":"聚类原理 代码编写代码说明： 测试数据的输入维度必须都相等才能运行！ [1,2,3,3]和[2,3,4,4] 这样维度相同，都是4维，可以运行。 [1,2,3,3]和[2,3,4] 这样维度不相同，不能运行。 输入数据的点，尽量不要重复！ 输入的数据点[1,2,3]和[1,2,3] 这样的数据点是重复的。可以运行，但是性能会下降。 分装Point类","text":"聚类原理 代码编写代码说明： 测试数据的输入维度必须都相等才能运行！ [1,2,3,3]和[2,3,4,4] 这样维度相同，都是4维，可以运行。 [1,2,3,3]和[2,3,4] 这样维度不相同，不能运行。 输入数据的点，尽量不要重复！ 输入的数据点[1,2,3]和[1,2,3] 这样的数据点是重复的。可以运行，但是性能会下降。 分装Point类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class Point &#123; private float[] localArray; private int id; private int clusterId; // 标识属于哪个类中心。 private float dist; // 标识和所属类中心的距离。 public Point(int id, float[] localArray) &#123; this.id = id; this.localArray = localArray; &#125; public Point(float[] localArray) &#123; this.id = -1; //表示不属于任意一个类 this.localArray = localArray; &#125; public float[] getlocalArray() &#123; return localArray; &#125; public int getId() &#123; return id; &#125; public void setClusterId(int clusterId) &#123; this.clusterId = clusterId; &#125; public int getClusterid() &#123; return clusterId; &#125; public float getDist() &#123; return dist; &#125; public void setDist(float dist) &#123; this.dist = dist; &#125; @Override public String toString() &#123; String result = \"Point_id=\" + id + \" [\"; for (int i = 0; i &lt; localArray.length; i++) &#123; result += localArray[i] + \" \"; &#125; return result.trim()+\"] clusterId: \"+clusterId+\" dist: \"+dist; &#125; @Override public boolean equals(Object obj) &#123; if (obj == null || getClass() != obj.getClass()) return false; Point point = (Point) obj; if (point.localArray.length != localArray.length) return false; for (int i = 0; i &lt; localArray.length; i++) &#123; if (Float.compare(point.localArray[i], localArray[i]) != 0) &#123; return false; &#125; &#125; return true; &#125; @Override public int hashCode() &#123; float x = localArray[0]; float y = localArray[localArray.length - 1]; long temp = x != +0.0d ? Double.doubleToLongBits(x) : 0L; int result = (int) (temp ^ (temp &gt;&gt;&gt; 32)); temp = y != +0.0d ? Double.doubleToLongBits(y) : 0L; result = 31 * result + (int) (temp ^ (temp &gt;&gt;&gt; 32)); return result; &#125;&#125; 封装Cluster 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.util.ArrayList;import java.util.List;public class Cluster &#123; private int id;// 标识 private Point center;// 中心 private List&lt;Point&gt; members = new ArrayList&lt;Point&gt;();// 成员 public Cluster(int id, Point center) &#123; this.id = id; this.center = center; &#125; public Cluster(int id, Point center, List&lt;Point&gt; members) &#123; this.id = id; this.center = center; this.members = members; &#125; public void addPoint(Point newPoint) &#123; if (!members.contains(newPoint))&#123; members.add(newPoint); &#125;else&#123; System.out.println(\"样本数据点 &#123;\"+newPoint.toString()+\"&#125; 已经存在！\"); &#125; &#125; public int getId() &#123; return id; &#125; public Point getCenter() &#123; return center; &#125; public void setCenter(Point center) &#123; this.center = center; &#125; public List&lt;Point&gt; getMembers() &#123; return members; &#125; @Override public String toString() &#123; String toString = \"Cluster \\n\" + \"Cluster_id=\" + this.id + \", center:&#123;\" + this.center.toString()+\"&#125;\"; for (Point point : members) &#123; toString+=\"\\n\"+point.toString(); &#125; return toString+\"\\n\"; &#125;&#125; 求两个点的欧式距离 1234567891011121314151617181920public class DistanceCompute &#123; /** * 求欧式距离 */ public double getEuclideanDis(Point p1, Point p2) &#123; double count_dis = 0; float[] p1_local_array = p1.getlocalArray(); float[] p2_local_array = p2.getlocalArray(); if (p1_local_array.length != p2_local_array.length) &#123; throw new IllegalArgumentException(\"length of array must be equal!\"); &#125; for (int i = 0; i &lt; p1_local_array.length; i++) &#123; count_dis += Math.pow(p1_local_array[i] - p2_local_array[i], 2); &#125; return Math.sqrt(count_dis); &#125;&#125; 核心运行类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152import java.util.ArrayList;import java.util.HashSet;import java.util.List;import java.util.Random;import java.util.Set;public class KMeansRun &#123; private int kNum; //簇的个数 private int iterNum = 10; //迭代次数 private int iterMaxTimes = 100000; //单次迭代最大运行次数 private int iterRunTimes = 0; //单次迭代实际运行次数 private float disDiff = (float) 0.01; //单次迭代终止条件，两次运行中类中心的距离差 private List&lt;float[]&gt; original_data =null; //用于存放，原始数据集 private static List&lt;Point&gt; pointList = null; //用于存放，原始数据集所构建的点集 private DistanceCompute disC = new DistanceCompute(); private int len = 0; //用于记录每个数据点的维度 public KMeansRun(int k, List&lt;float[]&gt; original_data) &#123; this.kNum = k; this.original_data = original_data; this.len = original_data.get(0).length; //检查规范 check(); //初始化点集。 init(); &#125; /** * 检查规范 */ private void check() &#123; if (kNum == 0)&#123; throw new IllegalArgumentException(\"k must be the number &gt; 0\"); &#125; if (original_data == null)&#123; throw new IllegalArgumentException(\"program can't get real data\"); &#125; &#125; /** * 初始化数据集，把数组转化为Point类型。 */ private void init() &#123; pointList = new ArrayList&lt;Point&gt;(); for (int i = 0, j = original_data.size(); i &lt; j; i++)&#123; pointList.add(new Point(i, original_data.get(i))); &#125; &#125; /** * 随机选取中心点，构建成中心类。 */ private Set&lt;Cluster&gt; chooseCenterCluster() &#123; Set&lt;Cluster&gt; clusterSet = new HashSet&lt;Cluster&gt;(); Random random = new Random(); for (int id = 0; id &lt; kNum; ) &#123; Point point = pointList.get(random.nextInt(pointList.size())); // 用于标记是否已经选择过该数据。 boolean flag =true; for (Cluster cluster : clusterSet) &#123; if (cluster.getCenter().equals(point)) &#123; flag = false; &#125; &#125; // 如果随机选取的点没有被选中过，则生成一个cluster if (flag) &#123; Cluster cluster =new Cluster(id, point); clusterSet.add(cluster); id++; &#125; &#125; return clusterSet; &#125; /** * 为每个点分配一个类！ */ public void cluster(Set&lt;Cluster&gt; clusterSet)&#123; // 计算每个点到K个中心的距离，并且为每个点标记类别号 for (Point point : pointList) &#123; float min_dis = Integer.MAX_VALUE; for (Cluster cluster : clusterSet) &#123; float tmp_dis = (float) Math.min(disC.getEuclideanDis(point, cluster.getCenter()), min_dis); if (tmp_dis != min_dis) &#123; min_dis = tmp_dis; point.setClusterId(cluster.getId()); point.setDist(min_dis); &#125; &#125; &#125; // 新清除原来所有的类中成员。把所有的点，分别加入每个类别 for (Cluster cluster : clusterSet) &#123; cluster.getMembers().clear(); for (Point point : pointList) &#123; if (point.getClusterid()==cluster.getId()) &#123; cluster.addPoint(point); &#125; &#125; &#125; &#125; /** * 计算每个类的中心位置！ */ public boolean calculateCenter(Set&lt;Cluster&gt; clusterSet) &#123; boolean ifNeedIter = false; for (Cluster cluster : clusterSet) &#123; List&lt;Point&gt; point_list = cluster.getMembers(); float[] sumAll =new float[len]; // 所有点，对应各个维度进行求和 for (int i = 0; i &lt; len; i++) &#123; for (int j = 0; j &lt; point_list.size(); j++) &#123; sumAll[i] += point_list.get(j).getlocalArray()[i]; &#125; &#125; // 计算平均值 for (int i = 0; i &lt; sumAll.length; i++) &#123; sumAll[i] = (float) sumAll[i]/point_list.size(); &#125; // 计算两个新、旧中心的距离，如果任意一个类中心移动的距离大于dis_diff则继续迭代。 if(disC.getEuclideanDis(cluster.getCenter(), new Point(sumAll)) &gt; disDiff)&#123; ifNeedIter = true; &#125; // 设置新的类中心位置 cluster.setCenter(new Point(sumAll)); &#125; return ifNeedIter; &#125; /** * 运行 k-means */ public Set&lt;Cluster&gt; run() &#123; Set&lt;Cluster&gt; clusterSet= chooseCenterCluster(); boolean ifNeedIter = true; while (ifNeedIter) &#123; cluster(clusterSet); ifNeedIter = calculateCenter(clusterSet); iterRunTimes ++ ; &#125; return clusterSet; &#125; /** * 返回实际运行次数 */ public int getIterTimes() &#123; return iterRunTimes; &#125;&#125; 测试类 12345678910111213141516171819202122232425262728293031import java.util.ArrayList;import java.util.Set;public class Main &#123; public static void main(String[] args) &#123; ArrayList&lt;float[]&gt; dataSet = new ArrayList&lt;float[]&gt;(); dataSet.add(new float[] &#123; 1, 2, 3 &#125;); dataSet.add(new float[] &#123; 3, 3, 3 &#125;); dataSet.add(new float[] &#123; 3, 4, 4&#125;); dataSet.add(new float[] &#123; 5, 6, 5&#125;); dataSet.add(new float[] &#123; 8, 9, 6&#125;); dataSet.add(new float[] &#123; 4, 5, 4&#125;); dataSet.add(new float[] &#123; 6, 4, 2&#125;); dataSet.add(new float[] &#123; 3, 9, 7&#125;); dataSet.add(new float[] &#123; 5, 9, 8&#125;); dataSet.add(new float[] &#123; 4, 2, 10&#125;); dataSet.add(new float[] &#123; 1, 9, 12&#125;); dataSet.add(new float[] &#123; 7, 8, 112&#125;); dataSet.add(new float[] &#123; 7, 8, 4&#125;); KMeansRun kRun =new KMeansRun(3, dataSet); Set&lt;Cluster&gt; clusterSet = kRun.run(); System.out.println(\"单次迭代运行次数：\"+kRun.getIterTimes()); for (Cluster cluster : clusterSet) &#123; System.out.println(cluster); &#125; &#125;&#125; 关于输入数据和运行结果这里故意加入了一个异常点[7 , 8 ,112]进行测试，果然独自分为一类：","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十三)逻辑回归预测性别","slug":"ceshi18","date":"2020-03-29T07:56:42.000Z","updated":"2020-03-29T08:50:21.163Z","comments":true,"path":"2020/03/29/ceshi18/","link":"","permalink":"https://etop.work/2020/03/29/ceshi18/","excerpt":"用到的部分维度用户id 订单次数 订单频次 浏览男装 浏览小孩 浏览女士 订单平均金额 浏览商品频次 标签","text":"用到的部分维度用户id 订单次数 订单频次 浏览男装 浏览小孩 浏览女士 订单平均金额 浏览商品频次 标签 添加实体类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107public class SexPreInfo &#123; /** * 用户id 订单次数 订单频次 浏览男装 * 浏览小孩 浏览老人 浏览女士 订单平均金额 浏览商品频次 标签 */ private int userid; private long ordernum;//订单的总数 private long orderfre;//隔多少天下单 private int manclothes;//浏览男装次数 private int womenclothes;//浏览女装的次数 private int childclothes;//浏览小孩衣服的次数 private int oldmanclothes;//浏览老人的衣服的次数 private double avramount;//订单平均金额 private int producttimes;//每天浏览商品数 private int label;//男，女 private String groupfield;//分组 public String getGroupfield() &#123; return groupfield; &#125; public void setGroupfield(String groupfield) &#123; this.groupfield = groupfield; &#125; public int getUserid() &#123; return userid; &#125; public void setUserid(int userid) &#123; this.userid = userid; &#125; public long getOrdernum() &#123; return ordernum; &#125; public void setOrdernum(long ordernum) &#123; this.ordernum = ordernum; &#125; public long getOrderfre() &#123; return orderfre; &#125; public void setOrderfre(long orderfre) &#123; this.orderfre = orderfre; &#125; public int getManclothes() &#123; return manclothes; &#125; public void setManclothes(int manclothes) &#123; this.manclothes = manclothes; &#125; public int getWomenclothes() &#123; return womenclothes; &#125; public void setWomenclothes(int womenclothes) &#123; this.womenclothes = womenclothes; &#125; public int getChildclothes() &#123; return childclothes; &#125; public void setChildclothes(int childclothes) &#123; this.childclothes = childclothes; &#125; public int getOldmanclothes() &#123; return oldmanclothes; &#125; public void setOldmanclothes(int oldmanclothes) &#123; this.oldmanclothes = oldmanclothes; &#125; public double getAvramount() &#123; return avramount; &#125; public void setAvramount(double avramount) &#123; this.avramount = avramount; &#125; public int getProducttimes() &#123; return producttimes; &#125; public void setProducttimes(int producttimes) &#123; this.producttimes = producttimes; &#125; public int getLabel() &#123; return label; &#125; public void setLabel(int label) &#123; this.label = label; &#125;&#125; 添加map数据处理类1234567891011121314151617181920212223242526272829303132333435/** * Created by li on 2019/1/6. */public class SexPreMap implements MapFunction&lt;String, SexPreInfo&gt; &#123; @Override public SexPreInfo map(String s) throws Exception &#123; String[] temps = s.split(\"\\t\"); Random random = new Random(); //清洗以及归一化 int userid = Integer.valueOf(temps[0]); long ordernum = Long.valueOf(temps[1]);//订单的总数 long orderfre = Long.valueOf(temps[4]);//隔多少天下单 int manclothes =Integer.valueOf(temps[5]);//浏览男装次数 int womenclothes = Integer.valueOf(temps[6]);//浏览女装的次数 int childclothes = Integer.valueOf(temps[7]);//浏览小孩衣服的次数 int oldmanclothes = Integer.valueOf(temps[8]);//浏览老人的衣服的次数 double avramount = Double.valueOf(temps[9]);//订单平均金额 int producttimes = Integer.valueOf(temps[10]);//每天浏览商品数 int label = Integer.valueOf(temps[11]);//0男，1女 String fieldgroup = \"sexpre==\"+random.nextInt(10); SexPreInfo sexPreInfo = new SexPreInfo(); sexPreInfo.setUserid(userid); sexPreInfo.setOrdernum(ordernum); sexPreInfo.setOrderfre(orderfre); sexPreInfo.setManclothes(manclothes); sexPreInfo.setWomenclothes(womenclothes); sexPreInfo.setChildclothes(childclothes); sexPreInfo.setOldmanclothes(oldmanclothes); sexPreInfo.setAvramount(avramount); sexPreInfo.setProducttimes(producttimes); sexPreInfo.setLabel(label); sexPreInfo.setGroupfield(fieldgroup); return sexPreInfo; &#125;&#125; 添加map save预测类保存结果到Hbase 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import com.youfan.entity.SexPreInfo;import com.youfan.logic.Logistic;import com.youfan.util.HbaseUtil;import org.apache.flink.api.common.functions.MapFunction;import java.util.ArrayList;import java.util.Random;/** * Created by li on 2019/1/6. */public class SexPresaveMap implements MapFunction&lt;String, SexPreInfo&gt; &#123; private ArrayList&lt;Double&gt; weights = null; public SexPresaveMap(ArrayList&lt;Double&gt; weights)&#123; this.weights = weights; &#125; @Override public SexPreInfo map(String s) throws Exception &#123; String[] temps = s.split(\"\\t\"); Random random = new Random(); //清洗以及归一化 int userid = Integer.valueOf(temps[0]); long ordernum = Long.valueOf(temps[1]);//订单的总数 long orderfre = Long.valueOf(temps[4]);//隔多少天下单 int manclothes =Integer.valueOf(temps[5]);//浏览男装次数 int womenclothes = Integer.valueOf(temps[6]);//浏览女装的次数 int childclothes = Integer.valueOf(temps[7]);//浏览小孩衣服的次数 int oldmanclothes = Integer.valueOf(temps[8]);//浏览老人的衣服的次数 double avramount = Double.valueOf(temps[9]);//订单平均金额 int producttimes = Integer.valueOf(temps[10]);//每天浏览商品数 ArrayList&lt;String&gt; as = new ArrayList&lt;String&gt;(); as.add(ordernum+\"\"); as.add(orderfre+\"\"); as.add(manclothes+\"\"); as.add(womenclothes+\"\"); as.add(childclothes+\"\"); as.add(oldmanclothes+\"\"); as.add(avramount+\"\"); as.add(producttimes+\"\"); String sexflag = Logistic.classifyVector(as, weights); String sexstring = sexflag==\"0\"?\"女\":\"男\"; String tablename = \"userflaginfo\"; String rowkey = userid+\"\"; String famliyname = \"baseinfo\"; String colum = \"sex\";//运营商 HbaseUtil.putdata(tablename,rowkey,famliyname,colum,sexstring); return null; &#125;&#125; 添加reduce类计算得到权重系数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import com.youfan.entity.SexPreInfo;import com.youfan.logic.CreateDataSet;import com.youfan.logic.LogicInfo;import com.youfan.logic.Logistic;import org.apache.flink.api.common.functions.GroupReduceFunction;import org.apache.flink.util.Collector;import java.util.ArrayList;import java.util.Iterator;/** * Created by li on 2019/1/6. */public class SexpreReduce implements GroupReduceFunction&lt;SexPreInfo,ArrayList&lt;Double&gt;&gt; &#123; @Override public void reduce(Iterable&lt;SexPreInfo&gt; iterable, Collector&lt;ArrayList&lt;Double&gt;&gt; collector) throws Exception &#123; Iterator&lt;SexPreInfo&gt; iterator = iterable.iterator(); CreateDataSet trainingSet = new CreateDataSet(); while(iterator.hasNext())&#123; SexPreInfo sexPreInfo = iterator.next(); int userid = sexPreInfo.getUserid(); long ordernum = sexPreInfo.getOrdernum();//订单的总数 long orderfre = sexPreInfo.getOrderfre();//隔多少天下单 int manclothes = sexPreInfo.getManclothes();//浏览男装次数 int womenclothes = sexPreInfo.getWomenclothes();//浏览女装的次数 int childclothes = sexPreInfo.getChildclothes();//浏览小孩衣服的次数 int oldmanclothes = sexPreInfo.getOldmanclothes();//浏览老人的衣服的次数 double avramount = sexPreInfo.getAvramount();//订单平均金额 int producttimes = sexPreInfo.getProducttimes();//每天浏览商品数 int label = sexPreInfo.getLabel();//0男，1女 ArrayList&lt;String&gt; as = new ArrayList&lt;String&gt;(); as.add(ordernum+\"\"); as.add(orderfre+\"\"); as.add(manclothes+\"\"); as.add(womenclothes+\"\"); as.add(childclothes+\"\"); as.add(oldmanclothes+\"\"); as.add(avramount+\"\"); as.add(producttimes+\"\"); trainingSet.data.add(as); trainingSet.labels.add(label+\"\"); &#125; ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); weights = Logistic.gradAscent1(trainingSet, trainingSet.labels, 500); collector.collect(weights); &#125;&#125; 添加Flink 任务计算类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import com.youfan.entity.EmaiInfo;import com.youfan.entity.SexPreInfo;import com.youfan.map.EmailMap;import com.youfan.map.SexPreMap;import com.youfan.map.SexPresaveMap;import com.youfan.reduce.EmailReduce;import com.youfan.reduce.SexpreReduce;import com.youfan.util.MongoUtils;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.utils.ParameterTool;import org.bson.Document;import java.util.*;/** * Created by li on 2019/1/6. */public class SexPreTask &#123; public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); // set up the execution environment final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataSet&lt;String&gt; text = env.readTextFile(params.get(\"input\")); DataSet&lt;SexPreInfo&gt; mapresult = text.map(new SexPreMap()); DataSet&lt;ArrayList&lt;Double&gt;&gt; reduceresutl = mapresult.groupBy(\"groupfield\").reduceGroup(new SexpreReduce()); try &#123; List&lt;ArrayList&lt;Double&gt;&gt; reusltlist = reduceresutl.collect(); int groupsize = reusltlist.size(); Map&lt;Integer,Double&gt; summap = new TreeMap&lt;Integer,Double&gt;(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;); for(ArrayList&lt;Double&gt; array:reusltlist)&#123; for(int i=0;i&lt;array.size();i++)&#123; double pre = summap.get(i)==null?0d:summap.get(i); summap.put(i,pre+array.get(i)); &#125; &#125; ArrayList&lt;Double&gt; finalweight = new ArrayList&lt;Double&gt;(); Set&lt;Map.Entry&lt;Integer,Double&gt;&gt; set = summap.entrySet(); for(Map.Entry&lt;Integer,Double&gt; mapentry :set)&#123; Integer key = mapentry.getKey(); Double sumvalue = mapentry.getValue(); double finalvalue = sumvalue/groupsize; finalweight.add(finalvalue); &#125; DataSet&lt;String&gt; text2 = env.readTextFile(params.get(\"input2\")); text2.map(new SexPresaveMap(finalweight)); env.execute(\"sexPreTask analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十二)java实现逻辑回归算法-代码编写","slug":"ceshi17","date":"2020-03-28T04:45:01.000Z","updated":"2020-03-29T07:48:21.610Z","comments":true,"path":"2020/03/28/ceshi17/","link":"","permalink":"https://etop.work/2020/03/28/ceshi17/","excerpt":"实体构建12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class LogicInfo &#123; private String variable1; private String variable2; private String variable3; private String labase; private String groupbyfield; public String getGroupbyfield() &#123; return groupbyfield; &#125; public void setGroupbyfield(String groupbyfield) &#123; this.groupbyfield = groupbyfield; &#125; public String getVariable1() &#123; return variable1; &#125; public void setVariable1(String variable1) &#123; this.variable1 = variable1; &#125; public String getVariable2() &#123; return variable2; &#125; public void setVariable2(String variable2) &#123; this.variable2 = variable2; &#125; public String getVariable3() &#123; return variable3; &#125; public void setVariable3(String variable3) &#123; this.variable3 = variable3; &#125; public String getLabase() &#123; return labase; &#125; public void setLabase(String labase) &#123; this.labase = labase; &#125; 矩阵","text":"实体构建12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class LogicInfo &#123; private String variable1; private String variable2; private String variable3; private String labase; private String groupbyfield; public String getGroupbyfield() &#123; return groupbyfield; &#125; public void setGroupbyfield(String groupbyfield) &#123; this.groupbyfield = groupbyfield; &#125; public String getVariable1() &#123; return variable1; &#125; public void setVariable1(String variable1) &#123; this.variable1 = variable1; &#125; public String getVariable2() &#123; return variable2; &#125; public void setVariable2(String variable2) &#123; this.variable2 = variable2; &#125; public String getVariable3() &#123; return variable3; &#125; public void setVariable3(String variable3) &#123; this.variable3 = variable3; &#125; public String getLabase() &#123; return labase; &#125; public void setLabase(String labase) &#123; this.labase = labase; &#125; 矩阵 12345678910111213141516import java.util.ArrayList;/** * @Description: [该类主要用于保存特征信息] * @parameter data: [主要保存特征矩阵] */public class Matrix &#123; public ArrayList&lt;ArrayList&lt;String&gt;&gt; data; public Matrix() &#123; data = new ArrayList&lt;ArrayList&lt;String&gt;&gt;(); &#125;&#125; 保存标签值123456789101112131415import java.util.ArrayList;/** * * @Description: [该类主要用于保存特征信息以及标签值] * @parameter labels: [主要保存标签值] */public class CreateDataSet extends Matrix &#123; public ArrayList&lt;String&gt; labels; public CreateDataSet() &#123; super(); labels = new ArrayList&lt;String&gt;(); &#125;&#125; 读取文件12345678910111213141516171819202122232425262728293031323334353637/** * @param fileName * 读入的文件名 * @return */ public static CreateDataSet readFile(String fileName) &#123; File file = new File(fileName); BufferedReader reader = null; CreateDataSet dataSet = new CreateDataSet(); try &#123; reader = new BufferedReader(new FileReader(file)); String tempString = null; // 一次读入一行，直到读入null为文件结束 while ((tempString = reader.readLine()) != null) &#123; // 显示行号 String[] strArr = tempString.split(\"\\t\"); ArrayList&lt;String&gt; as = new ArrayList&lt;String&gt;(); as.add(\"1\"); for (int i = 0; i &lt; strArr.length - 1; i++) &#123; as.add(strArr[i]); &#125; dataSet.data.add(as); dataSet.labels.add(strArr[strArr.length - 1]); &#125; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (reader != null) &#123; try &#123; reader.close(); &#125; catch (IOException e1) &#123; &#125; &#125; &#125; return dataSet; &#125; 逻辑回归算法代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220import java.io.BufferedReader;import java.io.File;import java.io.FileReader;import java.io.IOException;import java.util.ArrayList;public class Logistic &#123; public static void main(String[] args) &#123; colicTest(); &#125; /** */ public static void LogisticTest() &#123; // TODO Auto-generated method stub CreateDataSet dataSet = new CreateDataSet(); dataSet = readFile(\"testSet.txt\"); ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); weights = gradAscent1(dataSet, dataSet.labels, 150); for (int i = 0; i &lt; 3; i++) &#123; System.out.println(weights.get(i)); &#125; System.out.println(); &#125; /** * @param inX * @param weights * @return */ public static String classifyVector(ArrayList&lt;String&gt; inX, ArrayList&lt;Double&gt; weights) &#123; ArrayList&lt;Double&gt; sum = new ArrayList&lt;Double&gt;(); sum.clear(); sum.add(0.0); for (int i = 0; i &lt; inX.size(); i++) &#123; sum.set(0, sum.get(0) + Double.parseDouble(inX.get(i)) * weights.get(i)); &#125; if (sigmoid(sum).get(0) &gt; 0.5) return \"1\"; else return \"0\"; &#125; /** */ public static void colicTest() &#123; CreateDataSet trainingSet = new CreateDataSet(); CreateDataSet testSet = new CreateDataSet(); trainingSet = readFile(\"testTraining.txt\");// 23 445 34 1 45 56 67 0 testSet = readFile(\"Test.txt\");// 23 445 34 1 45 56 67 0 ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); weights = gradAscent1(trainingSet, trainingSet.labels, 500); int errorCount = 0; for (int i = 0; i &lt; testSet.data.size(); i++) &#123; if (!classifyVector(testSet.data.get(i), weights).equals(testSet.labels.get(i))) &#123; errorCount++; &#125; System.out.println(classifyVector(testSet.data.get(i), weights) + \",\" + testSet.labels.get(i)); &#125; System.out.println(1.0 * errorCount / testSet.data.size()); &#125; /** * @param inX * @return * @Description: [sigmod函数] */ public static ArrayList&lt;Double&gt; sigmoid(ArrayList&lt;Double&gt; inX) &#123; ArrayList&lt;Double&gt; inXExp = new ArrayList&lt;Double&gt;(); for (int i = 0; i &lt; inX.size(); i++) &#123; inXExp.add(1.0 / (1 + Math.exp(-inX.get(i)))); &#125; return inXExp; &#125; /** * @param dataSet * @param classLabels * @param numberIter * @return */ public static ArrayList&lt;Double&gt; gradAscent1(Matrix dataSet, ArrayList&lt;String&gt; classLabels, int numberIter) &#123; int m = dataSet.data.size(); int n = dataSet.data.get(0).size(); double alpha = 0.0; int randIndex = 0; ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; weightstmp = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; h = new ArrayList&lt;Double&gt;(); ArrayList&lt;Integer&gt; dataIndex = new ArrayList&lt;Integer&gt;(); ArrayList&lt;Double&gt; dataMatrixMulweights = new ArrayList&lt;Double&gt;(); for (int i = 0; i &lt; n; i++) &#123; weights.add(1.0); weightstmp.add(1.0); &#125; dataMatrixMulweights.add(0.0); double error = 0.0; for (int j = 0; j &lt; numberIter; j++) &#123; // 产生0到99的数组 for (int p = 0; p &lt; m; p++) &#123; dataIndex.add(p); &#125; // 进行每一次的训练 for (int i = 0; i &lt; m; i++) &#123; alpha = 4 / (1.0 + i + j) + 0.0001; randIndex = (int) (Math.random() * dataIndex.size()); dataIndex.remove(randIndex); double temp = 0.0; for (int k = 0; k &lt; n; k++) &#123; temp = temp + Double.parseDouble(dataSet.data.get(randIndex).get(k)) * weights.get(k); &#125; dataMatrixMulweights.set(0, temp); h = sigmoid(dataMatrixMulweights); error = Double.parseDouble(classLabels.get(randIndex)) - h.get(0); double tempweight = 0.0; for (int p = 0; p &lt; n; p++) &#123; tempweight = alpha * Double.parseDouble(dataSet.data.get(randIndex).get(p)) * error; weights.set(p, weights.get(p) + tempweight); &#125; &#125; &#125; return weights; &#125; /** * @param dataSet * @param classLabels * @return */ public static ArrayList&lt;Double&gt; gradAscent0(Matrix dataSet, ArrayList&lt;String&gt; classLabels) &#123; int m = dataSet.data.size(); int n = dataSet.data.get(0).size(); ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; weightstmp = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; h = new ArrayList&lt;Double&gt;(); double error = 0.0; ArrayList&lt;Double&gt; dataMatrixMulweights = new ArrayList&lt;Double&gt;(); double alpha = 0.01; for (int i = 0; i &lt; n; i++) &#123; weights.add(1.0); weightstmp.add(1.0); &#125; h.add(0.0); double temp = 0.0; dataMatrixMulweights.add(0.0); for (int i = 0; i &lt; m; i++) &#123; temp = 0.0; for (int k = 0; k &lt; n; k++) &#123; temp = temp + Double.parseDouble(dataSet.data.get(i).get(k)) * weights.get(k); &#125; dataMatrixMulweights.set(0, temp); h = sigmoid(dataMatrixMulweights); error = Double.parseDouble(classLabels.get(i)) - h.get(0); double tempweight = 0.0; for (int p = 0; p &lt; n; p++) &#123; tempweight = alpha * Double.parseDouble(dataSet.data.get(i).get(p)) * error; weights.set(p, weights.get(p) + tempweight); &#125; &#125; return weights; &#125; /** * @param dataSet * @param classLabels * @return */ public static ArrayList&lt;Double&gt; gradAscent(Matrix dataSet, ArrayList&lt;String&gt; classLabels) &#123; int m = dataSet.data.size(); int n = dataSet.data.get(0).size(); ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; weightstmp = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; h = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; error = new ArrayList&lt;Double&gt;(); ArrayList&lt;Double&gt; dataMatrixMulweights = new ArrayList&lt;Double&gt;(); double alpha = 0.001; int maxCycles = 500; for (int i = 0; i &lt; n; i++) &#123; weights.add(1.0); weightstmp.add(1.0); &#125; for (int i = 0; i &lt; m; i++) &#123; h.add(0.0); error.add(0.0); dataMatrixMulweights.add(0.0); &#125; double temp; for (int i = 0; i &lt; maxCycles; i++) &#123; for (int j = 0; j &lt; m; j++) &#123; temp = 0.0; for (int k = 0; k &lt; n; k++) &#123; temp = temp + Double.parseDouble(dataSet.data.get(j).get(k)) * weights.get(k); &#125; dataMatrixMulweights.set(j, temp); &#125; h = sigmoid(dataMatrixMulweights); for (int q = 0; q &lt; m; q++) &#123; error.set(q, Double.parseDouble(classLabels.get(q)) - h.get(q)); &#125; double tempweight = 0.0; for (int p = 0; p &lt; n; p++) &#123; tempweight = 0.0; for (int q = 0; q &lt; m; q++) &#123; tempweight = tempweight + alpha * Double.parseDouble(dataSet.data.get(q).get(p)) * error.get(q); &#125; weights.set(p, weights.get(p) + tempweight); &#125; &#125; return weights; &#125; public Logistic() &#123; super(); &#125;&#125; 添加map数据处理类1234567891011121314151617181920212223242526272829303132import com.youfan.entity.CarrierInfo;import com.youfan.util.CarrierUtils;import com.youfan.util.HbaseUtil;import org.apache.commons.lang3.StringUtils;import org.apache.flink.api.common.functions.MapFunction;import java.util.Random;/** * Created by li on 2019/1/5. */public class LogicMap implements MapFunction&lt;String, LogicInfo&gt;&#123; @Override public LogicInfo map(String s) throws Exception &#123; if(StringUtils.isBlank(s))&#123; return null; &#125; Random random = new Random(); String [] temps = s.split(\",\"); String variable1 = temps[0]; String variable2 = temps[1]; String variable3 = temps[2]; String labase = temps[3]; LogicInfo logicInfo = new LogicInfo(); logicInfo.setVariable1(variable1); logicInfo.setVariable2(variable2); logicInfo.setVariable3(variable3); logicInfo.setLabase(labase); logicInfo.setGroupbyfield(\"logic==\"+random.nextInt(10)); return logicInfo; &#125;&#125; 添加reduce分组统计类 1234567891011121314151617181920212223242526272829303132333435import org.apache.flink.api.common.functions.GroupReduceFunction;import org.apache.flink.util.Collector;import java.util.ArrayList;import java.util.Iterator;/** * Created by li on 2019/1/6. */public class LogicReduce implements GroupReduceFunction&lt;LogicInfo,ArrayList&lt;Double&gt;&gt; &#123; @Override public void reduce(Iterable&lt;LogicInfo&gt; iterable, Collector&lt;ArrayList&lt;Double&gt;&gt; collector) throws Exception &#123; Iterator&lt;LogicInfo&gt; iterator = iterable.iterator(); CreateDataSet trainingSet = new CreateDataSet(); while(iterator.hasNext())&#123; LogicInfo logicInfo = iterator.next(); String variable1 = logicInfo.getVariable1(); String variable2 = logicInfo.getVariable2(); String variable3 = logicInfo.getVariable3(); String label = logicInfo.getLabase(); ArrayList&lt;String&gt; as = new ArrayList&lt;String&gt;(); as.add(variable1); as.add(variable2); as.add(variable3); trainingSet.data.add(as); trainingSet.labels.add(label); &#125; ArrayList&lt;Double&gt; weights = new ArrayList&lt;Double&gt;(); weights = Logistic.gradAscent1(trainingSet, trainingSet.labels, 500); collector.collect(weights); &#125;&#125; 添加Flink计算类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import com.youfan.entity.CarrierInfo;import com.youfan.map.CarrierMap;import com.youfan.reduce.CarrierReduce;import com.youfan.util.MongoUtils;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.summarize.aggregation.DoubleSummaryAggregator;import org.apache.flink.api.java.utils.ParameterTool;import org.bson.Document;import java.util.*;/** * Created by li on 2019/1/6. */public class LogicTask &#123; public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); // set up the execution environment final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataSet&lt;String&gt; text = env.readTextFile(params.get(\"input\")); DataSet&lt;LogicInfo&gt; mapresult = text.map(new LogicMap()); DataSet&lt;ArrayList&lt;Double&gt;&gt; reduceresutl = mapresult.groupBy(\"groupbyfield\").reduceGroup(new LogicReduce()); try &#123; List&lt;ArrayList&lt;Double&gt;&gt; reusltlist = reduceresutl.collect(); int groupsize = reusltlist.size(); Map&lt;Integer,Double&gt; summap = new TreeMap&lt;Integer,Double&gt;(new Comparator&lt;Integer&gt;() &#123; @Override public int compare(Integer o1, Integer o2) &#123; return o1.compareTo(o2); &#125; &#125;); for(ArrayList&lt;Double&gt; array:reusltlist)&#123; for(int i=0;i&lt;array.size();i++)&#123; double pre = summap.get(i)==null?0d:summap.get(i); summap.put(i,pre+array.get(i)); &#125; &#125; ArrayList&lt;Double&gt; finalweight = new ArrayList&lt;Double&gt;(); Set&lt;Map.Entry&lt;Integer,Double&gt;&gt; set = summap.entrySet(); for(Map.Entry&lt;Integer,Double&gt; mapentry :set)&#123; Integer key = mapentry.getKey(); Double sumvalue = mapentry.getValue(); double finalvalue = sumvalue/groupsize; finalweight.add(finalvalue); &#125; env.execute(\"LogicTask analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十一)java实现逻辑回归算法理论学习","slug":"ceshi16","date":"2020-03-27T13:55:53.000Z","updated":"2020-03-28T04:50:51.620Z","comments":true,"path":"2020/03/27/ceshi16/","link":"","permalink":"https://etop.work/2020/03/27/ceshi16/","excerpt":"微分看待微分的意义，可以有不同的角度，最常用的两种是：函数图像中，某点的切线的斜率","text":"微分看待微分的意义，可以有不同的角度，最常用的两种是：函数图像中，某点的切线的斜率 函数的变化率 几个微分的例子： 多微分当一个函数有多个变量的时候，就有了多变量的微分，即分别对每个变量进行求微分。 梯度梯度实际上就是多变量微分的一般化 在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 梯度下降算法的数学解释J是关于Θ的一个函数，我们当前所处的位置为Θ0点，要从这个点走到J的最小值点，也就是山底。首先我们先确定前进的方向，也就是梯度的方向，然后走一段距离的步长，也就是α，走完这个段步长，就到达了Θ1这个点！ α在梯度下降算法中被称作为学习率或者步长 梯度下降算法的实现首先，我们需要定义一个代价函数，在此我们选用均方误差代价函数 m是数据集中点的个数½是一个常量，这样是为了在求梯度的时候，二次方乘下来就和这里的½抵消了，自然就没有多余的常数系数，方便后续的计算，同时对结果不会有影响y 是数据集中每个点的真实y坐标的值h 是我们的预测函数，根据每一个输入x，根据Θ 计算得到预测的y值，即 我们可以根据代价函数看到，代价函数中的变量有两个，所以是一个多变量的梯度下降问题，求解出代价函数的梯度，也就是分别对两个变量进行微分","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(十) 终端偏好","slug":"ceshi15","date":"2020-03-27T13:03:54.000Z","updated":"2020-03-27T13:56:44.999Z","comments":true,"path":"2020/03/27/ceshi15/","link":"","permalink":"https://etop.work/2020/03/27/ceshi15/","excerpt":"","text":"做法和品牌偏好类似这里不再详细讲解","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(八) 测试接口以及kafka接收消息","slug":"ceshi13","date":"2020-03-27T06:36:26.000Z","updated":"2020-03-27T07:11:11.807Z","comments":true,"path":"2020/03/27/ceshi13/","link":"","permalink":"https://etop.work/2020/03/27/ceshi13/","excerpt":"使用postman模拟post请求AttentionProductLog api接口: http://127.0.0.1:8762/infolog/receivelog?receivelog=AttentionProductLog:{&quot;product&quot;:2} kafkaconsumer 端返回如下消息体,说明程序是ok的: {“message”:”{“operatortype&quot;:0,&quot;productid&quot;:2,&quot;producttypeid&quot;:0,&quot;userid&quot;:0,&quot;usetype&quot;:0}”,”status”:”success”}","text":"使用postman模拟post请求AttentionProductLog api接口: http://127.0.0.1:8762/infolog/receivelog?receivelog=AttentionProductLog:{&quot;product&quot;:2} kafkaconsumer 端返回如下消息体,说明程序是ok的: {“message”:”{“operatortype&quot;:0,&quot;productid&quot;:2,&quot;producttypeid&quot;:0,&quot;userid&quot;:0,&quot;usetype&quot;:0}”,”status”:”success”}","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(七) 搭建数据收集服务","slug":"ceshi12","date":"2020-03-27T04:08:52.000Z","updated":"2020-03-27T07:11:18.425Z","comments":true,"path":"2020/03/27/ceshi12/","link":"","permalink":"https://etop.work/2020/03/27/ceshi12/","excerpt":"使用Intellij idea 搭建maven模块搭建数据收集服务模块,并加入以下依赖","text":"使用Intellij idea 搭建maven模块搭建数据收集服务模块,并加入以下依赖 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;groupId&gt;com.youfan.test&lt;/groupId&gt;&lt;artifactId&gt;youfanInfoInService&lt;/artifactId&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.47&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.youfan.test&lt;/groupId&gt; &lt;artifactId&gt;youfancommon&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; controller层接收日志1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import javax.servlet.http.HttpServletRequest;import java.util.Date;/** * Created by li on 2019/1/6. */@RestController@RequestMapping(\"infolog\")public class InfoInControl &#123; private final String attentionProductLogTopic = ReadProperties.getKey(\"attentionProductLog\"); private final String buyCartProductLogTopic = ReadProperties.getKey(\"buyCartProductLog\"); private final String collectProductLogTopic = ReadProperties.getKey(\"collectProductLog\"); private final String scanProductLogTopic = ReadProperties.getKey(\"scanProductLog\"); @Autowired private KafkaTemplate&lt;String, String&gt; kafkaTemplate; @RequestMapping(value = \"helloworld\",method = RequestMethod.GET) public String hellowolrd(HttpServletRequest req)&#123; String ip =req.getRemoteAddr(); ResultMessage resultMessage = new ResultMessage(); resultMessage.setMessage(\"hello:\"+ip); resultMessage.setStatus(\"success\"); String result = JSONObject.toJSONString(resultMessage); return result; &#125; /** * AttentionProductLog:&#123;productid:productid....&#125; BuyCartProductLog:&#123;productid:productid....&#125; CollectProductLog:&#123;productid:productid....&#125; ScanProductLog:&#123;productid:productid....&#125; * @param recevicelog * @param req * @return */ @RequestMapping(value = \"receivelog\",method = RequestMethod.POST) public String hellowolrd(String recevicelog,HttpServletRequest req)&#123; if(StringUtils.isBlank(recevicelog))&#123; return null; &#125; String[] rearrays = recevicelog.split(\":\",2); String classname = rearrays[0]; String data = rearrays[1]; String resulmesage= \"\"; if(\"AttentionProductLog\".equals(classname))&#123; AttentionProductLog attentionProductLog = JSONObject.parseObject(data,AttentionProductLog.class); resulmesage = JSONObject.toJSONString(attentionProductLog); kafkaTemplate.send(attentionProductLogTopic,resulmesage+\"##1##\"+new Date().getTime()); &#125;else if(\"BuyCartProductLog\".equals(classname))&#123; BuyCartProductLog buyCartProductLog = JSONObject.parseObject(data,BuyCartProductLog.class); resulmesage = JSONObject.toJSONString(buyCartProductLog); kafkaTemplate.send(buyCartProductLogTopic,resulmesage+\"##1##\"+new Date().getTime()); &#125;else if(\"CollectProductLog\".equals(classname))&#123; CollectProductLog collectProductLog = JSONObject.parseObject(data, CollectProductLog.class); resulmesage = JSONObject.toJSONString(collectProductLog); kafkaTemplate.send(collectProductLogTopic,resulmesage+\"##1##\"+new Date().getTime()); &#125;else if(\"ScanProductLog\".equals(classname))&#123; ScanProductLog scanProductLog = JSONObject.parseObject(data, ScanProductLog.class); resulmesage = JSONObject.toJSONString(scanProductLog); kafkaTemplate.send(scanProductLogTopic,resulmesage+\"##1##\"+new Date().getTime()); &#125; ResultMessage resultMessage = new ResultMessage(); resultMessage.setMessage(resulmesage); resultMessage.setStatus(\"success\"); String result = JSONObject.toJSONString(resultMessage); return result; &#125;&#125; 读取配置文件工具类1234567891011121314151617//这个工具类可以放在common模块import com.typesafe.config.Config;import com.typesafe.config.ConfigFactory;/** * Created by li on 2019/1/6. */public class ReadProperties &#123; public final static Config config = ConfigFactory.load(\"youfan.properties\"); public static String getKey(String key)&#123; return config.getString(key).trim(); &#125; public static String getKey(String key,String filename)&#123; Config config = ConfigFactory.load(filename); return config.getString(key).trim(); &#125;&#125; 加入kafka配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import org.apache.kafka.clients.producer.ProducerConfig;import org.apache.kafka.common.serialization.StringSerializer;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.kafka.annotation.EnableKafka;import org.springframework.kafka.core.DefaultKafkaProducerFactory;import org.springframework.kafka.core.KafkaTemplate;import org.springframework.kafka.core.ProducerFactory;import java.util.HashMap;import java.util.Map;@Configuration@EnableKafkapublic class KafkaProducerConfig &#123; @Value(\"$&#123;kafka.producer.servers&#125;\") private String servers; @Value(\"$&#123;kafka.producer.retries&#125;\") private int retries; @Value(\"$&#123;kafka.producer.batch.size&#125;\") private int batchSize; @Value(\"$&#123;kafka.producer.linger&#125;\") private int linger; @Value(\"$&#123;kafka.producer.buffer.memory&#125;\") private int bufferMemory; public Map&lt;String, Object&gt; producerConfigs() &#123; Map&lt;String, Object&gt; props = new HashMap&lt;&gt;(); props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, servers); props.put(ProducerConfig.RETRIES_CONFIG, retries); props.put(ProducerConfig.BATCH_SIZE_CONFIG, batchSize); props.put(ProducerConfig.LINGER_MS_CONFIG, linger); props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, bufferMemory); props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); return props; &#125; public ProducerFactory&lt;String, String&gt; producerFactory() &#123; return new DefaultKafkaProducerFactory&lt;String, String&gt;(producerConfigs()); &#125; @Bean public KafkaTemplate&lt;String, String&gt; kafkaTemplate() &#123; return new KafkaTemplate&lt;String, String&gt;(producerFactory()); &#125;&#125; 配置application.properties12345678910111213141516171819202122232425server.port&#x3D;8762spring.application.name&#x3D;youfanInfoInServiceeureka.client.serviceUrl.defaultZone&#x3D;http:&#x2F;&#x2F;localhost:8761&#x2F;eureka&#x2F;##--kafka--#&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; kafka &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;kafka.consumer.zookeeper.connect&#x3D;192.168.37.141:2181kafka.consumer.servers&#x3D;192.168.37.141:9092kafka.consumer.enable.auto.commit&#x3D;truekafka.consumer.session.timeout&#x3D;6000kafka.consumer.auto.commit.interval&#x3D;100kafka.consumer.auto.offset.reset&#x3D;latestkafka.consumer.topic&#x3D;testkafka.consumer.group.id&#x3D;testkafka.consumer.concurrency&#x3D;10kafka.producer.servers&#x3D;192.168.37.141:9092kafka.producer.retries&#x3D;0kafka.producer.batch.size&#x3D;4096kafka.producer.linger&#x3D;1kafka.producer.buffer.memory&#x3D;40960 在配置文件youfan.properties指定消息队列名称1234attentionProductLog&#x3D;attentionProductLogbuyCartProductLog&#x3D;buyCartProductLogcollectProductLog&#x3D;collectProductLogscanProductLog&#x3D;scanProductLog 消息实体1234567891011121314151617181920212223/** * Created by li on 2019/1/6. */public class ResultMessage &#123; private String status;//状态 fail 、 success private String message;//消息内容 public String getStatus() &#123; return status; &#125; public void setStatus(String status) &#123; this.status = status; &#125; public String getMessage() &#123; return message; &#125; public void setMessage(String message) &#123; this.message = message; &#125;&#125; 启动类12345678910111213141516import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;/** * Created by li on 2019/1/6. */@SpringBootApplication@EnableEurekaClientpublic class Startupmain &#123; public static void main(String[] args) &#123; SpringApplication.run( Startupmain.class, args ); &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(五) 注册中心搭建","slug":"ceshi10","date":"2020-03-27T03:31:11.000Z","updated":"2020-03-27T03:41:26.316Z","comments":true,"path":"2020/03/27/ceshi10/","link":"","permalink":"https://etop.work/2020/03/27/ceshi10/","excerpt":"注册中心搭建使用intellij idea搭建maven项目(搭建过程跳过)，然后添加一下依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;groupId&gt;com.youfan.test&lt;/groupId&gt; &lt;artifactId&gt;youfanRegiterCenter&lt;/artifactId&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;","text":"注册中心搭建使用intellij idea搭建maven项目(搭建过程跳过)，然后添加一下依赖 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;groupId&gt;com.youfan.test&lt;/groupId&gt; &lt;artifactId&gt;youfanRegiterCenter&lt;/artifactId&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Finchley.RELEASE&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 添加启动类 123456789101112import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run( EurekaServerApplication.class, args ); &#125;&#125; 启动并检查端口 访问注册中心页面http://localhost:8761/","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(四) 败家指数","slug":"ceshi9","date":"2020-03-26T06:51:29.000Z","updated":"2020-03-27T03:30:44.949Z","comments":true,"path":"2020/03/26/ceshi9/","link":"","permalink":"https://etop.work/2020/03/26/ceshi9/","excerpt":"数据库建表1234567891011121314151617181920212223242526272829CREATE TABLE `youfanportrait`.`productinfo` ( `id` INT NOT NULL AUTO_INCREMENT, `producttypeid` INT NULL, `productname` VARCHAR(45) NULL, `productdesc` VARCHAR(45) NULL, `price` INT NULL, `num` INT NULL, `createtime` TIMESTAMP NULL, `updatetime` TIMESTAMP NULL, `mecharid` INT NULL, `producturl` VARCHAR(45) NULL, PRIMARY KEY (`id`)); ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin CREATE TABLE `orderinfo` ( `id` int(11) NOT NULL AUTO_INCREMENT, `productid` int(11) DEFAULT NULL, `producttypeid` int(11) DEFAULT NULL, `createtime` timestamp NULL DEFAULT NULL, `amount` double DEFAULT NULL, `paytype` int(11) DEFAULT NULL, `paytime` timestamp NULL DEFAULT NULL, `paystatus` int(11) DEFAULT NULL, `couponamount` double DEFAULT NULL, `totalamount` double DEFAULT NULL, `refundamount` double DEFAULT NULL, `num` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin 败家指数定义败家指数 = 支付金额平均值x0.3、最大支付金额x0.3、下单频率x0.4","text":"数据库建表1234567891011121314151617181920212223242526272829CREATE TABLE `youfanportrait`.`productinfo` ( `id` INT NOT NULL AUTO_INCREMENT, `producttypeid` INT NULL, `productname` VARCHAR(45) NULL, `productdesc` VARCHAR(45) NULL, `price` INT NULL, `num` INT NULL, `createtime` TIMESTAMP NULL, `updatetime` TIMESTAMP NULL, `mecharid` INT NULL, `producturl` VARCHAR(45) NULL, PRIMARY KEY (`id`)); ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin CREATE TABLE `orderinfo` ( `id` int(11) NOT NULL AUTO_INCREMENT, `productid` int(11) DEFAULT NULL, `producttypeid` int(11) DEFAULT NULL, `createtime` timestamp NULL DEFAULT NULL, `amount` double DEFAULT NULL, `paytype` int(11) DEFAULT NULL, `paytime` timestamp NULL DEFAULT NULL, `paystatus` int(11) DEFAULT NULL, `couponamount` double DEFAULT NULL, `totalamount` double DEFAULT NULL, `refundamount` double DEFAULT NULL, `num` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin 败家指数定义败家指数 = 支付金额平均值x0.3、最大支付金额x0.3、下单频率x0.4 实体定义123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125import java.util.List;/** * Created by li on 2019/1/5. */public class BaiJiaInfo &#123; private String baijiatype;//败家指数区段：0-20 、20-50 、50-70、70-80、80-90、90-100 private String userid; private String createtime; private String amount ; private String paytype ; private String paytime; private String paystatus;//0、未支付 1、已支付 2、已退款 private String couponamount; private String totalamount; private String refundamount; private Long count;//数量 private String groupfield;//分组 private List&lt;BaiJiaInfo&gt; list; public List&lt;BaiJiaInfo&gt; getList() &#123; return list; &#125; public void setList(List&lt;BaiJiaInfo&gt; list) &#123; this.list = list; &#125; public String getUserid() &#123; return userid; &#125; public void setUserid(String userid) &#123; this.userid = userid; &#125; public String getCreatetime() &#123; return createtime; &#125; public void setCreatetime(String createtime) &#123; this.createtime = createtime; &#125; public String getAmount() &#123; return amount; &#125; public void setAmount(String amount) &#123; this.amount = amount; &#125; public String getPaytype() &#123; return paytype; &#125; public void setPaytype(String paytype) &#123; this.paytype = paytype; &#125; public String getPaytime() &#123; return paytime; &#125; public void setPaytime(String paytime) &#123; this.paytime = paytime; &#125; public String getPaystatus() &#123; return paystatus; &#125; public void setPaystatus(String paystatus) &#123; this.paystatus = paystatus; &#125; public String getCouponamount() &#123; return couponamount; &#125; public void setCouponamount(String couponamount) &#123; this.couponamount = couponamount; &#125; public String getTotalamount() &#123; return totalamount; &#125; public void setTotalamount(String totalamount) &#123; this.totalamount = totalamount; &#125; public String getRefundamount() &#123; return refundamount; &#125; public void setRefundamount(String refundamount) &#123; this.refundamount = refundamount; &#125; public String getBaijiatype() &#123; return baijiatype; &#125; public void setBaijiatype(String baijiatype) &#123; this.baijiatype = baijiatype; &#125; public Long getCount() &#123; return count; &#125; public void setCount(Long count) &#123; this.count = count; &#125; public String getGroupfield() &#123; return groupfield; &#125; public void setGroupfield(String groupfield) &#123; this.groupfield = groupfield; &#125;&#125; 添加map类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import com.youfan.entity.BaiJiaInfo;import com.youfan.entity.CarrierInfo;import com.youfan.util.CarrierUtils;import com.youfan.util.HbaseUtil;import org.apache.commons.lang3.StringUtils;import org.apache.flink.api.common.functions.MapFunction;import java.util.ArrayList;import java.util.List;/** * Created by li on 2019/1/5. */public class BaijiaMap implements MapFunction&lt;String, BaiJiaInfo&gt;&#123; @Override public BaiJiaInfo map(String s) throws Exception &#123; if(StringUtils.isBlank(s))&#123; return null; &#125; String[] orderinfos = s.split(\",\"); String id= orderinfos[0]; String productid = orderinfos[1]; String producttypeid = orderinfos[2]; String createtime = orderinfos[3]; String amount = orderinfos[4]; String paytype = orderinfos[5]; String paytime = orderinfos[6]; String paystatus = orderinfos[7]; String couponamount = orderinfos[8]; String totalamount = orderinfos[9]; String refundamount = orderinfos[10]; String num = orderinfos[11]; String userid = orderinfos[12]; BaiJiaInfo baiJiaInfo = new BaiJiaInfo(); baiJiaInfo.setUserid(userid); baiJiaInfo.setCreatetime(createtime); baiJiaInfo.setAmount(amount); baiJiaInfo.setPaytype(paytype); baiJiaInfo.setPaytime(paytime); baiJiaInfo.setPaystatus(paystatus); baiJiaInfo.setCouponamount(couponamount); baiJiaInfo.setTotalamount(totalamount); baiJiaInfo.setRefundamount(refundamount); String groupfield = \"baijia==\"+userid; baiJiaInfo.setGroupfield(groupfield); List&lt;BaiJiaInfo&gt; list = new ArrayList&lt;BaiJiaInfo&gt;(); list.add(baiJiaInfo); return baiJiaInfo; &#125;&#125; 添加reduce类 123456789101112131415161718192021222324252627282930import com.youfan.entity.BaiJiaInfo;import com.youfan.entity.CarrierInfo;import org.apache.flink.api.common.functions.GroupReduceFunction;import org.apache.flink.api.common.functions.ReduceFunction;import org.apache.flink.util.Collector;import java.util.ArrayList;import java.util.List;/** * Created by li on 2019/1/5. */public class BaijiaReduce implements ReduceFunction&lt;BaiJiaInfo&gt;&#123; @Override public BaiJiaInfo reduce(BaiJiaInfo baiJiaInfo, BaiJiaInfo t1) throws Exception &#123; String userid = baiJiaInfo.getUserid(); List&lt;BaiJiaInfo&gt; baijialist1 = baiJiaInfo.getList(); List&lt;BaiJiaInfo&gt; baijialist2 = t1.getList(); List&lt;BaiJiaInfo&gt; finallist = new ArrayList&lt;BaiJiaInfo&gt;(); finallist.addAll(baijialist1); finallist.addAll(baijialist2); BaiJiaInfo baiJiaInfofinal = new BaiJiaInfo(); baiJiaInfofinal.setUserid(userid); baiJiaInfofinal.setList(finallist); return baiJiaInfofinal; &#125;&#125; 添加task类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172import com.youfan.entity.BaiJiaInfo;import com.youfan.entity.CarrierInfo;import com.youfan.map.BaijiaMap;import com.youfan.map.CarrierMap;import com.youfan.reduce.BaijiaReduce;import com.youfan.reduce.CarrierReduce;import com.youfan.util.DateUtils;import com.youfan.util.HbaseUtil;import com.youfan.util.MongoUtils;import org.apache.flink.api.common.functions.ReduceFunction;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.utils.ParameterTool;import org.bson.Document;import java.text.DateFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.*;/** * Created by li on 2019/1/5. */public class BaiJiaTask &#123; public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); // set up the execution environment final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataSet&lt;String&gt; text = env.readTextFile(params.get(\"input\")); DataSet&lt;BaiJiaInfo&gt; mapresult = text.map(new BaijiaMap()); DataSet&lt;BaiJiaInfo&gt; reduceresutl = mapresult.groupBy(\"groupfield\").reduce(new BaijiaReduce()); try &#123; List&lt;BaiJiaInfo&gt; reusltlist = reduceresutl.collect(); for(BaiJiaInfo baiJiaInfo:reusltlist)&#123; String userid = baiJiaInfo.getUserid(); List&lt;BaiJiaInfo&gt; list = baiJiaInfo.getList(); Collections.sort(list, new Comparator&lt;BaiJiaInfo&gt;() &#123; @Override public int compare(BaiJiaInfo o1, BaiJiaInfo o2) &#123; String timeo1 = o1.getCreatetime(); String timeo2 = o2.getCreatetime(); DateFormat dateFormat = new SimpleDateFormat(\"yyyyMMdd hhmmss\"); Date datenow = new Date(); Date time1 = datenow; Date time2 = datenow; try &#123; time1 = dateFormat.parse(timeo1); time2 = dateFormat.parse(timeo2); &#125; catch (ParseException e) &#123; e.printStackTrace(); &#125; return time1.compareTo(time2); &#125; &#125;); BaiJiaInfo before = null; Map&lt;Integer,Integer&gt; frequencymap = new HashMap&lt;Integer,Integer&gt;(); double maxamount = 0d; double sum = 0d; for(BaiJiaInfo baiJiaInfoinner:list)&#123; if(before==null)&#123; before = baiJiaInfoinner; continue; &#125; //计算购买的频率 String beforetime = before.getCreatetime(); String endstime = baiJiaInfoinner.getCreatetime(); int days = DateUtils.getDaysBetweenbyStartAndend(beforetime,endstime,\"yyyyMMdd hhmmss\"); int brefore = frequencymap.get(days)==null?0:frequencymap.get(days); frequencymap.put(days,brefore+1); //计算最大金额 String totalamountstring = baiJiaInfoinner.getTotalamount(); Double totalamout = Double.valueOf(totalamountstring); if(totalamout&gt;maxamount)&#123; maxamount = totalamout; &#125; //计算平均值 sum += totalamout; before = baiJiaInfoinner; &#125; double avramount = sum/list.size(); int totaldays = 0; Set&lt;Map.Entry&lt;Integer,Integer&gt;&gt; set = frequencymap.entrySet(); for(Map.Entry&lt;Integer,Integer&gt; entry :set)&#123; Integer frequencydays = entry.getKey(); Integer count = entry.getValue(); totaldays += frequencydays*count; &#125; int avrdays = totaldays/list.size();//平均天数 //败家指数 = 支付金额平均值*0.3、最大支付金额*0.3、下单频率*0.4 //支付金额平均值30分（0-20 5 20-60 10 60-100 20 100-150 30 150-200 40 200-250 60 250-350 70 350-450 80 450-600 90 600以上 100 ） // 最大支付金额30分（0-20 5 20-60 10 60-200 30 200-500 60 500-700 80 700 100） // 下单平率30分 （0-5 100 5-10 90 10-30 70 30-60 60 60-80 40 80-100 20 100以上的 10） int avraoumtsoce = 0; if(avramount&gt;=0 &amp;&amp; avramount &lt; 20)&#123; avraoumtsoce = 5; &#125;else if (avramount&gt;=20 &amp;&amp; avramount &lt; 60)&#123; avraoumtsoce = 10; &#125;else if (avramount&gt;=60 &amp;&amp; avramount &lt; 100)&#123; avraoumtsoce = 20; &#125;else if (avramount&gt;=100 &amp;&amp; avramount &lt; 150)&#123; avraoumtsoce = 30; &#125;else if (avramount&gt;=150 &amp;&amp; avramount &lt; 200)&#123; avraoumtsoce = 40; &#125;else if (avramount&gt;=200 &amp;&amp; avramount &lt; 250)&#123; avraoumtsoce = 60; &#125;else if (avramount&gt;=250 &amp;&amp; avramount &lt; 350)&#123; avraoumtsoce = 70; &#125;else if (avramount&gt;=350 &amp;&amp; avramount &lt; 450)&#123; avraoumtsoce = 80; &#125;else if (avramount&gt;=450 &amp;&amp; avramount &lt; 600)&#123; avraoumtsoce = 90; &#125;else if (avramount&gt;=600)&#123; avraoumtsoce = 100; &#125; int maxaoumtscore = 0; if(maxamount&gt;=0 &amp;&amp; maxamount &lt; 20)&#123; maxaoumtscore = 5; &#125;else if (maxamount&gt;=20 &amp;&amp; maxamount &lt; 60)&#123; maxaoumtscore = 10; &#125;else if (maxamount&gt;=60 &amp;&amp; maxamount &lt; 200)&#123; maxaoumtscore = 30; &#125;else if (maxamount&gt;=200 &amp;&amp;maxamount &lt; 500)&#123; maxaoumtscore = 60; &#125;else if (maxamount&gt;=500 &amp;&amp; maxamount &lt; 700)&#123; maxaoumtscore = 80; &#125;else if (maxamount&gt;=700)&#123; maxaoumtscore = 100; &#125; // 下单平率30分 （0-5 100 5-10 90 10-30 70 30-60 60 60-80 40 80-100 20 100以上的 10） int avrdaysscore = 0; if(avrdays&gt;=0 &amp;&amp; avrdays &lt; 5)&#123; avrdaysscore = 100; &#125;else if (avramount&gt;=5 &amp;&amp; avramount &lt; 10)&#123; avrdaysscore = 90; &#125;else if (avramount&gt;=10 &amp;&amp; avramount &lt; 30)&#123; avrdaysscore = 70; &#125;else if (avramount&gt;=30 &amp;&amp; avramount &lt; 60)&#123; avrdaysscore = 60; &#125;else if (avramount&gt;=60 &amp;&amp; avramount &lt; 80)&#123; avrdaysscore = 40; &#125;else if (avramount&gt;=80 &amp;&amp; avramount &lt; 100)&#123; avrdaysscore = 20; &#125;else if (avramount&gt;=100)&#123; avrdaysscore = 10; &#125; double totalscore = (avraoumtsoce/100)*30+(maxaoumtscore/100)*30+(avrdaysscore/100)*40; String tablename = \"userflaginfo\"; String rowkey = userid; String famliyname = \"baseinfo\"; String colum = \"baijiasoce\"; HbaseUtil.putdata(tablename,rowkey,famliyname,colum,totalscore+\"\"); &#125; env.execute(\"baijiascore analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 添加工具类DateUtils12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.text.DateFormat;import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date;/** * Created by li on 2019/1/5. */public class DateUtils &#123; public static String getYearbasebyAge(String age)&#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(new Date()); calendar.add(Calendar.YEAR,-Integer.valueOf(age)); Date newdate = calendar.getTime(); DateFormat dateFormat = new SimpleDateFormat(\"yyyy\"); String newdatestring = dateFormat.format(newdate); Integer newdateinteger = Integer.valueOf(newdatestring); String yearbasetype = \"未知\"; if(newdateinteger &gt;= 1940 &amp;&amp; newdateinteger &lt; 1950)&#123; yearbasetype = \"40后\"; &#125;else if (newdateinteger &gt;= 1950 &amp;&amp; newdateinteger &lt; 1960)&#123; yearbasetype = \"50后\"; &#125;else if (newdateinteger &gt;= 1960 &amp;&amp; newdateinteger &lt; 1970)&#123; yearbasetype = \"60后\"; &#125;else if (newdateinteger &gt;= 1970 &amp;&amp; newdateinteger &lt; 1980)&#123; yearbasetype = \"70后\"; &#125;else if (newdateinteger &gt;= 1980 &amp;&amp; newdateinteger &lt; 1990)&#123; yearbasetype = \"80后\"; &#125;else if (newdateinteger &gt;= 1990 &amp;&amp; newdateinteger &lt; 2000)&#123; yearbasetype = \"90后\"; &#125;else if (newdateinteger &gt;= 2000 &amp;&amp; newdateinteger &lt; 2010)&#123; yearbasetype = \"00后\"; &#125;else if (newdateinteger &gt;= 2010 )&#123; yearbasetype = \"10后\"; &#125; return yearbasetype; &#125; public static int getDaysBetweenbyStartAndend(String starttime,String endTime,String dateFormatstring) throws ParseException &#123; DateFormat dateFormat = new SimpleDateFormat(dateFormatstring); Date start = dateFormat.parse(starttime); Date end = dateFormat.parse(endTime); Calendar startcalendar = Calendar.getInstance(); Calendar endcalendar = Calendar.getInstance(); startcalendar.setTime(start); endcalendar.setTime(end); int days = 0; while(startcalendar.before(endcalendar))&#123; startcalendar.add(Calendar.DAY_OF_YEAR,1); days += 1; &#125; return days; &#125; public static String gethoursbydate(String timevalue) throws ParseException &#123; DateFormat dateFormat = new SimpleDateFormat(\"yyyyMMdd hhmmss\"); Date time = dateFormat.parse(timevalue); dateFormat = new SimpleDateFormat(\"hh\"); String resulthour = dateFormat.format(time); return resulthour; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(三)手机运营商标签代码编写","slug":"ceshi8","date":"2020-03-25T13:43:17.000Z","updated":"2020-03-26T06:52:30.900Z","comments":true,"path":"2020/03/25/ceshi8/","link":"","permalink":"https://etop.work/2020/03/25/ceshi8/","excerpt":"设计流程类似于用户年代标签","text":"设计流程类似于用户年代标签 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960//手机运营商工具类package com.youfan.util;import java.util.regex.Pattern;/** * Created by li on 2019/1/5. */public class CarrierUtils &#123; /** * 中国电信号码格式验证 手机段： 133,153,180,181,189,177,1700,173,199 **/ private static final String CHINA_TELECOM_PATTERN = \"(^1(33|53|77|73|99|8[019])\\\\d&#123;8&#125;$)|(^1700\\\\d&#123;7&#125;$)\"; /** * 中国联通号码格式验证 手机段：130,131,132,155,156,185,186,145,176,1709 **/ private static final String CHINA_UNICOM_PATTERN = \"(^1(3[0-2]|4[5]|5[56]|7[6]|8[56])\\\\d&#123;8&#125;$)|(^1709\\\\d&#123;7&#125;$)\"; /** * 中国移动号码格式验证 * 手机段：134,135,136,137,138,139,150,151,152,157,158,159,182,183,184,187,188,147,178,1705 **/ private static final String CHINA_MOBILE_PATTERN = \"(^1(3[4-9]|4[7]|5[0-27-9]|7[8]|8[2-478])\\\\d&#123;8&#125;$)|(^1705\\\\d&#123;7&#125;$)\"; /** * 0、未知 1、移动 2、联通 3、电信 * @param telphone * @return */ public static int getCarrierByTel(String telphone)&#123; boolean b1 = telphone == null || telphone.trim().equals(\"\") ? false : match(CHINA_MOBILE_PATTERN, telphone); if (b1) &#123; return 1; &#125; b1 = telphone == null || telphone.trim().equals(\"\") ? false : match(CHINA_UNICOM_PATTERN, telphone); if (b1) &#123; return 2; &#125; b1 = telphone == null || telphone.trim().equals(\"\") ? false : match(CHINA_TELECOM_PATTERN, telphone); if (b1) &#123; return 3; &#125; return 0; &#125; /** * 匹配函数 * @param regex * @param tel * @return */ private static boolean match(String regex, String tel) &#123; return Pattern.matches(regex, tel); &#125;&#125; 实体类 1234567891011121314151617181920212223242526272829public class CarrierInfo &#123; private String carrier;//运营商 private Long count;//数量 private String groupfield;//分组 public String getCarrier() &#123; return carrier; &#125; public void setCarrier(String carrier) &#123; this.carrier = carrier; &#125; public Long getCount() &#123; return count; &#125; public void setCount(Long count) &#123; this.count = count; &#125; public String getGroupfield() &#123; return groupfield; &#125; public void setGroupfield(String groupfield) &#123; this.groupfield = groupfield; &#125;&#125; map数据处理类 12345678910111213141516171819202122232425262728293031323334353637383940414243import com.youfan.entity.CarrierInfo;import com.youfan.entity.YearBase;import com.youfan.util.CarrierUtils;import com.youfan.util.DateUtils;import com.youfan.util.HbaseUtil;import org.apache.commons.lang3.StringUtils;import org.apache.flink.api.common.functions.MapFunction;/** * Created by li on 2019/1/5. */public class CarrierMap implements MapFunction&lt;String, CarrierInfo&gt;&#123; @Override public CarrierInfo map(String s) throws Exception &#123; if(StringUtils.isBlank(s))&#123; return null; &#125; String[] userinfos = s.split(\",\"); String userid = userinfos[0]; String username = userinfos[1]; String sex = userinfos[2]; String telphone = userinfos[3]; String email = userinfos[4]; String age = userinfos[5]; String registerTime = userinfos[6]; String usetype = userinfos[7];//'终端类型：0、pc端；1、移动端；2、小程序端' int carriertype = CarrierUtils.getCarrierByTel(telphone); String carriertypestring = carriertype==0?\"未知运营商\":carriertype==1?\"移动用户\":carriertype==2?\"联通用户\":\"电信用户\"; String tablename = \"userflaginfo\"; String rowkey = userid; String famliyname = \"baseinfo\"; String colum = \"carrierinfo\";//运营商 HbaseUtil.putdata(tablename,rowkey,famliyname,colum,carriertypestring); CarrierInfo carrierInfo = new CarrierInfo(); String groupfield = \"carrierInfo==\"+carriertype; carrierInfo.setCount(1l); carrierInfo.setCarrier(carriertypestring); carrierInfo.setGroupfield(groupfield); return carrierInfo; &#125;&#125; reduce 端统计运营商个数 1234567891011121314151617181920212223package com.youfan.reduce;import com.youfan.entity.CarrierInfo;import com.youfan.entity.YearBase;import org.apache.flink.api.common.functions.ReduceFunction;/** * Created by li on 2019/1/5. */public class CarrierReduce implements ReduceFunction&lt;CarrierInfo&gt;&#123; @Override public CarrierInfo reduce(CarrierInfo carrierInfo, CarrierInfo t1) throws Exception &#123; String carrier = carrierInfo.getCarrier(); Long count1 = carrierInfo.getCount(); Long count2 = t1.getCount(); CarrierInfo carrierInfofinal = new CarrierInfo(); carrierInfofinal.setCarrier(carrier); carrierInfofinal.setCount(count1+count2); return carrierInfofinal; &#125;&#125; Flink 类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.youfan.task;import com.youfan.entity.CarrierInfo;import com.youfan.entity.YearBase;import com.youfan.map.CarrierMap;import com.youfan.map.YearBaseMap;import com.youfan.reduce.CarrierReduce;import com.youfan.reduce.YearBaseReduce;import com.youfan.util.MongoUtils;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.utils.ParameterTool;import org.bson.Document;import java.util.List;/** * Created by li on 2019/1/5. */public class CarrierTask &#123; public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); // set up the execution environment final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataSet&lt;String&gt; text = env.readTextFile(params.get(\"input\")); DataSet&lt;CarrierInfo&gt; mapresult = text.map(new CarrierMap()); DataSet&lt;CarrierInfo&gt; reduceresutl = mapresult.groupBy(\"groupfield\").reduce(new CarrierReduce()); try &#123; List&lt;CarrierInfo&gt; reusltlist = reduceresutl.collect(); for(CarrierInfo carrierInfo:reusltlist)&#123; String carrier = carrierInfo.getCarrier(); Long count = carrierInfo.getCount(); Document doc = MongoUtils.findoneby(\"carrierstatics\",\"youfanPortrait\",carrier); if(doc == null)&#123; doc = new Document(); doc.put(\"info\",carrier); doc.put(\"count\",count); &#125;else&#123; Long countpre = doc.getLong(\"count\"); Long total = countpre+count; doc.put(\"count\",total); &#125; MongoUtils.saveorupdatemongo(\"carrierstatics\",\"youfanPortrait\",doc); &#125; env.execute(\"carrier analy\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(二) 年代标签代码编写","slug":"ceshi7","date":"2020-03-25T04:14:15.000Z","updated":"2020-03-26T06:52:27.675Z","comments":true,"path":"2020/03/25/ceshi7/","link":"","permalink":"https://etop.work/2020/03/25/ceshi7/","excerpt":"年代标签定义年代：40年代 50年代 60年代 70年代 80年代 90年代 00后 10后统计每个年代群里的数量，做到近实时统计，每半小时会进行一次任务统计 年代标签代码编写设计思路业务数据库-&gt;sqoop同步到-&gt;hdfs-&gt;flink读取readText-&gt;map转换每行数据设置count-&gt;reduce统计count","text":"年代标签定义年代：40年代 50年代 60年代 70年代 80年代 90年代 00后 10后统计每个年代群里的数量，做到近实时统计，每半小时会进行一次任务统计 年代标签代码编写设计思路业务数据库-&gt;sqoop同步到-&gt;hdfs-&gt;flink读取readText-&gt;map转换每行数据设置count-&gt;reduce统计count 123456789101112131415161718192021222324252627282930313233343536//时间工具类import java.text.DateFormat;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date;public class DateUtils &#123; public static String getYearbasebyAge(String age)&#123; Calendar cal = Calendar.getInstance(); cal.setTime(new Date()); cal.add(Calendar.YEAR,-Integer.valueOf(age)); Date newdate = cal.getTime(); DateFormat dateFormat = new SimpleDateFormat(\"yyyy\"); String newdatestr = dateFormat.format(newdate); Integer newdateinteger = Integer.valueOf(newdatestr); String yearbasetype = \"\"; if(newdateinteger &gt;= 1940 &amp;&amp; newdateinteger &lt; 1950)&#123; yearbasetype = \"40年后\"; &#125;else if (newdateinteger &gt;= 1950 &amp;&amp; newdateinteger &lt; 1960)&#123; yearbasetype = \"50年后\"; &#125;else if (newdateinteger &gt;= 1960 &amp;&amp; newdateinteger &lt; 1970)&#123; yearbasetype = \"60年后\"; &#125;else if (newdateinteger &gt;= 1970 &amp;&amp; newdateinteger &lt; 1980)&#123; yearbasetype = \"70年后\"; &#125;else if (newdateinteger &gt;= 1980 &amp;&amp; newdateinteger &lt; 1990)&#123; yearbasetype = \"80年后\"; &#125;else if (newdateinteger &gt;= 1990 &amp;&amp; newdateinteger &lt; 2000)&#123; yearbasetype = \"90年后\"; &#125;else if (newdateinteger &gt;= 2000 &amp;&amp; newdateinteger &lt; 2010)&#123; yearbasetype = \"00年后\"; &#125;else if (newdateinteger &gt;= 2010 &amp;&amp; newdateinteger &lt; 2020)&#123; yearbasetype = \"10年后\"; &#125; return yearbasetype; &#125;&#125; 年代数据保存123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104//Hbase工具类import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.HColumnDescriptor;import org.apache.hadoop.hbase.HTableDescriptor;import org.apache.hadoop.hbase.TableName;import org.apache.hadoop.hbase.client.*;import org.apache.hadoop.hbase.util.Bytes;import java.io.IOException;import java.util.Map;import java.util.Set;public class HbaseUtil &#123; private static Admin admin = null; private static Connection conn = null; static&#123; // 创建hbase配置对象 Configuration conf = HBaseConfiguration.create(); conf.set(\"hbase.rootdir\",\"hdfs://192.168.37.141:9000/hbase\"); //使用eclipse时必须添加这个，否则无法定位 conf.set(\"hbase.zookeeper.quorum\",\"192.168.37.141\"); conf.set(\"hbase.client.scanner.timeout.period\", \"600000\"); conf.set(\"hbase.rpc.timeout\", \"600000\"); try &#123; conn = ConnectionFactory.createConnection(conf); // 得到管理程序 admin = conn.getAdmin(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 创建表 create \"userflaginfo\",\"baseinfo\" */ public void createTable(String tabName,String famliyname) throws Exception &#123; HTableDescriptor tab = new HTableDescriptor(tabName); // 添加列族,每个表至少有一个列族. HColumnDescriptor colDesc = new HColumnDescriptor(famliyname); tab.addFamily(colDesc); // 创建表 admin.createTable(tab); System.out.println(\"over\"); &#125; /** * 插入数据，create \"testinfo\",\"time\" */ public static void put(String tablename, String rowkey, String famliyname, Map&lt;String,String&gt; datamap) throws Exception &#123; Table table = conn.getTable(TableName.valueOf(tablename)); // 将字符串转换成byte[] byte[] rowkeybyte = Bytes.toBytes(rowkey); Put put = new Put(rowkeybyte); if(datamap != null)&#123; Set&lt;Map.Entry&lt;String,String&gt;&gt; set = datamap.entrySet(); for(Map.Entry&lt;String,String&gt; entry : set)&#123; String key = entry.getKey(); Object value = entry.getValue(); put.addColumn(Bytes.toBytes(famliyname), Bytes.toBytes(key), Bytes.toBytes(value+\"\")); &#125; &#125; table.put(put); table.close(); System.out.println(\"ok\"); &#125; /** * 获取数据，create \"testinfo\",\"time\" */ public static String getdata(String tablename, String rowkey, String famliyname,String colum) throws Exception &#123; Table table = conn.getTable(TableName.valueOf(tablename)); // 将字符串转换成byte[] byte[] rowkeybyte = Bytes.toBytes(rowkey); Get get = new Get(rowkeybyte); Result result =table.get(get); byte[] resultbytes = result.getValue(famliyname.getBytes(),colum.getBytes()); if(resultbytes == null)&#123; return null; &#125; return new String(resultbytes); &#125; /** * 插入数据，create \"testinfo\",\"time\" */ public static void putdata(String tablename, String rowkey, String famliyname,String colum,String data) throws Exception &#123; Table table = conn.getTable(TableName.valueOf(tablename)); Put put = new Put(rowkey.getBytes()); put.addColumn(famliyname.getBytes(),colum.getBytes(),data.getBytes()); table.put(put); &#125; public static void main(String[] args) throws Exception &#123; System.setProperty(\"hadoop.home.dir\",\"E:\\\\dw\\\\hadoop-2.6.0-cdh5.13.0\");// putdata(\"testinfo\", \"5\", \"time\",\"test\",\"etest\"); String string = getdata(\"testinfo\", \"5\", \"time\",\"test\"); System.out.println(string); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//mongodb 工具类import com.alibaba.fastjson.JSONObject;import com.mongodb.MongoClient;import com.mongodb.client.FindIterable;import com.mongodb.client.MongoCollection;import com.mongodb.client.MongoCursor;import com.mongodb.client.MongoDatabase;import org.bson.Document;import org.bson.types.ObjectId;/** * Created by li on 2019/1/5. */public class MongoUtils &#123; private static MongoClient mongoClient = new MongoClient(\"192.168.37.141\",27017); public static Document findoneby(String tablename, String database,String yearbasetype)&#123; MongoDatabase mongoDatabase = mongoClient.getDatabase(database); MongoCollection mongoCollection = mongoDatabase.getCollection(tablename); Document doc = new Document(); doc.put(\"info\", yearbasetype); FindIterable&lt;Document&gt; itrer = mongoCollection.find(doc); MongoCursor&lt;Document&gt; mongocursor = itrer.iterator(); if(mongocursor.hasNext())&#123; return mongocursor.next(); &#125;else&#123; return null; &#125; &#125; public static void saveorupdatemongo(String tablename,String database,Document doc) &#123; MongoDatabase mongoDatabase = mongoClient.getDatabase(database); MongoCollection&lt;Document&gt; mongocollection = mongoDatabase.getCollection(tablename); if(!doc.containsKey(\"_id\"))&#123; ObjectId objectid = new ObjectId(); doc.put(\"_id\", objectid); mongocollection.insertOne(doc); return; &#125; Document matchDocument = new Document(); String objectid = doc.get(\"_id\").toString(); matchDocument.put(\"_id\", new ObjectId(objectid)); FindIterable&lt;Document&gt; findIterable = mongocollection.find(matchDocument); if(findIterable.iterator().hasNext())&#123; mongocollection.updateOne(matchDocument, new Document(\"$set\",doc)); try &#123; System.out.println(\"come into saveorupdatemongo ---- update---\"+ JSONObject.toJSONString(doc)); &#125; catch (Exception e) &#123;// TODO Auto-generated catch block e.printStackTrace(); &#125; &#125;else&#123; mongocollection.insertOne(doc); try &#123; System.out.println(\"come into saveorupdatemongo ---- insert---\"+JSONObject.toJSONString(doc)); &#125;catch (Exception e) &#123;// TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125; map数据处理代码: 123456789101112131415161718192021222324252627282930313233343536373839import com.youfan.entity.YearBase;import com.youfan.util.DateUtils;import com.youfan.util.HbaseUtil;import org.apache.commons.lang3.StringUtils;import org.apache.flink.api.common.functions.MapFunction;public class YearBaseMap implements MapFunction&lt;String,YearBase&gt; &#123; @Override public YearBase map(String s) throws Exception &#123; if(StringUtils.isBlank(s))&#123; return null; &#125; //因为是存储在hdfs以\",\"分隔 String [] userinfos = s.split(\",\"); String userid = userinfos[0]; String username = userinfos[1]; String sex = userinfos[2]; String telphone = userinfos[3]; String email = userinfos[4]; String age = userinfos[5]; String register = userinfos[6]; String usetype = userinfos[7]; String yearbasetype = DateUtils.getYearbasebyAge(age); String tablename = \"userflahinfo\"; String rowkey = userid; String familyname = \"baseinfo\"; String column = \"yearbase\"; //把计算以前的结果插入数据到hbase HbaseUtil.putdata(tablename,rowkey,familyname,column,yearbasetype); YearBase yearbase = new YearBase(); String groupfield = \"yearbase==\"+yearbasetype; yearbase.setYeartype(yearbasetype); yearbase.setCount(1L); yearbase.setGroupfield(groupfield); return yearbase; &#125;&#125; reduce统计代码 12345678910111213141516171819package com.youfan.reduce;import com.youfan.entity.YearBase;import org.apache.flink.api.common.functions.ReduceFunction;public class YearBaseReduce implements ReduceFunction&lt;YearBase&gt; &#123; @Override public YearBase reduce(YearBase yearBase, YearBase t1) throws Exception &#123; String yeartype = yearBase.getYeartype(); Long count1 = yearBase.getCount(); Long count2 =t1.getCount(); YearBase finalyearBase = new YearBase(); finalyearBase.setYeartype(yeartype); finalyearBase.setCount(count1+count2); return finalyearBase; &#125;&#125; 实体类 12345678910111213141516171819202122232425262728293031package com.youfan.entity;public class YearBase &#123; private String yeartype; // private Long count; private String groupfield; //分组字段 public String getGroupfield() &#123; return groupfield; &#125; public void setGroupfield(String groupfield) &#123; this.groupfield = groupfield; &#125; public String getYeartype() &#123; return yeartype; &#125; public void setYeartype(String yeartype) &#123; this.yeartype = yeartype; &#125; public Long getCount() &#123; return count; &#125; public void setCount(Long count) &#123; this.count = count; &#125;&#125; Flink 数据批处理代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.youfan.task;import com.youfan.entity.YearBase;import com.youfan.map.YearBaseMap;import com.youfan.reduce.YearBaseReduce;import com.youfan.util.MongoUtils;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.utils.ParameterTool;import org.bson.Document;import java.util.List;public class YearBaseTask &#123;public static void main(String[] args) &#123; final ParameterTool params = ParameterTool.fromArgs(args); //set up the execution environment final ExecutionEnvironment env= ExecutionEnvironment.getExecutionEnvironment(); //make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); //get input data from hdfs path(mysql -&gt;hdfs) DataSet&lt;String&gt; text=env.readTextFile(params.get(\"input\")); DataSet&lt;YearBase&gt; mapresult = text.map(new YearBaseMap()); //DataSet map = text.flatMap(null); DataSet&lt;YearBase&gt; reduce = mapresult.groupBy(\"groupbyField\").reduce(new YearBaseReduce()); try &#123; List&lt;YearBase&gt; reduceresult = reduce.collect(); //保存计算以后的结果到mongodb for(YearBase yearbase: reduceresult)&#123; String yeartype = yearbase.getYeartype(); Long count = yearbase.getCount(); Document doc = MongoUtils.findoneby(\"yearbasestatics\",\"youfanPortrait\",yeartype); if(doc == null)&#123; doc= new Document(); doc.put(\"yearbasetype\",yeartype); doc.put(\"count\",count); &#125;else&#123; Long countpre =doc.getLong(\"count\"); Long total = countpre+count; doc.put(\"count\",total); &#125; MongoUtils.saveorupdatemongo(\"yearbasestatics\",\"youfanPortrait\",doc); &#125; env.execute(\"test\"); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"实时用户画像系统(一)业务说明以及环境搭建","slug":"ceshi6","date":"2020-03-22T17:15:56.000Z","updated":"2020-03-25T04:12:44.561Z","comments":true,"path":"2020/03/23/ceshi6/","link":"","permalink":"https://etop.work/2020/03/23/ceshi6/","excerpt":"实时用户画像系统系统架构","text":"实时用户画像系统系统架构 系统架构以及来源 数据说明 基本信息: 用户表: 用户ID, 用户名,密码,性别，手机号，邮箱，年龄，户籍身份，身份证编码，注册时间，收货地址，终端类型。 用户表额外信息: 学历，收入，职业，婚姻, 是否有小孩，是否有房，电话的牌子 建库建表语句123456789101112131415161718192021222324252627CREATE DATABASE `youfanportrait`;CREATE TABLE `youfanportrait`.`userinfo` ( `userid` INT NOT NULL AUTO_INCREMENT, `username` VARCHAR(50) NULL, `password` VARCHAR(50) NULL, `sex` INT NULL, `telphone` VARCHAR(50) NULL, `email` VARCHAR(50) NULL, `age` INT NULL, `idCard` VARCHAR(50) NULL, `registertime` TIMESTAMP(0) NULL, `usertype` INT NULL, PRIMARY KEY (`userid`));CREATE TABLE `userinfodetail` ( `userdetailid` int(11) NOT NULL AUTO_INCREMENT, `userid` int(11) DEFAULT NULL, `edu` int(11) DEFAULT NULL, `profession` varchar(20) COLLATE utf8_bin DEFAULT NULL, `marriage` int(11) DEFAULT NULL, `haschild` int(11) DEFAULT NULL, `hascar` int(11) DEFAULT NULL, `hashourse` int(11) DEFAULT NULL, `telphonebrand` varchar(50) COLLATE utf8_bin DEFAULT NULL, PRIMARY KEY (`userdetailid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin idea新建maven项目新建maven项目后加入依赖: 1234567891011121314151617181920212223&lt;parent&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-examples&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;scala.version&gt;2.11.12&lt;/scala.version&gt; &lt;scala.binary.version&gt;2.11&lt;/scala.binary.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-streaming-java_$&#123;scala.binary.version&#125;&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.flink&lt;/groupId&gt; &lt;artifactId&gt;flink-scala_2.11&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 搭建hadoop环境(本机是cdh5.13.0虚拟机环境)，搭建细节不在这里详细解说了，大家可以自己下载CDH VM 同时搭建单机的mongodb，flink1.9环境(这些需要手动安装)","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://etop.work/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"友盟电商分析系统[仿]","slug":"ceshi4","date":"2020-03-22T06:52:55.000Z","updated":"2020-03-24T09:10:39.262Z","comments":true,"path":"2020/03/22/ceshi4/","link":"","permalink":"https://etop.work/2020/03/22/ceshi4/","excerpt":"友盟电商分析系统[仿]友盟官网: https://web.umeng.com/","text":"友盟电商分析系统[仿]友盟官网: https://web.umeng.com/ 本項目是一个真实的企业级云产品项目，该项目是国内专业的移动应用统计分析平台，每天触达14亿活跃设备，每月覆盖80%以上新增手机消费者，几乎覆盖全部iOS消费者，通过该项目系统帮助移动应用开发商统计和分析流量来源、内容使用、用户属性和行为数据，以便开发商利用数据进行产品、运营、推广策略的决策。提供基本统计、活跃用户、使用频率、使用时长、页面访问、地域分析、版本分析、渠道分析、设备分析、操作系统、分辨率、运营商、联网方式、自定义事件分析、终端异常分析,流失用户分析等多种统计分析手段。 项目所用到的开发环境和用到的技术 系统：window7， 开发工具是:eclipse，IDEA， 本项目是一个综合项目，技术涵盖java web，大数据，虚拟化，linux服务器等 具体包含： spring，spark，spark streaming, kafka，mongodb，dubbo,分布式缓存，docker, tomcat ,easyui，highcharts等等。 此项目是按照真实企业级开发项目流程进行开发，需要熟练掌握大数据技术，java web技术，docker虚拟化技术，分布式技术，缓存技术，linux等 (二)项目总体需求分析 1.项目背景 在这个互联网爆发的时代，移动网络，移动设备逐渐成为人们的必备品，移动设备的用户已经达到几亿，可想而知，app必将流行起来，但是每一款app都要运营，达到盈利的目的，那么这个运营怎么做呢？要借助大数据的技术，准确分析用户的行为，这必将会有很大的需求。 2.项目需求 在这个互联网爆发的时代，移动网络，移动设备逐渐成为人们的必备品，移动设备的用户已经达到几亿，可想而知，app必将流行起来，但是每一款app都要运营，达到盈利的目的，那么这个运营怎么做呢，要借助大数据的技术，准确分析用户的行为，这必将会有很大的需求。急需一个系统帮助各大中小企业快速的分析app用户的行为，只需要接入提供的sdk，就可以轻松的了解用户的行为，享受大数据技术带来的时代变革。通过该产品可以了解到：app的应用趋势，app的渠道推广情况，用户留存情况，用户的行为分析，用户属性分析，应用错误分析，用户数据挖掘，并且需要实时去展示这些分析结果。 业务名词解析: 新增用户：小白第一次安装了应用，那他就是一个新增用户 活跃用户：小白当天启动了应用，然后过了一小时又启动了应用，那他就是一个天活跃用户 沉默用户：小白第一天第一次启动了应用，然后过了2天还没有启动应用的就算沉默用户 本周回流用户：小白上上周启动了应用，上周没启动应用，本周启动了应用，那他就是一个本周回流用户 连续n周活跃用户：小白上周启动了应用，这周有启动了应用，那他就是一个连续2周活跃的用户 忠诚用户：小白连续活跃5周的，一定是连续的，那他就是一个忠诚用户 连续活跃用户：小白上上周启动了应用，上周启动了应用，本周又启动了应用，那么他就是一个连续活跃用户 近期流失用户：小白上周没有启动应用，本周又没启动应用的就算是，那么他就是一个近期流失用户 留存用户：小白今天第一次安装和启动了应用，然后过了一天后，他又启动应用，就算是一个今天这个时间的留存用户 3.系统功能 可以查看该app的用户活跃度，每个时段的新增用户，app的终端使用分类情况，沉默用户，和忠诚用户的统计和查看等。 项目架构设计以及流程 系统架构 系统前端展示效果(部分截图) （三）项目整体环境搭建 1.机器选型、节点规划等。 2.集群环境搭建 （四）相关项目内容 1.物理架构，逻辑架构 2.上报数据服务的设计与开发 3.实时处理数据的环境搭建和程序开发 4.日志收集系统设计 5.离线任务的设计和开发 6.高并发，缓存，虚拟化等","categories":[],"tags":[{"name":"数据仓库","slug":"数据仓库","permalink":"https://etop.work/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"}]},{"title":"Flink实时数据仓库系统(一)","slug":"ceshi3","date":"2020-03-22T05:32:56.000Z","updated":"2020-03-24T09:10:32.839Z","comments":true,"path":"2020/03/22/ceshi3/","link":"","permalink":"https://etop.work/2020/03/22/ceshi3/","excerpt":"欢迎使用xxx实时数据仓库系统","text":"欢迎使用xxx实时数据仓库系统 大盘 高付费用户报表 流量域分析 营销域分析 用户主题分析 实时排行榜 技术栈：FlumeKafkaHiveHbaseFlinkRedisMysql MycatSqoopHdfsMapreduceZookeeperspring bootspring cloud Vue.js+NodejsHighchartsMybatisBinlogCanalEhCache 架构图","categories":[],"tags":[{"name":"数据仓库","slug":"数据仓库","permalink":"https://etop.work/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"}]},{"title":"阿里云Dataworks+Maxcompute实时计算数据仓库方案之用户行为数仓搭建(一)","slug":"ceshi","date":"2020-03-19T03:12:23.000Z","updated":"2020-03-24T09:10:14.790Z","comments":true,"path":"2020/03/19/ceshi/","link":"","permalink":"https://etop.work/2020/03/19/ceshi/","excerpt":"数据仓库概念数据仓库定义(Data Warehouse)是为企业所有决策制定过程，提供所有系统数据支持的战略集合。数据仓库好处：可以帮助企业， 改进业务流程、 控制成本、 提高产品质量等。数据仓库做什么： 清洗，转义，分类，重组，合并，拆分，统计等。数据仓库输出到哪： 报表系统、用户画像、推荐系统、机器学习、风控系统等","text":"数据仓库概念数据仓库定义(Data Warehouse)是为企业所有决策制定过程，提供所有系统数据支持的战略集合。数据仓库好处：可以帮助企业， 改进业务流程、 控制成本、 提高产品质量等。数据仓库做什么： 清洗，转义，分类，重组，合并，拆分，统计等。数据仓库输出到哪： 报表系统、用户画像、推荐系统、机器学习、风控系统等 项目需求分析 采集埋点日志数据 采集业务数据库中数据 数据仓库的搭建（用户行为数仓、业务数仓） 分析统计业务指标 对结果进行可视化展示 项目框架阿里云产品 简介 类比 系统数据流程设计 技术选型 数据生成模块埋点数据基本格式1）公共字段：基本所有安卓手机都包含的字段 2） 业务字段：埋点上报的字段，有具体的业务类型 下面就是一个示例，表示业务字段的上传。 {“ap”:”xxxxx”,//项目数据来源 app pc “cm”: { //公共字段“mid”: “”, // (String) 设备唯一标识“uid”: “”, // (String) 用户标识“vc”: “1”, // (String) versionCode，程序版本号“vn”: “1.0”, // (String) versionName，程序版本名“l”: “zh”, // (String) language 系统语言“sr”: “”, // (String) 渠道号，应用从哪个渠道来的。“os”: “7.1.1”, // (String) Android 系统版本“ar”: “CN”, // (String) area 区域“md”: “BBB100-1”, // (String) model 手机型号“ba”: “blackberry”, // (String) brand 手机品牌“sv”: “V2.2.1”, // (String) sdkVersion“g”: “”, // (String) gmail“hw”: “1620x1080”, // (String) heightXwidth，屏幕宽高“t”: “1506047606608”, // (String) 客户端日志产生时的时间“nw”: “WIFI”, // (String) 网络模式“ln”: 0, // (double) lng 经度“la”: 0 // (double) lat 纬度},“et”: [ //事件{“ett”: “1506047605364”, //客户端事件产生时间“en”: “display”, //事件名称“kv”: { //事件结果，以 key-value 形式自行定义“goodsid”: “236”,“action”: “1”,“extend1”: “1”,“place”: “2”,“category”: “75”}}]} 示例日志（服务器时间戳 | 日志） ： 1540934156385|{“ap”: “gmall”,“cm”: {“uid”: “1234”,“vc”: “2”,“vn”: “1.0”,“la”: “EN”,“sr”: “”,“os”: “7.1.1”,“ar”: “CN”,“md”: “BBB100-1”,“ba”: “blackberry”,“sv”: “V2.2.1”,“g”: “abc@gmail.com“,“hw”: “1620x1080”,“t”: “1506047606608”,“nw”: “WIFI”,“ln”: 0},“et”: [ {“ett”: “1506047605364”, //客户端事件产生时间“en”: “display”, //事件名称“kv”: { //事件结果，以 key-value 形式自行定义“goodsid”: “236”,“action”: “1”,“extend1”: “1”,“place”: “2”,“category”: “75”}},{“ett”: “1552352626835”,“en”: “error”,“kv”: {“errorBrief”: “错误摘要”,“errorDetail”: “错误详情”}}]} } 下面是各个埋点日志格式。 其中商品点击属于信息流的范畴3.2 事件日志数据3.2.1 商品列表页（loading）事件名称： loading 标签 含义 action 动作：开始加载=1，加载成功=2，加载失败=3 loading_time 加载时长：计算下拉开始到接口返回数据的时间，（开始加载报 0，加载成 功或加载失败才上报时间） loading_way 加载类型： 1-读取缓存， 2-从接口拉新数据 （加载成功才上报加载类型） extend1 扩展字段 Extend1 extend2 扩展字段 Extend2 type 加载类型：自动加载=1，用户下拽加载=2，底部加载=3（底部条触发点击 底部提示条/点击返回顶部加载） type1 加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败） 商品曝光（display） 标签 含义 action 动作：曝光商品=1，点击商品=2， goodsid 商品 ID（服务端下发的 ID） place 顺序（第几条商品，第一条为 0，第二条为 1，如此类推） extend1 曝光类型： 1 - 首次曝光 2-重复曝光 category 分类 ID（服务端定义的分类 ID） 商品详情页 action 动作：开始加载=1，加载成功=2（ pv），加载失败=3, 退出页面=4 goodsid 商品 ID（服务端下发的 ID） show_style 商品样式： 0、无图、 1、一张大图、 2、两张图、 3、三张小图、 4、一张小图、 5、 一张大图两张小图 news_staytime 页面停留时长：从商品开始加载时开始计算，到用户关闭页面所用的时间。若中途 用跳转到其它页面了，则暂停计时，待回到详情页时恢复计时。或中途划出的时间 超过 10 分钟，则本次计时作废，不上报本次数据。如未加载成功退出，则报空。 loading_time 加载时长：计算页面开始加载到接口返回数据的时间 （开始加载报 0，加载成功或 加载失败才上报时间） type1 加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败） category 分类 ID（服务端定义的分类 ID） 购物车（cart） 标签 含义 itemid 商品 action 操作类型： 1 添加购物车； 2 改变商品数量； 3 移除商品 change_num 加减数量 before_num 更改前数量 after_num 更改后数量 price 商品单价 广告（ad） 标签 含义 entry 入口：商品列表页=1 应用首页=2 商品详情页=3 action 动作：请求广告=1 取缓存广告=2 广告位展示=3 广告展示=4 广告点击=5 content 状态：成功=1 失败=2 detail 失败码（没有则上报空） source 广告来源:admob=1 facebook=2 ADX（百度） =3 VK（头条） =4 behavior 用户行为： 主动获取广告=1 被动获取广告=2 newstype Type: 1- 图文 2-图集 3-段子 4-GIF 5-视频 6-调查 7-纯文 8-视频+图文 9-GI F+图文 0-其他 show_style 内容样式：无图(纯文字)=6 一张大图=1 三站小图+文=4 一张小图=2 一张大图 两张小图+文=3 图集+文 = 5 一张大图+文=11 GIF 大图+文=12 视频(大图)+文 = 13 来源于详情页相关推荐的商品，上报样式都为 0（因为都是左文右图） 消息通知（notification） 标签 含义 action 动作：通知产生=1，通知弹出=2，通知点击=3，常驻通知展示（不重复上报， 一天之内只报一次） =4 type 通知 id：预警通知=1，天气预报（早=2，晚=3），常驻=4 ap_time 客户端弹出时间 content 备用字段 评论（comment） 标签 含义 字段类型 长度 允许空 缺省值 comment_id 评论表 int 10,0 userid 用户 id int 10,0 √ 0 p_comment_id 父级评论 id(为 0 则是一 级评论,不为 0 则是回复) int 10,0 √ content 评论内容 string 1000 √ addtime 创建时间 string √ other_id 评论的相关 id int 10,0 √ praise_count 点赞数量 int 10,0 √ 0 reply_count 回复数量 int 10,0 √ 0 收藏（favorites） 标签 含义 字段类型 长度 允许空 缺省值 id 主键 int 10,0 course_id 商品 id int 10,0 √ 0 userid 用户 ID int 10,0 √ 0 add_time 创建时间 string √ 点赞（praise） 标签 含义 字段类型 长度 允许空 缺省值 id 主键 id int 10,0 userid 用户 id int 10,0 √ target_id 点赞的对象 id int 10,0 √ type 点赞类型 1 问答点赞 2 问 答评论点赞 3 文章点赞数 4 评论点赞 int 10,0 √ add_time 添加时间 string √ 错误日志（error） 标签 含义 errorBrief 错误摘要 errorDetail 错误详情 启动日志数据（start） 标签 含义 entry 入 口 ： push=1 ， widget=2 ， icon=3 ， notification=4, lockscreen_widget =5 open_ad_type 开屏广告类型: 开屏原生广告=1, 开屏插屏广告=2 action 状态：成功=1 失败=2 loading_time 加载时长：计算下拉开始到接口返回数据的时间，（开始加载报 0，加载 成功或加载失败才上报时间） detail 失败码（没有则上报空） extend1 失败的 message（没有则上报空） en 日志类型 start 数据生成脚本创建 Maven 工程1） 创建 log-collector 2）创建一个包名： com.atguigu.appclient3） 在 com.atguigu.appclient 包下创建一个类， AppMain。4） 在 pom.xml 文件中添加如下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!--版本号统一--&gt;&lt;properties&gt;&lt;slf4j.version&gt;1.7.20&lt;/slf4j.version&gt;&lt;logback.version&gt;1.0.7&lt;/logback.version&gt;&lt;/properties&gt;&lt;dependencies&gt;&lt;!--阿里巴巴开源 json 解析框架--&gt;&lt;dependency&gt;&lt;groupId&gt;com.alibaba&lt;/groupId&gt;&lt;artifactId&gt;fastjson&lt;/artifactId&gt;&lt;version&gt;1.2.51&lt;/version&gt;&lt;/dependency&gt;&lt;!--日志生成框架--&gt;&lt;dependency&gt;&lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;&lt;artifactId&gt;logback-core&lt;/artifactId&gt;&lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;&lt;artifactId&gt;logback-classic&lt;/artifactId&gt;&lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; &lt;!--编译打包插件--&gt;&lt;build&gt;&lt;plugins&gt;&lt;plugin&gt;&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;&lt;version&gt;2.3.2&lt;/version&gt;&lt;configuration&gt;&lt;source&gt;1.8&lt;/source&gt;&lt;target&gt;1.8&lt;/target&gt;&lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt;&lt;artifactId&gt;maven-assembly-plugin &lt;/artifactId&gt;&lt;configuration&gt;&lt;descriptorRefs&gt;&lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;&lt;/descriptorRefs&gt;&lt;archive&gt;&lt;manifest&gt;&lt;mainClass&gt;com.atguigu.appclient.AppMain&lt;/mainClass&gt;&lt;/manifest&gt;&lt;/archive&gt;&lt;/configuration&gt;&lt;executions&gt;&lt;execution&gt;&lt;id&gt;make-assembly&lt;/id&gt;&lt;phase&gt;package&lt;/phase&gt;&lt;goals&gt;&lt;goal&gt;single&lt;/goal&gt;&lt;/goals&gt;&lt;/execution&gt;&lt;/executions&gt;&lt;/plugin&gt;&lt;/plugins&gt;&lt;/build&gt; 注意： com.atguigu.appclient.AppMain 要和自己建的全类名一致。 公共字段 Bean1） 创建包名： com.atguigu.bean2） 在 com.atguigu.bean 包下依次创建如下 bean 对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package com.atguigu.bean;/***公共日志*/public class AppBase&#123;private String mid; // (String) 设备唯一标识private String uid; // (String) 用户 uidprivate String vc; // (String) versionCode，程序版本号private String vn; // (String) versionName，程序版本名private String l; // (String) 系统语言private String sr; // (String) 渠道号，应用从哪个渠道来的。private String os; // (String) Android 系统版本private String ar; // (String) 区域private String md; // (String) 手机型号private String ba; // (String) 手机品牌private String sv; // (String) sdkVersionprivate String g; // (String) gmail private String hw; // (String) heightXwidth，屏幕宽高private String t; // (String) 客户端日志产生时的时间private String nw; // (String) 网络模式private String ln; // (double) lng 经度private String la; // (double) lat 纬度public String getMid() &#123;return mid;&#125;public void setMid(String mid) &#123;this.mid = mid;&#125;public String getUid() &#123;return uid;&#125;public void setUid(String uid) &#123;this.uid = uid;&#125;public String getVc() &#123;return vc;&#125;public void setVc(String vc) &#123;this.vc = vc;&#125;public String getVn() &#123;return vn;&#125;public void setVn(String vn) &#123;this.vn = vn;&#125;public String getL() &#123;return l;&#125;public void setL(String l) &#123;this.l = l;&#125;public String getSr() &#123;return sr;&#125;public void setSr(String sr) &#123;this.sr = sr;&#125;public String getOs() &#123;return os;&#125;public void setOs(String os) &#123;this.os = os;&#125;public String getAr() &#123; return ar;&#125;public void setAr(String ar) &#123;this.ar = ar;&#125;public String getMd() &#123;return md;&#125;public void setMd(String md) &#123;this.md = md;&#125;public String getBa() &#123;return ba;&#125;public void setBa(String ba) &#123;this.ba = ba;&#125;public String getSv() &#123;return sv;&#125;public void setSv(String sv) &#123;this.sv = sv;&#125;public String getG() &#123;return g;&#125;public void setG(String g) &#123;this.g = g;&#125;public String getHw() &#123;return hw;&#125;public void setHw(String hw) &#123;this.hw = hw;&#125;public String getT() &#123;return t;&#125;public void setT(String t) &#123;this.t = t;&#125;public String getNw() &#123;return nw;&#125;public void setNw(String nw) &#123;this.nw = nw;&#125; public String getLn() &#123;return ln;&#125;public void setLn(String ln) &#123;this.ln = ln;&#125;public String getLa() &#123;return la;&#125;public void setLa(String la) &#123;this.la = la;&#125;&#125; 启动日志 Bean123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.atguigu.bean;/*** 启动日志*/public class AppStart extends AppBase &#123;private String entry;//入口： push=1， widget=2， icon=3， notification=4,lockscreen_widget =5private String open_ad_type;//开屏广告类型: 开屏原生广告=1, 开屏插屏广告=2private String action;//状态：成功=1 失败=2private String loading_time;//加载时长：计算下拉开始到接口返回数据的时间，（开始加载报 0，加载成功或加载失败才上报时间）private String detail;//失败码（没有则上报空）private String extend1;//失败的 message（没有则上报空）private String en;//启动日志类型标记public String getEntry() &#123;return entry;&#125;public void setEntry(String entry) &#123;this.entry = entry;&#125;public String getOpen_ad_type() &#123;return open_ad_type;&#125;public void setOpen_ad_type(String open_ad_type) &#123;this.open_ad_type = open_ad_type;&#125;public String getAction() &#123;return action;&#125;public void setAction(String action) &#123;this.action = action;&#125;public String getLoading_time() &#123;return loading_time;&#125;public void setLoading_time(String loading_time) &#123;this.loading_time = loading_time;&#125;public String getDetail() &#123;return detail;&#125;public void setDetail(String detail) &#123;this.detail = detail;&#125;public String getExtend1() &#123;return extend1;&#125;public void setExtend1(String extend1) &#123;this.extend1 = extend1;&#125;public String getEn() &#123;return en;&#125;public void setEn(String en) &#123;this.en = en;&#125;&#125; 错误日志 Bean1234567891011121314151617181920package com.atguigu.bean;/*** 错误日志*/public class AppError &#123;private String errorBrief; //错误摘要private String errorDetail; //错误详情public String getErrorBrief() &#123;return errorBrief;&#125;public void setErrorBrief(String errorBrief) &#123;this.errorBrief = errorBrief;&#125;public String getErrorDetail() &#123;return errorDetail;&#125;public void setErrorDetail(String errorDetail) &#123;this.errorDetail = errorDetail;&#125;&#125; 事件日志 Bean 之商品曝光123456789101112131415161718192021222324252627282930313233343536373839404142package com.atguigu.bean;/**** 商品点击日志 */ public class AppDisplay &#123; private String action;//动作：曝光商品=1，点击商品=2， private String goodsid;//商品 ID（服务端下发的 ID） private String place;//顺序（第几条商品，第一条为 0，第二条为 1，如此类推） private String extend1;//曝光类型： 1 - 首次曝光 2-重复曝光（没有使用） private String category;//分类 ID（服务端定义的分类 ID） public String getAction() &#123; return action; &#125; public void setAction(String action) &#123; this.action = action; &#125; public String getGoodsid() &#123; return goodsid; &#125; public void setGoodsid(String goodsid) &#123; this.goodsid = goodsid; &#125; public String getPlace() &#123; return place; &#125; public void setPlace(String place) &#123; this.place = place; &#125; public String getExtend1() &#123; return extend1; &#125; public void setExtend1(String extend1) &#123; this.extend1 = extend1; &#125; public String getCategory() &#123; return category; &#125; public void setCategory(String category) &#123; this.category = category; &#125; &#125; 事件日志 Bean 之商品详情页123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.atguigu.bean;/*** 商品详情*/public class AppNewsDetail &#123;private String entry;//页面入口来源：应用首页=1、 push=2、详情页相关推荐=3private String action;//动作：开始加载=1，加载成功=2（pv），加载失败=3, 退出页面=4private String goodsid;//商品 ID（服务端下发的 ID）private String showtype;//商品样式： 0、无图 1、一张大图 2、两张图 3、三张小图 4、一张小图 5、一张大图两张小图 来源于详情页相关推荐的商品，上报样式都为 0（因为都是左文右图）private String news_staytime;//页面停留时长：从商品开始加载时开始计算，到用户关闭页面所用的时间。若中途用跳转到其它页面了，则暂停计时，待回到详情页时恢复计时。或中途划出的时间超过 10 分钟，则本次计时作废，不上报本次数据。如未加载成功退出，则报空。private String loading_time;//加载时长：计算页面开始加载到接口返回数据的时间（开始加载报 0，加载成功或加载失败才上报时间）private String type1;//加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败）private String category;//分类 ID（服务端定义的分类 ID）public String getEntry() &#123;return entry;&#125;public void setEntry(String entry) &#123;this.entry = entry;&#125;public String getAction() &#123;return action;&#125;public void setAction(String action) &#123;this.action = action;&#125;public String getGoodsid() &#123;return goodsid;&#125;public void setGoodsid(String goodsid) &#123;this.goodsid = goodsid;&#125;public String getShowtype() &#123;return showtype;&#125;public void setShowtype(String showtype) &#123;this.showtype = showtype;&#125;public String getNews_staytime() &#123;return news_staytime;&#125;public void setNews_staytime(String news_staytime) &#123;this.news_staytime = news_staytime;&#125;public String getLoading_time() &#123;return loading_time;&#125;public void setLoading_time(String loading_time) &#123;this.loading_time = loading_time;&#125;public String getType1() &#123;return type1;&#125;public void setType1(String type1) &#123;this.type1 = type1;&#125;public String getCategory() &#123;return category;&#125;public void setCategory(String category) &#123;this.category = category;&#125;&#125; 事件日志 Bean 之商品列表页1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.atguigu.bean;/*** 商品列表*/public class AppLoading &#123;private String action;//动作：开始加载=1，加载成功=2，加载失败=3private String loading_time;//加载时长：计算下拉开始到接口返回数据的时间，（开始加载报 0，加载成功或加载失败才上报时间）private String loading_way;//加载类型： 1-读取缓存， 2-从接口拉新数据 （加载成功才上报加载类型）private String extend1;//扩展字段 Extend1private String extend2;//扩展字段 Extend2private String type;//加载类型：自动加载=1，用户下拽加载=2，底部加载=3（底部条触发点击底部提示条/点击返回顶部加载）private String type1;//加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败）public String getAction() &#123;return action;&#125;public void setAction(String action) &#123;this.action = action;&#125;public String getLoading_time() &#123;return loading_time;&#125;public void setLoading_time(String loading_time) &#123;this.loading_time = loading_time;&#125;public String getLoading_way() &#123;return loading_way;&#125;public void setLoading_way(String loading_way) &#123;this.loading_way = loading_way;&#125;public String getExtend1() &#123;return extend1;&#125;public void setExtend1(String extend1) &#123;this.extend1 = extend1;&#125;public String getExtend2() &#123;return extend2;&#125;public void setExtend2(String extend2) &#123;this.extend2 = extend2;&#125;public String getType() &#123;return type;&#125;public void setType(String type) &#123;this.type = type;&#125;public String getType1() &#123;return type1;&#125;public void setType1(String type1) &#123;this.type1 = type1;&#125;&#125; 事件日志 Bean 之购物车123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.atguigu.bean;/*** 购物车*/public class AppCart &#123;int itemid;int action; // 1 添加产品进购物车 2 调整购物车数量int changeNum; // 数量变化int beforeNum; // 变化前数量int afterNum; // 变化后数量Double price; // 加入购物车时的单价public int getItemid() &#123;return itemid;&#125;public void setItemid(int itemid) &#123;this.itemid = itemid;&#125;public int getAction() &#123;return action;&#125;public void setAction(int action) &#123;this.action = action;&#125;public int getChangeNum() &#123;return changeNum;&#125;public void setChangeNum(int changeNum) &#123;this.changeNum = changeNum;&#125;public int getBeforeNum() &#123;return beforeNum;&#125;public void setBeforeNum(int beforeNum) &#123;this.beforeNum = beforeNum;&#125;public int getAfterNum() &#123;return afterNum;&#125;public void setAfterNum(int afterNum) &#123;this.afterNum = afterNum;&#125;public Double getPrice() &#123;return price;&#125;public void setPrice(Double price) &#123;this.price = price;&#125;&#125; 事件日志 Bean 之广告123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.atguigu.bean;&#x2F;*** 广告*&#x2F;public class AppAd &#123;private String entry;&#x2F;&#x2F;入口：商品列表页&#x3D;1 应用首页&#x3D;2 商品详情页&#x3D;3private String action;&#x2F;&#x2F;动作：请求广告&#x3D;1 取缓存广告&#x3D;2 广告位展示&#x3D;3 广告展示&#x3D;4 广告点击&#x3D;5private String content;&#x2F;&#x2F;状态：成功&#x3D;1 失败&#x3D;2private String detail;&#x2F;&#x2F;失败码（没有则上报空）private String source;&#x2F;&#x2F;广告来源:admob&#x3D;1 facebook&#x3D;2 ADX（百度） &#x3D;3 VK（俄罗斯） &#x3D;4private String behavior;&#x2F;&#x2F;用户行为： 主动获取广告&#x3D;1 被动获取广告&#x3D;2private String newstype;&#x2F;&#x2F;Type: 1- 图文 2-图集 3-段子 4-GIF 5-视频 6-调查7-纯文 8-视频+图文 9-GIF+图文 0-其他private String show_style;&#x2F;&#x2F;内容样式：无图(纯文字)&#x3D;6 一张大图&#x3D;1 三站小图+文&#x3D;4 一张小图&#x3D;2 一张大图两张小图+文&#x3D;3 图集+文 &#x3D; 5&#x2F;&#x2F;一张大图+文&#x3D;11 GIF 大图+文&#x3D;12 视频(大图)+文 &#x3D; 13&#x2F;&#x2F;来源于详情页相关推荐的商品，上报样式都为 0（因为都是左文右图）public String getEntry() &#123;return entry;&#125;public void setEntry(String entry) &#123;this.entry &#x3D; entry;&#125;public String getAction() &#123;return action;&#125;public void setAction(String action) &#123;this.action &#x3D; action;&#125;public String getContent() &#123;return content;&#125;public void setContent(String content) &#123;this.content &#x3D; content;&#125;public String getDetail() &#123;return detail;&#125;public void setDetail(String detail) &#123;this.detail &#x3D; detail;&#125;public String getSource() &#123;return source;&#125;public void setSource(String source) &#123;this.source &#x3D; source;&#125;public String getBehavior() &#123;return behavior;&#125;public void setBehavior(String behavior) &#123;this.behavior &#x3D; behavior;&#125; public String getNewstype() &#123;return newstype;&#125;public void setNewstype(String newstype) &#123;this.newstype &#x3D; newstype;&#125;public String getShow_style() &#123;return show_style;&#125;public void setShow_style(String show_style) &#123;this.show_style &#x3D; show_style;&#125;&#125; 事件日志 Bean 之消息通知1234567891011121314151617181920212223242526272829303132333435package com.atguigu.bean;/*** 消息通知日志*/public class AppNotification &#123;private String action;//动作：通知产生=1，通知弹出=2，通知点击=3，常驻通知展示（不重复上报，一天之内只报一次） =4private String type;//通知 id：预警通知=1，天气预报（早=2，晚=3），常驻=4private String ap_time;//客户端弹出时间private String content;//备用字段public String getAction() &#123;return action;&#125;public void setAction(String action) &#123;this.action = action;&#125;public String getType() &#123;return type;&#125;public void setType(String type) &#123;this.type = type;&#125;public String getAp_time() &#123;return ap_time;&#125;public void setAp_time(String ap_time) &#123;this.ap_time = ap_time;&#125;public String getContent() &#123;return content;&#125;public void setContent(String content) &#123;this.content = content;&#125;&#125; 事件日志 Bean 之用户评论1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.atguigu.bean;&#x2F;*** 评论*&#x2F;public class AppComment &#123;private int comment_id;&#x2F;&#x2F;评论表private int userid;&#x2F;&#x2F;用户 idprivate int p_comment_id;&#x2F;&#x2F;父级评论 id(为 0 则是一级评论,不为 0 则是回复)private String content;&#x2F;&#x2F;评论内容private String addtime;&#x2F;&#x2F;创建时间private int other_id;&#x2F;&#x2F;评论的相关 idprivate int praise_count;&#x2F;&#x2F;点赞数量private int reply_count;&#x2F;&#x2F;回复数量public int getComment_id() &#123;return comment_id;&#125;public void setComment_id(int comment_id) &#123;this.comment_id &#x3D; comment_id;&#125;public int getUserid() &#123;return userid;&#125;public void setUserid(int userid) &#123;this.userid &#x3D; userid;&#125;public int getP_comment_id() &#123;return p_comment_id;&#125;public void setP_comment_id(int p_comment_id) &#123;this.p_comment_id &#x3D; p_comment_id;&#125;public String getContent() &#123;return content;&#125;public void setContent(String content) &#123;this.content &#x3D; content;&#125;public String getAddtime() &#123;return addtime;&#125;public void setAddtime(String addtime) &#123;this.addtime &#x3D; addtime;&#125;public int getOther_id() &#123;return other_id;&#125;public void setOther_id(int other_id) &#123;this.other_id &#x3D; other_id;&#125;public int getPraise_count() &#123;return praise_count;&#125;public void setPraise_count(int praise_count) &#123;this.praise_count &#x3D; praise_count;&#125;public int getReply_count() &#123;return reply_count;&#125;public void setReply_count(int reply_count) &#123;this.reply_count &#x3D; reply_count;&#125;&#125; 事件日志 Bean 之用户收藏12345678910111213141516171819202122232425262728293031323334package com.atguigu.bean;/*** 收藏*/public class AppFavorites &#123;private int id;//主键private int course_id;//商品 idprivate int userid;//用户 IDprivate String add_time;//创建时间public int getId() &#123;return id;&#125;public void setId(int id) &#123;this.id = id;&#125;public int getCourse_id() &#123;return course_id;&#125;public void setCourse_id(int course_id) &#123;this.course_id = course_id;&#125;public int getUserid() &#123;return userid;&#125;public void setUserid(int userid) &#123;this.userid = userid;&#125;public String getAdd_time() &#123;return add_time;&#125;public void setAdd_time(String add_time) &#123;this.add_time = add_time;&#125;&#125; 事件日志 Bean 之用户点赞1234567891011121314151617181920212223242526272829303132333435363738394041package com.atguigu.bean;/*** 点赞*/public class AppPraise &#123;private int id; //主键 idprivate int userid;//用户 idprivate int target_id;//点赞的对象 idprivate int type;//点赞类型 1 问答点赞 2 问答评论点赞 3 文章点赞数 4 评论点赞private String add_time;//添加时间public int getId() &#123;return id;&#125;public void setId(int id) &#123;this.id = id;&#125;public int getUserid() &#123;return userid;&#125;public void setUserid(int userid) &#123;this.userid = userid;&#125;public int getTarget_id() &#123;return target_id;&#125;public void setTarget_id(int target_id) &#123;this.target_id = target_id;&#125;public int getType() &#123;return type;&#125;public void setType(int type) &#123;this.type = type;&#125;public String getAdd_time() &#123;return add_time;&#125;public void setAdd_time(String add_time) &#123;this.add_time = add_time;&#125;&#125; 主函数 在 AppMain 类中添加如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598package com.atguigu.appclient;import java.io.UnsupportedEncodingException;import java.util.Random;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONArray;import com.alibaba.fastjson.JSONObject;import com.atguigu.bean.*;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/*** 日志行为数据模拟*/public class AppMain &#123;private final static Logger logger =LoggerFactory.getLogger(AppMain.class);private static Random rand = new Random();// 设备 idprivate static int s_mid = 0;// 用户 idprivate static int s_uid = 0;// 商品 idprivate static int s_goodsid = 0;public static void main(String[] args) &#123;// 参数一：控制发送每条的延时时间，默认是 0Long delay = args.length &gt; 0 ? Long.parseLong(args[0]) : 0L;// 参数二：循环遍历次数int loop_len = args.length &gt; 1 ? Integer.parseInt(args[1]) : 1000;// 生成数据generateLog(delay, loop_len);&#125;private static void generateLog(Long delay, int loop_len) &#123;for (int i = 0; i &lt; loop_len; i++) &#123;JSONObject json = new JSONObject();json.put(\"ap\", \"app\");json.put(\"cm\", generateComFields());JSONArray eventsArray = new JSONArray();// 启动日志eventsArray.add(generateStart());// 事件日志// 商品曝光if (rand.nextBoolean()) &#123;eventsArray.add(generateDisplay());&#125;// 商品详情页if (rand.nextBoolean()) &#123;eventsArray.add(generateNewsDetail());&#125;// 商品列表页if (rand.nextBoolean()) &#123;eventsArray.add(generateNewList());&#125;// 购物车if (rand.nextBoolean()) &#123;eventsArray.add(generateCart());&#125;// 广告if (rand.nextBoolean()) &#123;eventsArray.add(generateAd());&#125;// 消息通知if (rand.nextBoolean()) &#123;eventsArray.add(generateNotification());&#125;//故障日志if (rand.nextBoolean()) &#123;eventsArray.add(generateError());&#125;// 用户评论if (rand.nextBoolean()) &#123;eventsArray.add(generateComment());&#125;// 用户收藏if (rand.nextBoolean()) &#123;eventsArray.add(generateFavorites());&#125;// 用户点赞if (rand.nextBoolean()) &#123;eventsArray.add(generatePraise());&#125;json.put(\"et\", eventsArray);//时间long millis2 = System.currentTimeMillis();//控制台打印logger.info(millis2 + \"|\" + json.toJSONString());// 延迟try &#123;Thread.sleep(delay);&#125; catch (InterruptedException e) &#123;e.printStackTrace();&#125;&#125;&#125;/*** 公共字段设置*/private static JSONObject generateComFields() &#123;AppBase appBase = new AppBase();//设备 idappBase.setMid(s_mid + \"\");s_mid++;// 用户 idappBase.setUid(s_uid + \"\");s_uid++;// 程序版本号 5,6 等appBase.setVc(\"\" + rand.nextInt(20));//程序版本名 v1.1.1appBase.setVn(\"1.\" + rand.nextInt(4) + \".\" + rand.nextInt(10));// 安卓系统版本appBase.setOs(\"8.\" + rand.nextInt(3) + \".\" + rand.nextInt(10));// 语言 es,en,ptint flag = rand.nextInt(3);switch (flag) &#123;case (0):appBase.setL(\"es\");break;case (1):appBase.setL(\"en\");break;case (2):appBase.setL(\"pt\");break;&#125;// 渠道号 从哪个渠道来的appBase.setSr(getRandomChar(1));// 区域flag = rand.nextInt(2);switch (flag) &#123;case 0:appBase.setAr(\"BR\");case 1:appBase.setAr(\"MX\");&#125;// 手机品牌 ba ,手机型号 md，就取 2 位数字了flag = rand.nextInt(3);switch (flag) &#123;case 0:appBase.setBa(\"Sumsung\");appBase.setMd(\"sumsung-\" + rand.nextInt(20));break;case 1:appBase.setBa(\"Huawei\");appBase.setMd(\"Huawei-\" + rand.nextInt(20));break;case 2:appBase.setBa(\"HTC\");appBase.setMd(\"HTC-\" + rand.nextInt(20));break;&#125;// 嵌入 sdk 的版本appBase.setSv(\"V2.\" + rand.nextInt(10) + \".\" + rand.nextInt(10));// gmailappBase.setG(getRandomCharAndNumr(8) + \"@gmail.com\");// 屏幕宽高 hwflag = rand.nextInt(4);switch (flag) &#123;case 0:appBase.setHw(\"640*960\");break;case 1:appBase.setHw(\"640*1136\");break;case 2:appBase.setHw(\"750*1134\");break;case 3:appBase.setHw(\"1080*1920\");break;&#125;// 客户端产生日志时间long millis = System.currentTimeMillis();appBase.setT(\"\" + (millis - rand.nextInt(99999999)));// 手机网络模式 3G,4G,WIFIflag = rand.nextInt(3);switch (flag) &#123;case 0:appBase.setNw(\"3G\");break;case 1:appBase.setNw(\"4G\");break;case 2:appBase.setNw(\"WIFI\");break;&#125;// 拉丁美洲 西经 34°46′至西经 117°09；北纬 32°42′至南纬 53°54′// 经度appBase.setLn((-34 - rand.nextInt(83) - rand.nextInt(60) / 10.0) +\"\");// 纬度appBase.setLa((32 - rand.nextInt(85) - rand.nextInt(60) / 10.0) +\"\");return (JSONObject) JSON.toJSON(appBase);&#125;/*** 商品展示事件*/private static JSONObject generateDisplay() &#123;AppDisplay appDisplay = new AppDisplay();boolean boolFlag = rand.nextInt(10) &lt; 7;// 动作：曝光商品=1，点击商品=2，if (boolFlag) &#123;appDisplay.setAction(\"1\");&#125; else &#123;appDisplay.setAction(\"2\");&#125;// 商品 idString goodsId = s_goodsid + \"\";s_goodsid++;appDisplay.setGoodsid(goodsId);// 顺序 设置成 6 条吧int flag = rand.nextInt(6);appDisplay.setPlace(\"\" + flag);// 曝光类型flag = 1 + rand.nextInt(2);appDisplay.setExtend1(\"\" + flag);// 分类flag = 1 + rand.nextInt(100);appDisplay.setCategory(\"\" + flag);JSONObject jsonObject = (JSONObject) JSON.toJSON(appDisplay);return packEventJson(\"display\", jsonObject);&#125;/*** 商品详情页*/private static JSONObject generateNewsDetail() &#123;AppNewsDetail appNewsDetail = new AppNewsDetail();// 页面入口来源int flag = 1 + rand.nextInt(3);appNewsDetail.setEntry(flag + \"\");// 动作appNewsDetail.setAction(\"\" + (rand.nextInt(4) + 1));// 商品 idappNewsDetail.setGoodsid(s_goodsid + \"\");// 商品来源类型flag = 1 + rand.nextInt(3);appNewsDetail.setShowtype(flag + \"\");// 商品样式flag = rand.nextInt(6);appNewsDetail.setShowtype(\"\" + flag);// 页面停留时长flag = rand.nextInt(10) * rand.nextInt(7);appNewsDetail.setNews_staytime(flag + \"\");// 加载时长flag = rand.nextInt(10) * rand.nextInt(7);appNewsDetail.setLoading_time(flag + \"\");// 加载失败码flag = rand.nextInt(10);switch (flag) &#123;case 1:appNewsDetail.setType1(\"102\");break;case 2:appNewsDetail.setType1(\"201\");break;case 3:appNewsDetail.setType1(\"325\");break;case 4:appNewsDetail.setType1(\"433\");break;case 5:appNewsDetail.setType1(\"542\");break;default:appNewsDetail.setType1(\"\");break;&#125;// 分类flag = 1 + rand.nextInt(100);appNewsDetail.setCategory(\"\" + flag);JSONObject eventJson = (JSONObject) JSON.toJSON(appNewsDetail);return packEventJson(\"newsdetail\", eventJson);&#125;/*** 商品列表*/private static JSONObject generateNewList() &#123;AppLoading appLoading = new AppLoading();// 动作int flag = rand.nextInt(3) + 1;appLoading.setAction(flag + \"\");// 加载时长flag = rand.nextInt(10) * rand.nextInt(7);appLoading.setLoading_time(flag + \"\");// 失败码flag = rand.nextInt(10);switch (flag) &#123;case 1:appLoading.setType1(\"102\");break;case 2:appLoading.setType1(\"201\");break;case 3:appLoading.setType1(\"325\");break;case 4:appLoading.setType1(\"433\");break;case 5:appLoading.setType1(\"542\");break;default:appLoading.setType1(\"\");break;&#125;// 页面 加载类型flag = 1 + rand.nextInt(2);appLoading.setLoading_way(\"\" + flag);// 扩展字段 1appLoading.setExtend1(\"\");// 扩展字段 2appLoading.setExtend2(\"\");// 用户加载类型flag = 1 + rand.nextInt(3);appLoading.setType(\"\" + flag);JSONObject jsonObject = (JSONObject) JSON.toJSON(appLoading);return packEventJson(\"loading\", jsonObject);&#125;/*** 购物车*/static public JSONObject generateCart() &#123;AppCart appItemCart = new AppCart();appItemCart.setItemid(s_mid);appItemCart.setBeforeNum(1 + rand.nextInt(3));appItemCart.setAction(1 + rand.nextInt(2));if (appItemCart.getAction() == 2) &#123;int changNum = (-1) + rand.nextInt(3);changNum = (changNum == 0 ? 1 : changNum);appItemCart.setChangeNum(changNum);appItemCart.setAfterNum(appItemCart.getBeforeNum() +appItemCart.getChangeNum());&#125;JSONObject jsonObject = (JSONObject) JSON.toJSON(appItemCart);return packEventJson(\"favorites\", jsonObject);&#125;/*** 广告相关字段*/private static JSONObject generateAd() &#123;AppAd appAd = new AppAd();// 入口int flag = rand.nextInt(3) + 1;appAd.setEntry(flag + \"\");// 动作flag = rand.nextInt(5) + 1;appAd.setAction(flag + \"\");// 状态flag = rand.nextInt(10) &gt; 6 ? 2 : 1;appAd.setContent(flag + \"\");// 失败码flag = rand.nextInt(10);switch (flag) &#123;case 1:appAd.setDetail(\"102\");break;case 2:appAd.setDetail(\"201\");break;case 3:appAd.setDetail(\"325\");break;case 4:appAd.setDetail(\"433\");break;case 5:appAd.setDetail(\"542\");break;default:appAd.setDetail(\"\");break;&#125;// 广告来源flag = rand.nextInt(4) + 1;appAd.setSource(flag + \"\");// 用户行为flag = rand.nextInt(2) + 1;appAd.setBehavior(flag + \"\");// 商品类型flag = rand.nextInt(10);appAd.setNewstype(\"\" + flag);// 展示样式flag = rand.nextInt(6);appAd.setShow_style(\"\" + flag);JSONObject jsonObject = (JSONObject) JSON.toJSON(appAd);return packEventJson(\"ad\", jsonObject);&#125;/*** 启动日志*/static JSONObject generateStart() &#123;AppStart appStart = new AppStart();// 入口int flag = rand.nextInt(5) + 1;appStart.setEntry(flag + \"\");// 开屏广告类型flag = rand.nextInt(2) + 1;appStart.setOpen_ad_type(flag + \"\");// 状态flag = rand.nextInt(10) &gt; 8 ? 2 : 1;appStart.setAction(flag + \"\");// 加载时长appStart.setLoading_time(rand.nextInt(20) + \"\");// 失败码flag = rand.nextInt(10);switch (flag) &#123;case 1:appStart.setDetail(\"102\");break;case 2:appStart.setDetail(\"201\");break;case 3:appStart.setDetail(\"325\");break;case 4:appStart.setDetail(\"433\");break;case 5:appStart.setDetail(\"542\");break;default:appStart.setDetail(\"\");break;&#125;JSONObject jsonObject = (JSONObject) JSON.toJSON(appStart);return packEventJson(\"start\", jsonObject);&#125;/*** 消息通知*/private static JSONObject generateNotification() &#123;AppNotification appNotification = new AppNotification();int flag = rand.nextInt(4) + 1;// 动作appNotification.setAction(flag + \"\");// 通知 idflag = rand.nextInt(4) + 1;appNotification.setType(flag + \"\");// 客户端弹时间appNotification.setAp_time((System.currentTimeMillis() -rand.nextInt(99999999)) + \"\");// 备用字段appNotification.setContent(\"\");JSONObject jsonObject = (JSONObject) JSON.toJSON(appNotification);return packEventJson(\"notification\", jsonObject);&#125;/*** 错误日志数据*/private static JSONObject generateError() &#123;AppError appErrorLog = new AppError();String[] errorBriefs = &#123;\"atcn.lift.dfdf.web.AbstractBaseController.validInbound(AbstractBaseController.java:72)\", \"atcn.lift.appIn.control.CommandUtil.getInfo(CommandUtil.java:67)\"&#125;;//错误摘要String[] errorDetails = &#123;\"java.lang.NullPointerException\\\\n \" +\"atcn.lift.appIn.web.AbstractBaseController.validInbound(AbstractBaseController.java:72)\\\\n \" + \"atcn.lift.dfdf.web.AbstractBaseController.validInbound\", \"atcn.lift.dfdfdf.control.CommandUtil.getInfo(CommandUtil.java:67)\\\\n \" +\"atsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\\\n\" + \" atjava.lang.reflect.Method.invoke(Method.java:606)\\\\n\"&#125;; //错误详情//错误摘要appErrorLog.setErrorBrief(errorBriefs[rand.nextInt(errorBriefs.length)]);//错误详情appErrorLog.setErrorDetail(errorDetails[rand.nextInt(errorDetails.length)]);JSONObject jsonObject = (JSONObject) JSON.toJSON(appErrorLog);return packEventJson(\"error\", jsonObject);&#125;/*** 为各个事件类型的公共字段（时间、事件类型、 Json 数据）拼接*/private static JSONObject packEventJson(String eventName, JSONObjectjsonObject) &#123;JSONObject eventJson = new JSONObject();eventJson.put(\"ett\", (System.currentTimeMillis() -rand.nextInt(99999999)) + \"\");eventJson.put(\"en\", eventName);eventJson.put(\"kv\", jsonObject);return eventJson;&#125;/*** 获取随机字母组合** @param length 字符串长度*/private static String getRandomChar(Integer length) &#123;StringBuilder str = new StringBuilder();Random random = new Random();for (int i = 0; i &lt; length; i++) &#123;// 字符串str.append((char) (65 + random.nextInt(26)));// 取得大写字母&#125;return str.toString();&#125;/*** 获取随机字母数字组合** @param length 字符串长度*/private static String getRandomCharAndNumr(Integer length) &#123;StringBuilder str = new StringBuilder();Random random = new Random();for (int i = 0; i &lt; length; i++) &#123;boolean b = random.nextBoolean();if (b) &#123; // 字符串// int choice = random.nextBoolean() ? 65 : 97; 取得 65 大写字母还是 97 小写字母str.append((char) (65 + random.nextInt(26)));// 取得大写字母&#125; else &#123; // 数字str.append(String.valueOf(random.nextInt(10)));&#125;&#125;return str.toString();&#125;/*** 收藏*/private static JSONObject generateFavorites() &#123;AppFavorites favorites = new AppFavorites();favorites.setCourse_id(rand.nextInt(10));favorites.setUserid(rand.nextInt(10));favorites.setAdd_time((System.currentTimeMillis() -rand.nextInt(99999999)) + \"\");JSONObject jsonObject = (JSONObject) JSON.toJSON(favorites);return packEventJson(\"favorites\", jsonObject);&#125;/*** 点赞*/private static JSONObject generatePraise() &#123;AppPraise praise = new AppPraise();praise.setId(rand.nextInt(10));praise.setUserid(rand.nextInt(10));praise.setTarget_id(rand.nextInt(10));praise.setType(rand.nextInt(4) + 1);praise.setAdd_time((System.currentTimeMillis() -rand.nextInt(99999999)) + \"\");JSONObject jsonObject = (JSONObject) JSON.toJSON(praise);return packEventJson(\"praise\", jsonObject);&#125;/*** 评论*/private static JSONObject generateComment() &#123;AppComment comment = new AppComment();comment.setComment_id(rand.nextInt(10));comment.setUserid(rand.nextInt(10));comment.setP_comment_id(rand.nextInt(5));comment.setContent(getCONTENT());comment.setAddtime((System.currentTimeMillis() -rand.nextInt(99999999)) + \"\");comment.setOther_id(rand.nextInt(10));comment.setPraise_count(rand.nextInt(1000));comment.setReply_count(rand.nextInt(200));JSONObject jsonObject = (JSONObject) JSON.toJSON(comment);return packEventJson(\"comment\", jsonObject);&#125;/*** 生成单个汉字*/private static char getRandomChar() &#123;String str = \"\";int hightPos; //int lowPos;Random random = new Random();//随机生成汉子的两个字节hightPos = (176 + Math.abs(random.nextInt(39)));lowPos = (161 + Math.abs(random.nextInt(93)));byte[] b = new byte[2];b[0] = (Integer.valueOf(hightPos)).byteValue();b[1] = (Integer.valueOf(lowPos)).byteValue();try &#123;str = new String(b, \"GBK\");&#125; catch (UnsupportedEncodingException e) &#123;e.printStackTrace();System.out.println(\"错误\");&#125;return str.charAt(0);&#125;/*** 拼接成多个汉字*/private static String getCONTENT() &#123;StringBuilder str = new StringBuilder();for (int i = 0; i &lt; rand.nextInt(100); i++) &#123;str.append(getRandomChar());&#125;return str.toString();&#125;&#125; 配置日志打印（Logback）Logback 主要用于在磁盘和控制台打印日志。 Logback 具体使用如下：1）在 resources 文件夹下创建 logback.xml 文件。2）在 logback.xml 文件中填写如下配配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration debug=\"false\"&gt;&lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径 --&gt;&lt;property name=\"LOG_HOME\" value=\"/opt/module/logs/\" /&gt;&lt;!-- 控制台输出 --&gt;&lt;appender name=\"STDOUT\"class=\"ch.qos.logback.core.ConsoleAppender\"&gt;&lt;encoderclass=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt;&lt;!--格式化输出： %d 表示日期， %thread 表示线程名， %-5level：级别从左显示 5 个字符宽度%msg：日志消息， %n 是换行符 --&gt;&lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125;- %msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;/appender&gt;&lt;!-- 按照每天生成日志文件。存储事件日志 --&gt;&lt;appender name=\"FILE\"class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;&lt;!-- &lt;File&gt;$&#123;LOG_HOME&#125;/app.log&lt;/File&gt;设置日志不超过$&#123;log.max.size&#125;时的保存路径，注意，如果是 web 项目会保存到 Tomcat 的 bin 目录 下 --&gt;&lt;rollingPolicyclass=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt;&lt;!--日志文件输出的文件名 --&gt;&lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/app-%d&#123;yyyy-MM\u0002dd&#125;.log&lt;/FileNamePattern&gt;&lt;!--日志文件保留天数 --&gt;&lt;MaxHistory&gt;30&lt;/MaxHistory&gt;&lt;/rollingPolicy&gt; &lt;encoderclass=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt;&lt;pattern&gt;%msg%n&lt;/pattern&gt;&lt;/encoder&gt;&lt;!--日志文件最大的大小 --&gt;&lt;triggeringPolicyclass=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\"&gt;&lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt;&lt;/triggeringPolicy&gt;&lt;/appender&gt;&lt;!--异步打印日志--&gt;&lt;appender name =\"ASYNC_FILE\" class=\"ch.qos.logback.classic.AsyncAppender\"&gt;&lt;!-- 不丢失日志.默认的,如果队列的 80%已满,则会丢弃 TRACT、 DEBUG、 INFO 级别的日志 --&gt;&lt;discardingThreshold &gt;0&lt;/discardingThreshold&gt;&lt;!-- 更改默认的队列的深度,该值会影响性能.默认值为 256 --&gt;&lt;queueSize&gt;512&lt;/queueSize&gt;&lt;!-- 添加附加的 appender,最多只能添加一个 --&gt;&lt;appender-ref ref = \"FILE\"/&gt;&lt;/appender&gt;&lt;!-- 日志输出级别 --&gt;&lt;root level=\"INFO\"&gt;&lt;appender-ref ref=\"STDOUT\" /&gt;&lt;appender-ref ref=\"ASYNC_FILE\" /&gt;&lt;appender-ref ref=\"error\" /&gt;&lt;/root&gt;&lt;/configuration&gt; 打包1）采用 Maven 对程序打包 数据采集模块日志生成1）集群规划 2） 打包好的 log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar 程序到hadoop102 的/opt/module/目录下，并执行如下命令 java -jar log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar &gt; /dev/null 2&gt;&amp;1 &amp; 3）然后进入到/opt/module/logs 目录，观察日志是否写入成功 Flume 安装及使用1） Flume 官网地址： http://flume.apache.org/2）文档查看地址： http://flume.apache.org/FlumeUserGuide.html3）下载地址： http://archive.apache.org/dist/flume/ Flume 简介Flume 是 Cloudera 提供的一个高可用的，高可靠的， 分布式的海量日志采集、聚合和传输的系统。 Flume 基于流式架构，灵活简单。 1） Source主要负责采集工作，采用 TailDir 组件用于监控文件或文件夹的变化。2） Channel扮演数据管道的角色，对数据进行缓冲。采用非持久化的 Memory 类型。3） Sink把 Channel 中的数据输出到外部环境中，支持多种数据接口（ HDFS、 Kafka 等），此次案例中我们的最终目标是数据到阿里云的数据总线中（ DataHub），调试阶段可以先输出到控制台中。 Flume 安装集群规划 1）将 apache-flume-1.7.0-bin.tar.gz 上传到 hadoop102 的/opt/software 目录下2）解压 apache-flume-1.7.0-bin.tar.gz 到/opt/module/目录下[atguigu@hadoop102 software]$ tar -zxf apache-flume-1.7.0-bin.tar.gz -C /opt/module/3） 修改 apache-flume-1.7.0-bin 的名称为 flume[atguigu@hadoop102 module]$ mv apache-flume-1.7.0-bin flume4）将 flume/conf 下的 flume-env.sh.template 文件修改为 flume-env.sh，并配置 flume-env.sh 文件 [atguigu@hadoop102 conf]$ mv flume-env.sh.template flume-env.sh[atguigu@hadoop102 conf]$ vi flume-env.shexport JAVA_HOME=/opt/module/jdk1.8.0_144 Flume 配置1）在/opt/module/flume/conf 中添加文件 file-flume-log.conf，该文件是一个 Flume 作业的核心文件，咱们上述的 Source、 Channel、 Sink 都是通过这个配置文件来实现的。 [atguigu@hadoop102 conf]$ vim file-flume-log.conf添加如下内容 定义组件名称a1.sources = r1a1.sinks = k1a1.channels = c1###source 部分a1.sources.r1.type = TAILDIR#记录偏移量实现断点续传a1.sources.r1.positionFile =/opt/module/flume/test/taildir_position.jsona1.sources.r1.channels = c1a1.sources.r1.filegroups=f1a1.sources.r1.filegroups.f1=/opt/module/logs/app.+a1.sources.r1.fileHeader = true###channel 部分a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 1000###sink 部分 先输出到控制台中a1.sinks.k1.type = logger #把 source 和 sink 绑定到 channel 中 a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 启动 Flume 进程[atguigu@hadoop102 flume]$ /opt/module/flume/bin/flume-ng agent -n a1 -c /opt/module/flume/conf/ -f/opt/module/flume/conf/file-flume-log.conf -Dflume.root.logger=info,console 说明 参数选项 含义 flume-ng agent 启动 Flume 程序 -n 任务名称，必须和配置文件中的前缀一致。 -c Flume 基本配置文件位置 -f Flume 任务配置文件位置 -Dflume.root.logger=info,console 打印控制台 验证，启动 Flume 的同时，运行日志生成程序，观察 Flume 控制台是否滚动打印日志。 DataHub 安装及使用DataHub 简介Flume 部分已经可以输出后，咱们开始搭建真正需要输出的目的地—DataHub，即阿里云数据总线服务。通俗来说这个 DataHub 类似于传统大数据解决方案中 Kafka 的角色，提供了一个数据 队列功能。 对于离线计算， DataHub 除了供了一个缓冲的队列作用。 同时由于 DataHub 提供了各种与其他阿里云上下游产品的对接功能，所以 DataHub 又扮演了一个数据的分发枢纽工作。 1） DataHub 输入组件包括Flume：主流的开源日志采集框架DTS： 类似 Canal， 日志实时监控采集框架Logstash： 也是日志采集框架，通常和 Elasticsearch、 Kibana 集合使用Fluentd： Fluentd 是一个实时开源的数据收集器OGG： 实时监控 Oracle 中数据变化Java sdk：支持 JavaAPI 方式访问2） DataHub 输出组件包括RDS：类似与传统 MySQL 数据库AnalyticDB： 面向分析型的分布式数据库MaxCompute：离线分析框架Elasticsearch：数据分析，倒排索引StreamCompute：实时分析框架TableSotre：类似于 Redis， KV 形式存储数据 OSS：类似于 HDFS， 存储图片、视频 创建 DataHub 与 Topic阿里云 DataHub 控制台入口： https://datahub.console.aliyun.com/datahub1） 进入到 DataHub 控制台 2） 点击创建 Project 3）点击查看，准备创建主题 4）点击创建 Topic 5）配置 Topic 详情 说明： 选择参数 含义 Topic 类型 Tuple 为结构化数据， Blob 是二进制数据。 Schema Tuple 类型的字段名 Shard 数量 决定了队列吞吐量，每个 Shard 支持 1MB/s 的写入能力 生命周期 数据在队列中的最长存活时间 Flume 推送数据到 DataHubFlume-DataHub 插件安装Flume 默认是不支持 DataHub 的，所以要给 Flume 安装 DataHub 的 Sink 插件 插件名称: aliyun-flume-datahub-sink-2.0.2.tar.gz 1）首先在 Flume 安装目录建立插件文件夹 mkdir plugins.d 2 ） 利 用 SecureCRT 工 具 把 aliyun-flume-datahub-sink-2.0.2.tar.gz 拷 贝 到 该/opt/module/flume/plugins.d 目录下，并原地解压缩 ls tar -zxvf aliyun-flume-datahub\u0002sink-2.0.2.tar.gz Flume 配置文件修改vim /opt/module/flume/conf/file\u0002flume-datahub.conf #定义组件名称 a1.sources = r1a1.sinks = k1a1.channels = c1 source 部分a1.sources.r1.type = TAILDIRa1.sources.r1.positionFile =/opt/module/flume/test/taildir_position.jsona1.sources.r1.channels = c1a1.sources.r1.filegroups = f1a1.sources.r1.filegroups.f1 = /opt/module/logs/app.+a1.sources.r1.fileHeader = true channel 部分a1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 1000 #sink 部分 a1.sinks.k1.type = com.aliyun.datahub.flume.sink.DatahubSinka1.sinks.k1.datahub.accessID = LTAI4FiU71dZAL17SdLBa6Nta1.sinks.k1.datahub.accessKey = 63YzSmqMOSjDR5A2ZXEzFLM2tREY6ma1.sinks.k1.datahub.endPoint = http://xxxxxinc.coma1.sinks.k1.datahub.project = gmall_datahuba1.sinks.k1.datahub.topic = base_loga1.sinks.k1.batchSize = 100a1.sinks.k1.serializer = DELIMITEDa1.sinks.k1.serializer.delimiter = “\\u007C”a1.sinks.k1.serializer.fieldnames = event_time,log_stringa1.sinks.k1.serializer.charset = UTF-8a1.sinks.k1.shard.number = 1a1.sinks.k1.shard.maxTimeOut = 60 #把 source 和 sink 绑定到 channel 中 a1.sources.r1.channels = c1a1.sinks.k1.channel = c1 说明： 选择参数 含义 type 必须是： com.aliyun.datahub.flume.sink.DatahubSink datahub.accessID accessID 下面小节会介绍 datahub.accessKey accessKey datahub.endPoint 不同的地区有不同的接入点，参考 https://help.aliyun.com/document_detail/47442.html project datahub 中创建的 project 名 topic datahub 中 project 下的 topic batchSize 每批次都少条记录 serializer 序列化方式， DELIMITED 表示按分隔符切分 serializer.delimiter 具体分隔符是什么，这里“\\u007C” 表示 | Unicode 转中文工具地址： http://www.msxindl.com/tools/unicode16.asp serializer.fieldnames 切分后对应的字段名 serializer.charset 字符集 shard.number 分片数 shard.maxTimeOut 超时时间， 单位是秒 获取 AccessID 和 AccessKeyDataHub 服务并不是靠 IP 来定位的，而是靠阿里云账号，每个阿里云账号只能有一个DataHub，每个阿里云账号也会有唯一的 AccessID 和 AccessKey。所以通过 AccessId 和AccessKey 就可以直接锁定某个阿里云账号的 DataHub。1）悬浮鼠标到阿里云账号头像上-&gt;点击 accesskeys 2）点击继续使用 AccessKey 3）新用户需要点击创建 AccessKey 4）获取到 AccessKeyID 和 AccessKeySecret 值 查看接收数据1）启动 Flume 进程 /opt/module/flume/bin/flume-ng agent -n a1 -c /opt/module/flume/conf/ -f /opt/module/flume/conf/file-flume-datahub.conf -Dflume.root.logger=info,console 2）启动日志生成程序 java -jar log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar &gt; /dev/null 2&gt;&amp;1 &amp; 3） 观察 DataHub 中数据量 DataWorks 和 MaxCompute简介MaxCompute（大数据计算服务）是阿里巴巴自主研发的海量数据处理平台，主要提供数据上传和下载通道，提供 SQL 及 MapReduce 等多种计算分析服务，同时还提供完善的安全解决方案。DataWorks（数据工场，原大数据开发套件） 是基于 MaxCompute 计算引擎的一站式大 数据工场，它能帮助您快速完成数据集成、开发、治理、服务、质量、安全等全套数据研发工作。 盘古： 相当于 Hadoop 中的 HDFS伏羲： 相当于 Hadoop 中的 YARNMaxCompute Engine： 相当于 MR、 Tez 等计算引擎MaxCompute 和 DataWorks 一起向用户提供完善的 ETL 和数仓管理能力，以及 SQL、MR、 Graph 等多种经典的分布式计算模型，能够更快速地解决用户海量数据计算问题，有效降低企业成本，保障数据安全。 用户行为数仓搭建数仓分层概念数仓分层 1） ODS 层原始数据层，存放原始数据，直接加载原始日志、数据，数据保持原貌不做处理。2） DWD 层对 ODS 层数据进行清洗（去除空值，脏数据，超过极限范围的数据）3） DWS 层以 DWD 为基础，进行轻度汇总。4） ADS 层为各种统计报表提供数据 数仓分层优点1）把复杂问题简单化将一个复杂的任务分解成多个步骤来完成，每一层只处理单一的步骤，比较简单、并且方便定位问题。2）减少重复开发规范数据分层，通过的中间层数据，能够减少极大的重复计算，增加一次计算结果的复用性。3）隔离原始数据不论是数据的异常还是数据的敏感性，使真实数据与统计数据解耦开。 数仓命名规范ODS层命名为ods前缀DWD层命名为dwd前缀 DWS层命名为dws前缀 ADS层命名为ads前缀 维度表命名为dim前缀 每日全量导入命名为df（day full） 后缀 每日增量导入命名为di（day increase） 后缀 数仓分层配置建立业务流程1）点击数据开发-&gt;业务流程-&gt;新建业务流程-&gt;输入业务名称 2）再业务流程下面就可以看到业务 1 配置表主题1）进入配置中心点击最下方的齿轮，进入配置中心 2）配置主题管理，这里主要是划分表的主题 主题一般是表的对应的业务主题，比如：基础表、用户、商品、广告等对应的业务线。 配置表层级 在同一页面中， DataWorks 还提供了一个物理分类的划分维度，用户可以根据情况自行决定划分方式。本案例中，对数据表按照数据来源划分为，日志、数据库和综合。 原始数据层（ODS 层）用户行为数仓分层 建表语句1）回到数据开发的界面，按下图开始创建数据表 2）输入表名-&gt;提交 开始建立的表要和原始数据最基本的结构一致 。 配置基本属性配置新创建的表的主题。 配置物理模型注意选择层级和物理分类，由于建立的原始日志表，所以此处选择 ODS 层。分类是日志 从 DataHub 过来的数据必须选择分区表。如果手工文件导入的表可以选择非分区。为了减少再购买存储服务器， 所以选择内部表。真实企业开发时，大部分情况都是创建外部表，需要在 OSS 服务中申请存储空间。 配置字段发送过来的日志包含两部分： 服务器时间和日志详情。 这里面设计了两个字段对应接收。 注意：这里的主键，是指一个标志而已，本身不提供索引和唯一性约束。 配置分区表示数据按如下字段进行分区 由于目前 DataHub 至 MaxCompute 的接口，只支持按年月日+小时+分钟方式分区，所以这三个字段是必须有的，且字段类型必须是 String。 查看建表语句点击 DDL 模式，可以查看自动生成的建表语句。 和普通的创建表语句一样。 提交到生产环境点击提交到生产环境，表就创建完成了 。 表的基本操作查看表结构在最左侧菜单中选择【表管理】，可以在右侧查看表的结构信息。但是不可以修改。 在业务流程中导入表在业务 1 中建 ods、 dwd、 dws、 ads， 4 个文件夹 2）向 ods 文件夹中导入表 临时查询1） 点击临时查询-&gt;新建-&gt;ODPS SQL 2）创建临时查询节点 3）可以执行 SQL 命令 DataHub 推送数据到 MaxCompute如下图，之前 Flume 中的数据利用 DataHub Sink 把数据写入到了 DataHub 中， DataHub中提供了很多的其他第三方的 DataConnector 可以连接各种例如： MaxCompute， ElasticSearch，ADB， RDS 等数据库。 所以下面就要建立 DataConnector 把数据推送到 MaxCompute 中。 创建 DataConnector1）在 DataHub 中找到 Topic，在某个 Topic 下，点击右上角的 DataConnector 2） 点击同步到 MaxCompute 离线表 3） 创建 DataConnector （1） MaxCompute Project：名称要和 MaxCompute 创建的工作空间名称一致（ 2） MaxCompute Table： 数据导入到 MaxCompute 中的表名（ 3） AccessKey ID： LTAI4FiU71dZAL17SdLBa6Nt（ 4） AccessKey Secret： 63YzSmqMOSjDR5A2ZXEzFLM2tREY6m注意： AccessKey ID 和 AccessKey Secret 要和自己的阿里云账号一一对应（ 5）分区选项： system、 event_time通常采用 system 时间分区。如果是 event_time 方式分区，就要在 topic 中包含一个 event_time 的字段。不过这个字段与以往的 timestamp 不同的是，必须精确到微秒级。而且这个字段一旦用于分区，则不会再写入到实体表中。（ 6）分区范围： 15 分钟起 发送数据建立好表后 DataConnector 就可以尝试发送数据了。注意： 如果已经启动了 Flume，就不需要再次启动了。1）启动 Flume 程序 /opt/module/flume/bin/flume-ng agent-n a1 -c /opt/module/flume/conf/ -f /opt/module/flume/conf/file-flume-datahub.conf -Dflume.root.logger=info,console 2）在服务器 hadoop102 上执行命令 java -jar log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar &gt; /dev/null 2&gt;&amp;1 &amp; 接收数据1） 观察 DataHub 中接收到数据（速度很快） 2）查看 MaxCompute 中接收到数据（1-5 分钟的延迟） 明细数据层（DWD 层）DWD 层主要是对 ODS 层数据进行清洗（去除空值，脏数据，超过极限范围的数据）。DWD 层处理后的表，能够成为非常明确可用的基础明细数据。本次项目中需要将用户行为过来基础日志，根据表类型，一张一张的解析出来 11 张不同类型的表数据，方便后续的处理。 日志格式分析1）日志格式：服务器时间 | json 2）其中 json 包括：cm：公共字段的 key；ap： app 的名称；et：具体事件 自定义 UDTF（解析具体事件字段）开发 UDTF 有两个方法： 方法 1：在本地 IDEA 中创建工程，开发代码，打包，把 JAR 上传到 DataStudio 成为资源 JAR 包。然后基于资源 JAR 包，声明函数。 方法 2：直接在 FunctionStudio 中开发，然后在线打包发布程序，声明函数。 相比而言，从发布流程上来说利用 FunctionStudio 更快捷方便。但是从 IDEA 开发角度来说，网页版本的 FunctionStudio，肯定不如客户端的功能强大、反应速度流畅。不过也可以两者配合起来使用。本次案例主要介绍通过 FunctionStudio 来编写 UDTF 函数。1） 按下图所示，打开 FunctionStudio 的界面 2）创建工程 3）选择命名工程名，选择 udfjava 4）添加代码文件 可以看到工程创建好后，默认有很多参考的模板。 5）在 udtf 目录下创建一个 FlatEventUDTF 类 6）编写代码 首先分析日志结构 1）在 pom.xml 中要加入 fastJson 依赖 12345&lt;dependency&gt;&lt;groupId&gt;com.alibaba&lt;/groupId&gt;&lt;artifactId&gt;fastjson&lt;/artifactId&gt;&lt;version&gt;1.2.28.odps&lt;/version&gt;&lt;/dependency&gt; （ 2）编写自定义 UDTF 代码 12345678910111213141516171819202122232425262728import com.aliyun.odps.udf.ExecutionContext;import com.aliyun.odps.udf.UDFException;import com.aliyun.odps.udf.UDTF;import com.aliyun.odps.udf.annotation.Resolve;import com.alibaba.fastjson.*;// TODO define input and output types, e.g.\"string,string-&gt;string,bigint\".@Resolve(&#123;\"string-&gt;bigint,string,string\"&#125;)public class FlatEventUDTF extends UDTF &#123;@Overridepublic void setup(ExecutionContext ctx) throws UDFException&#123; &#125;@Overridepublic void process(Object[] args) throws UDFException &#123;String event =(String) args[0];JSONArray jsonArray = JSON.parseArray(event);for (int i = 0; i &lt; jsonArray.size(); i++) &#123;JSONObject jsonObject = jsonArray.getJSONObject(i);String ett =(String) jsonObject.getString(\"ett\");String eventName =(String) jsonObject.getString(\"en\");String eventJson =(String) jsonObject.getString(\"kv\");forward(Long.parseLong(ett),eventName,eventJson);&#125;&#125;@Overridepublic void close() throws UDFException &#123;&#125;&#125; 其中， @Resolve({“string-&gt;bigint,string,string”} 表示该函数，传入参数是 string，返回参数是三个，分别为长整型，和两个字符串，对应的返回值就是事件的时间、事件名称和事件内容（json 格式）。 7）打包部署 （1）提交到 Data Studio 开发环境 （2）提交函数详情 （ 3）提交函数过程，控制台打印 提交成功后 ，回到 DataWorks 中的资源菜单中可以看到增加了 1 个 JAR 包，函数菜单中可以看到定义的函数。 8）测试函数在 DataStudio 中临时查询，执行如下语句 12345selectFlatEventUDTF(GET_JSON_OBJECT(log_string,'$.et')) as(event_time, event_name, event_json)from ods_base_logwhere ds='20191008'; 能看到如下结果表示运行正确 DWD 层建表（启动日志表）在流程中建立表，在 DWD 文件夹中增加一个 dwd_start_log 的表，可以直接用 ddl 模式建立，再进行微调。 1） 在业务 1 的表上，右键新建表 2）点击 DDL 模式 3） 在 DDL 模式中添加建表语句 详细建表语句如下 12345678910111213141516171819202122232425CREATE TABLE `dwd_start_log` (`mid` string,`user_id` string,`version_code` string,`version_name` string,`lang` string,`source` string,`os` string,`area` string,`model` string,`brand` string,`sdk_version` string,`email` string,`height_width` string,`network` string,`lng` string,`lat` string,`entry` string,`open_ad_type` string,`action` string,`loading_time` string,`detail` string,`event_time` string COMMENT '事件时间')PARTITIONED BY (ds string, hh string, mm string); 4）补充一些相关字段。 5）补充分区格式 6）提交到生产环境 手动将 ODS 层数据导入 DWD 层1）在临时查询页面， 把 ods 层 ods_base_log 里面的数据导入到 dwd_start_log 123456789101112131415161718192021222324252627282930313233INSERT OVERWRITE TABLE dwd_start_log PARTITION (ds,hh,mm)selectGET_JSON_OBJECT(log_string,'$.cm.mid') mid,GET_JSON_OBJECT(log_string,'$.cm.uid') user_id,GET_JSON_OBJECT(log_string,'$.cm.vc') version_code,GET_JSON_OBJECT(log_string,'$.cm.vn') version_name,GET_JSON_OBJECT(log_string,'$.cm.l') lang,GET_JSON_OBJECT(log_string,'$.cm.sr') source,GET_JSON_OBJECT(log_string,'$.cm.os') os,GET_JSON_OBJECT(log_string,'$.cm.ar') area,GET_JSON_OBJECT(log_string,'$.cm.md') model,GET_JSON_OBJECT(log_string,'$.cm.ba') brand,GET_JSON_OBJECT(log_string,'$.cm.sv') sdk_version,GET_JSON_OBJECT(log_string,'$.cm.hw') height_width,GET_JSON_OBJECT(log_string,'$.cm.g') email,GET_JSON_OBJECT(log_string,'$.cm.hw') sv,GET_JSON_OBJECT(log_string,'$.cm.ln') ln,GET_JSON_OBJECT(log_string,'$.cm.la') la,GET_JSON_OBJECT( event_view.event_json,'$.entry') entry,GET_JSON_OBJECT( event_view.event_json,'$.loading_time')loading_time,GET_JSON_OBJECT( event_view.event_json,'$.action') action,GET_JSON_OBJECT( event_view.event_json,'$.open_ad_type')open_ad_type,GET_JSON_OBJECT( event_view.event_json,'$.detail') detail ,event_view.event_time,ds,hh,mmfrom ods_base_logLATERAL VIEW FlatEventUDTF(GET_JSON_OBJECT(log_string,'$.et' ))event_view as event_time,event_name,event_jsonwhere ds='20191008' and event_view.event_name = 'start'; 注意: get_json_object函数的作用：用来解析json字符串的一个字段 2）在临时查询中查看导入结果 1SELECT * from dwd_start_log WHERE ds='20191008'; 数据导入脚本1）在流程中加入一个ODPS数据开发SQL脚本 123456789101112131415161718192021222324252627282930313233INSERT OVERWRITE TABLE dwd_start_log PARTITION (ds,hh,mm)selectGET_JSON_OBJECT(log_string,'$.cm.mid') mid,GET_JSON_OBJECT(log_string,'$.cm.uid') user_id,GET_JSON_OBJECT(log_string,'$.cm.vc') version_code,GET_JSON_OBJECT(log_string,'$.cm.vn') version_name,GET_JSON_OBJECT(log_string,'$.cm.l') lang,GET_JSON_OBJECT(log_string,'$.cm.sr') source,GET_JSON_OBJECT(log_string,'$.cm.os') os,GET_JSON_OBJECT(log_string,'$.cm.ar') area,GET_JSON_OBJECT(log_string,'$.cm.md') model,GET_JSON_OBJECT(log_string,'$.cm.ba') brand,GET_JSON_OBJECT(log_string,'$.cm.sv') sdk_version,GET_JSON_OBJECT(log_string,'$.cm.hw') height_width,GET_JSON_OBJECT(log_string,'$.cm.g') email,GET_JSON_OBJECT(log_string,'$.cm.hw') sv,GET_JSON_OBJECT(log_string,'$.cm.ln') ln,GET_JSON_OBJECT(log_string,'$.cm.la') la,GET_JSON_OBJECT( event_view.event_json,'$.entry') entry,GET_JSON_OBJECT( event_view.event_json,'$.loading_time')loading_time,GET_JSON_OBJECT( event_view.event_json,'$.action') action,GET_JSON_OBJECT( event_view.event_json,'$.open_ad_type')open_ad_type,GET_JSON_OBJECT( event_view.event_json,'$.detail') detail,event_view.event_time,ds,hh,mmfrom ods_base_logLATERAL VIEW FlatEventUdtf (GET_JSON_OBJECT(log_string,'$.et' ))event_view as event_time,event_name,event_jsonwhere ds='$&#123;bizdate&#125;' and event_view.event_name = 'start' ; 注意： 在上面的 SQL 中我们使用了一个${bizedate}作为外部传入的日期参数 。 2）配置参数在执行或者调度该脚本的时候传入相应的参数。 （ 1）在右侧有一个调度配置，打开可以对参数进行设置。 注意：这里参数设置用的是花括号， bizdate=${yyyymmdd}， 表示取前一日的日期；如果采用方括号，如， bizdate= $[yyyymmdd]， 表示取当前日期。 （ 2）配置脚本执行时间 服务数据层（DWS 层）需求：日活统计 建表语句1） 创建表 dws_uv_detail_d 2）点击 DDL 模式 3） 在 DDL 模式中添加建表语句 123456789101112131415161718192021CREATE TABLE `dws_uv_detail_d` (`mid` string COMMENT '设备唯一标识',`user_id` string COMMENT '用户标识',`version_code` string COMMENT '程序版本号',`version_name` string COMMENT '程序版本名',`lang` string COMMENT '系统语言',`source` string COMMENT '渠道号',`os` string COMMENT '系统版本',`area` string COMMENT '区域',`model` string COMMENT '手机型号',`brand` string COMMENT '手机品牌',`sdk_version` string COMMENT 'sdkversion',`email` string COMMENT 'email',`height_width` string COMMENT '屏幕宽高',`network` string COMMENT '网络模式',`lng` string COMMENT '经度',`lat` string COMMENT '纬度',`event_time` bigint)COMMENT '活跃用户按天明细'PARTITIONED BY (ds string,hh string,mm string); 4）补全建表信息描述 5）提交到生产环境 手动将 DWD 层数据导入 DWS 层1）在临时查询页面， 把 DWD 层 dwd_start_log 里面的数据导入到 dws_uv_detail_d 12345678910111213141516171819202122232425262728293031insert overwrite table dws_uv_detail_d partition(ds,hh,mm)selectmid,user_id,version_code,version_name,lang,source,os,area,model,brand,sdk_version,email,height_width,network,lng,lat,event_time,ds,hh,mmfrom(select*,ROW_NUMBER() OVER(PARTITION BY mid ORDER BY event_timeasc) rnfrom dwd_start_logwhere ds='20191008') st where rn = 1; 2）查看导入结果 SELECT * from dws_uv_detail_d WHERE ds=’20191008’; 数据导入脚本DWS 层一般围绕某个主题进行聚合、拼接处理。针对统计日活的需求， DWS 主要的工作就进行以日为单位的去重操作。 1）在流程中加入一个数据开发脚本 12345678910111213141516171819202122232425262728293031insert overwrite table dws_uv_detail_d partition(ds,hh,mm)selectmid,user_id,version_code,version_name,lang,source,os,area,model,brand,sdk_version,email,height_width,network,lng,lat,event_time,ds,hh,mmfrom(select*,ROW_NUMBER() OVER(PARTITION BY mid ORDER BY event_timeasc) rnfrom dwd_start_logwhere ds = '$&#123;bizdate&#125;') st where rn = 1; 2）配置参数点击调度配置-&gt; bizdate=${yyyymmdd} 应用数据层（ADS 层）统计各个渠道的 uv 个数 建表语句1） 创建表 ads_uv_source_d 2）点击 DDL 模式 3） 在 DDL 模式中添加建表语句 123456CREATE TABLE `ads_uv_source_d` (`source` string COMMENT '渠道',`ct` bigint COMMENT '个数')COMMENT '日活渠道统计'PARTITIONED BY (ds string); 4）补全建表信息描述 5）提交到生产环境 ads层数据导入脚本1）在流程中加入一个数据开发脚本 12345678insert OVERWRITE table ads_uv_source_d PARTITION(ds='$&#123;bizdate&#125;')SELECTsource,COUNT(*) ctfrom dws_uv_detail_dwhere ds='$&#123;bizdate&#125;'group by source; 2）配置参数点击调度配置-&gt; bizdate=${yyyymmdd} 日活需求： 全流程业务调度1）点击业务 1， 右侧就会出现之前写的脚本。默认三个脚本之间没有关系，可以根据业务需求，手动连线。 2）点击执行 3）查询运行日志 4）临时查询， 检查结果 1SELECT * from ads_uv_source_d WHERE ds='20191008'; to be continued…","categories":[],"tags":[{"name":"数据仓库","slug":"数据仓库","permalink":"https://etop.work/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"}]}]}